# OpenSeesMP App

***Parallel OpenSees Runner for High-Performance Computing***

The **OpenSeesMP** app is a Tapis-powered, SLURM-submitted application that runs OpenSees in **MPI-parallel** mode on the **Stampede3 cluster** at TACC. Unlike *OpenSees-express*, this app is built for large-scale, multi-core structural simulations that require distributed memory processing, job queuing, and access to advanced hardware.

You can find the template for this app in the [TACC Repo](https://github.com/TACC/WMA-Tapis-Templates/tree/main/applications/opensees-mp/opensees-mp-s3)

## Key Features

* **Runs OpenSeesMP** â€” the MPI-enabled version of OpenSees
* **Executes on Stampede3** via SLURM scheduler
* **Leverages Tapis API** for structured job submission and tracking
* **Accepts directory-based input** with customizable *.tcl* scripts
* **Supports MPI execution** using *ibrun* across 2+ nodes and 48+ cores per node

This app is composed of three main files:

1. A Tapis *app.json* file defining the HPC job structure
2. A *profile.json* that loads Stampede3 modules
3. A *tapisjob_app.sh* script that launches the MPI-enabled binary




## Summary: OpenSees at Scale with OpenSeesMP

| Component         | Purpose                                                               |
|------------------|-----------------------------------------------------------------------|
| *app.json*        | Describes inputs, parameters, HPC config, and output archiving        |
| *profile.json*    | Loads required software modules on Stampede3                          |
| *tapisjob_app.sh* | Executes OpenSeesMP using *ibrun* and user-defined *.tcl* script      |

This app is ideal for:

- **Large-scale simulations** requiring distributed memory
- **Parallel analyses** using OpenSeesMP
- Users familiar with MPI and SLURM workflows

```{tip}
To **debug or test** your script before submitting to Stampede3, you can use the lightweight *OpenSees-express* or a JupyterHub terminal session with a smaller *.tcl* input file.
```
