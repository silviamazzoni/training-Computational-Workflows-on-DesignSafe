{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"reference external\" href=\"https://jupyter.designsafe-ci.org/hub/user-redirect/lab/tree/CommunityData/Training/Computational-Workflows-on-DesignSafe/Jupyter_Notebooks/Jupyter_Notebooks_TapisAppsDev/custApp_DesignSafe-Agnostic_A_BuildApp.ipynb\" target=\"_blank\">\n",
    "<img alt=\"Try on DesignSafe\" src=\"https://raw.githubusercontent.com/DesignSafe-Training/pinn/main/DesignSafe-Badge.svg\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build A Custom Tapis App\n",
    "Silvia Mazzoni, DesignSafe, 2026 \n",
    "\n",
    "## **Build a General “Agnostic” App and a Reduced-Scope OpenSeesPy App**\n",
    "\n",
    "You can access these apps via the web portal at \n",
    "* https://designsafe-ci.org/workspace/designsafe-agnostic-app\n",
    "* https://designsafe-ci.org/workspace/designsafe-openseespy-s3\n",
    "Even though submitting the job via the portal is not efficient when you have to submit it more than once, looking at the app input via the portal is very helpful in gaining insight into the app itself since the inputs are presented with options and documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose of this Notebook\n",
    "<div style=\"margin-left:25px;padding:10px;border:2px solid lightgray\">\n",
    "    \n",
    "This notebook is a **practical, end-to-end guide** for designing, generating, packaging, and registering **custom Tapis v3 ZIP-runtime apps** on DesignSafe HPC systems (e.g., Stampede3).\n",
    "\n",
    "It focuses on two closely related outcomes:\n",
    "\n",
    "1. **A general “agnostic” Tapis app: designsafe-agnostic-app**  \n",
    "   A flexible, reusable wrapper capable of running:\n",
    "   - OpenSees (serial)\n",
    "   - OpenSeesMP (MPI)\n",
    "   - OpenSeesPy\n",
    "   - Python-based workflows\n",
    "   - Other command-line solvers or scripts\n",
    "\n",
    "2. **A reduced-scope, opinionated OpenSeesPy app: designsafe-openseespy-s3**  \n",
    "   A simplified derivative designed for:\n",
    "   - portal-friendly usage\n",
    "   - fewer user-facing parameters\n",
    "   - constrained, safer execution patterns\n",
    "\n",
    "The notebook **parameterizes shared logic first**, then shows how to specialize it—demonstrating how one robust app design can support many execution styles without duplicating code.\n",
    "</div>\n",
    "\n",
    "## What This Notebook Produces\n",
    "\n",
    "<div style=\"margin-left:25px;padding:10px;border:2px solid lightgray\">\n",
    "    \n",
    "Running this notebook generates a **complete, versionable ZIP app bundle**, including:\n",
    "\n",
    "- **`app.json`**  \n",
    "  The Tapis App definition: inputs, parameters, resource requests, queue mapping, and runtime settings.\n",
    "\n",
    "- **`profile.json`**  \n",
    "  Execution-system–specific environment configuration (e.g., module loads, defaults), allowing the same app logic to remain portable.\n",
    "\n",
    "- **`tapisjob_app.sh`**  \n",
    "  The core wrapper script that runs on the allocated compute node(s).  \n",
    "  This script is treated as a **first-class software artifact**, with:\n",
    "  - explicit setup / run / post-process phases\n",
    "  - structured logging\n",
    "  - MPI and non-MPI launch control\n",
    "  - controlled staging and cleanup\n",
    "\n",
    "- **A packaged `.zip` archive**  \n",
    "  Ready to be registered as a new Tapis app version or used to update an existing one.\n",
    "\n",
    "This notebook is designed to be **re-run repeatedly** as you refine the app, ensuring that artifacts remain consistent, reproducible, and traceable.\n",
    "\n",
    "\n",
    "  \n",
    "#### Side-By-Side Comparison: Agnostic App vs. OpenSeesPy-Only App\n",
    "\n",
    "| Feature              | **designsafe-agnostic-app**                                                   | **designsafe-openseespy-s3**                |\n",
    "| -------------------- | ----------------------------------------------------------------------------- | ------------------------------------------- |\n",
    "| Scope                | Run *any* executable: OpenSees, OpenSeesMP, OpenSeesPy, python3, custom tools | Run OpenSeesPy only                         |\n",
    "| Main Program options | Multiple (OpenSees, OpenSeesMP, python3)                                      | Hidden → always python3                   |\n",
    "| UseMPI               | Exposed to user                                                               | Exposed but optional                        |\n",
    "| PIP installation     | List + file                                                                   | Hidden default list                         |\n",
    "| Module loading       | User controls via list/file                                                   | Hidden defaults (python, opensees, hdf5)    |\n",
    "| ZIP/Move output      | Supported                                                                     | Removed (not supported)                     |\n",
    "| Complexity           | Full-featured                                                                 | Simplest possible                           |\n",
    "| Intended for         | Advanced users, HPC workflows, general apps                                   | Web portal users running OpenSeesPy scripts |\n",
    "\n",
    "</div>\n",
    "\n",
    "## MPI vs. Non-MPI Apps: Interpreting *isMpi*\n",
    "<div style=\"margin-left:25px;padding:10px;border:2px solid lightgray\">\n",
    "    \n",
    "Tapis apps include an `isMpi` flag that controls **how Tapis launches the job**, not what your wrapper is allowed to do.\n",
    "\n",
    "Key clarifications:\n",
    "\n",
    "- An app with `isMpi: false` **can still run MPI internally**\n",
    "- Requesting multiple nodes does **not automatically invoke MPI**\n",
    "- The wrapper (`tapisjob_app.sh`) ultimately decides:\n",
    "  - whether MPI is used\n",
    "  - how many ranks\n",
    "  - which launcher (`mpirun`, `srun`, etc.)\n",
    "\n",
    "This notebook demonstrates:\n",
    "- pure serial execution\n",
    "- explicit MPI launch inside the wrapper\n",
    "- hybrid workflows (serial preprocessing → MPI solve → serial postprocessing)\n",
    "\n",
    "This design gives you **maximum control** while remaining compatible with Tapis orchestration.\n",
    "\n",
    "---\n",
    "### Jupyter as an IDE\n",
    "\n",
    "The Jupyter Notebook turns app development into a **repeatable, one-click pipeline** instead of a fragile set of manual steps. It becomes the living, executable “source of truth” for both the app logic and its documentation. \n",
    "\n",
    "The notebook parameterizes the common logic and then specializes it for each app, so you can see:\n",
    "\n",
    "- how to design a **flexible, general app**; and  \n",
    "- how to derive a **simplified, opinionated variant** (here, OpenSeesPy-only) for portal-friendly use.\n",
    "\n",
    "Creating a robust app requires many iterations. <br>When using a Jupyter Notebook you **just hit the *\"Restart the Kernel and Run All Cells\"* button to run the entire app-building workflow, from creating the app to submitting a job and visualizing the output**.\n",
    "\n",
    "---\n",
    "### Execution-System Constraints\n",
    "When using OpenSees, these apps rely on its availability in the execution system. **Stampede3** meets this requirement.\n",
    "\n",
    "If you do not need OpenSees, or are using your own version of it, you may install the Agnostic app in any system.\n",
    "\n",
    "---\n",
    "What follows is a practical walkthrough for defining, packaging, and registering these two **apps** using the Tapis v3 API.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this Notebook\n",
    "\n",
    "<div style=\"margin-left:25px;padding:10px;border:2px solid lightgray\">\n",
    "    \n",
    "This notebook builds the **designsafe-agnostic-app**: a Tapis app wrapper that can run OpenSees / OpenSeesMP / OpenSeesSP, OpenSeesPy, and general Python tasks, as well as other command-line programs.\n",
    "\n",
    "The goal is **not** just to produce one app, but to give you a **template and guide** for writing your own apps:\n",
    "\n",
    "* The notebook demonstrates how to work from a **single source** and generate multiple app variants (e.g., the full agnostic app vs. a more focused OpenSeesPy app).\n",
    "* The Tapis-app's shell script is broken down into many features that are designed to be **modular, optional, and controlled by environment variables or app inputs**.\n",
    "* A core design goal is to **minimize expensive file movement through Tapis**. Moving large or numerous files via Tapis (into or out of the execution directory) can dominate runtime and congest shared channels. Many of the features in the app are explicitly designed to move work onto the **shared filesystem** (via 'rsync', 'unzip', and 'mv' on the cluster), so jobs run faster and the Tapis system scales better for everyone.\n",
    "\n",
    "---\n",
    "### Design Philosophy: Modular, Optional, Single-Source\n",
    "\n",
    "The notebook and the 'tapisjob_app.sh' script are designed so that:\n",
    "\n",
    "* Each feature is **self-contained** (usually guarded by an environment variable: 'GET_TACC_OPENSEESPY', 'PATH_COPY_IN_LIST', 'ZIP_OUTPUT_SWITCH', etc.).\n",
    "* Features **complement each other**, some may be **interdependent**, but **none is mandatory** for the app to function.\n",
    "* The same core shell script supports:\n",
    "\n",
    "  * A **fully-featured, “agnostic” app** (OpenSees + Python + generic features).\n",
    "  * A more targeted **OpenSeesPy-focused app**, which only enables a subset of those features.\n",
    "\n",
    "This notebook shows how to keep one **single source** for the logic and selectively turn features on/off when building different apps. In practice, apps are never “done” after a single iteration; this single-source model makes it realistic to maintain and evolve a family of related apps over time.\n",
    "\n",
    "---\n",
    "### Why a Jupyter Notebook as the Single Source?\n",
    "\n",
    "A Jupyter Notebook is an ideal **single-source, click-button** environment for building and maintaining Tapis apps. Instead of juggling separate shell scripts, JSON files, and command-line calls, the entire app lifecycle lives in one place: the notebook.\n",
    "\n",
    "<details>\n",
    "With this approach:\n",
    "\n",
    "* **All steps are captured in one workflow**\n",
    "  Writing the app files ('tapisjob_app.sh', 'app.json', optional helper scripts), registering/updating the app, and submitting a test job can all be driven from a **single “Run All”** action. Anything else would require you to perform those steps manually—editing files by hand, copying them to the system, running 'tapis' CLI commands in the right order, and hoping you didn’t miss a step.\n",
    "\n",
    "* **Reproducible “click-to-rebuild” apps**\n",
    "  The notebook acts as an executable recipe: whenever you want to change the app (new feature, new version, new defaults), you edit cells, re-run them, and the notebook regenerates the app definition and script in a consistent way. This reduces “drift” between your code and your registration on Tapis.\n",
    "\n",
    "* **Single source for logic *and* documentation**\n",
    "  Markdown cells describe the intent and usage; code cells implement it. The same notebook that writes 'app.json' also explains every input, parameter, and feature. When you change the app, you update the notebook in one place, instead of hunting through external docs.\n",
    "\n",
    "* **Interactive inspection and debugging**\n",
    "  The notebook can show you each generated file **with and without line numbers**:\n",
    "\n",
    "  * Line numbers help you quickly locate errors reported by JSON validators or Tapis (e.g., “line 127” in 'app.json').\n",
    "  * The plain (no line numbers) view is perfect for copying file contents into other tools when necessary.\n",
    "\n",
    "* **Flexible for multiple app variants**\n",
    "  Because the notebook contains all the branching logic, you can generate the **full agnostic app** and more specialized apps (e.g., OpenSeesPy-only) from the same code. Parameters, feature flags, and small configuration changes are handled programmatically, rather than by hand-editing multiple divergent copies.\n",
    "</details>\n",
    "In short, the Jupyter Notebook turns app development into a **repeatable, one-click pipeline** instead of a fragile set of manual steps. It becomes the living, executable “source of truth” for both the app logic and its documentation.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### How to Use This Notebook as Your Template\n",
    "\n",
    "When you adapt this notebook for your own app:\n",
    "\n",
    "1. **Start from the generic features**:\n",
    "\n",
    "   * Keep the logging, timers, directory management, and output movement.\n",
    "   * Decide which file-movement helpers ('UNZIP_FILES_LIST', 'PATH_COPY_IN_LIST', 'ZIP_OUTPUT_SWITCH', 'PATH_MOVE_OUTPUT') make sense for your workflow.\n",
    "2. **Add your domain-specific blocks**:\n",
    "\n",
    "   * For OpenSees, keep or extend the existing module loads and OpenSeesPy handling.\n",
    "   * For other solvers, use these as patterns to load different modules or shared libraries.\n",
    "3. **Adapt the Python features as needed**:\n",
    "\n",
    "   * Decide whether you want a strict requirements file, a simple list-of-packages switch, or both.\n",
    "4. **Document everything in 'app.json'**:\n",
    "\n",
    "   * For each input and parameter, provide a meaningful description.\n",
    "   * Use the notebook’s line-numbered view and validation helpers as you iterate.\n",
    "5. **Reuse and extend the logging and timers**:\n",
    "\n",
    "   * They are extremely useful for profiling jobs and should be considered foundational infrastructure in every new app you build.\n",
    "\n",
    "The result is a **single-source, modular, and reusable pattern** that you can carry forward into future apps—whether they’re for structural analysis, data post-processing, or entirely different scientific workflows.\n",
    "\n",
    "---\n",
    "### Why Well-Documented Apps Matter\n",
    "\n",
    "Keeping rich documentation *inside* 'app.json' is important:\n",
    "\n",
    "* You only need to **update one source** as the app evolves.\n",
    "* Users see clear descriptions directly in the Tapis UI (or in CLI help), rather than searching for an external PDF or web page.\n",
    "* It helps future you (and collaborators) understand:\n",
    "\n",
    "  * What each input does,\n",
    "  * Which options are safe to change,\n",
    "  * How environment variables map to script behavior.\n",
    "\n",
    "Because the notebook builds and validates the JSON, it becomes the **natural place to update both logic and documentation** together.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomy of a Tapis App\n",
    "\n",
    "<div style=\"margin-left:25px;padding:10px;border:2px solid lightgray\">  \n",
    "\n",
    "A Tapis v3 App is composed of a small set of files and configuration artifacts that work together to define:\n",
    "\n",
    "* how a job *looks* to the user\n",
    "* how it *runs* on the HPC system\n",
    "* how files are *staged*, *executed*, and *archived*\n",
    "* how the scientific code or workflow is *launched*\n",
    "\n",
    "Although a Tapis app can be extremely flexible—supporting OpenSees, OpenSeesMP, OpenSeesPy, Python, or arbitrary executables—the underlying structure is always the same.\n",
    "\n",
    "This section breaks down each component, explains what it does, where it lives, why it is needed, and how Tapis interacts with it during a job. *(Click on each header to expand)*\n",
    "\n",
    "\n",
    "<details><summary><b><large>1. app.json — The App Definition (Required)</large></b><br>Defines the app’s identity, inputs, parameters, and execution system</summary>\n",
    "<div style=\"padding-left:30px\">\n",
    "app.json is the **formal definition** of the application.\n",
    "This is the file that is *registered* into Tapis, and therefore must follow the Tapis App schema.\n",
    "\n",
    "It defines:\n",
    "\n",
    "<details><summary><b>App identity</b></summary>\n",
    "\n",
    "* App ID\n",
    "* Version\n",
    "* Description\n",
    "* Category\n",
    "* Ownership / permissions\n",
    "</details>\n",
    "<details><summary><b>Execution system</b></summary>\n",
    "\n",
    "* Stampede3 (or another execution system)\n",
    "* Queue, node count, cores, memory\n",
    "* Scheduler profile\n",
    "* Archiving rules\n",
    "</details>\n",
    "\n",
    "<details><summary><b>Runtime configuration</b></summary>\n",
    "\n",
    "* runtime: \"ZIP\" tells Tapis to fetch + unpack a ZIP file at job start\n",
    "* Path to the ZIP package\n",
    "* Whether MPI is enabled at the Tapis level (isMpi: false for our apps)\n",
    "</details>\n",
    "\n",
    "<details><summary><b>App parameters (visible to the user in the portal)</b></summary>\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Main Program (OpenSees, python3, etc.)\n",
    "* Main Script name\n",
    "* UseMPI toggle\n",
    "* Optional command-line arguments\n",
    "\n",
    "These appear in the portal UI or Tapis CLI and are forwarded directly into the wrapper script.\n",
    "</details>\n",
    "\n",
    "<details><summary><b>Environment variables</b></summary>\n",
    "\n",
    "These control application-specific behavior such as:\n",
    "\n",
    "* Which modules to load\n",
    "* Which pip packages to install\n",
    "* Whether to copy TACC-compiled OpenSeesPy\n",
    "* Optional ZIP/unzip behavior\n",
    "\n",
    "They are automatically exported into the job’s environment.\n",
    "</details>\n",
    "\n",
    "<details><summary><b>Input/Output behavior</b></summary>\n",
    "\n",
    "* Required “Input Directory”\n",
    "* Archive inclusion/exclusion patterns\n",
    "\n",
    "**In short:**\n",
    "app.json defines *what* the app is and *how* users interact with it.\n",
    "</details>\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "<details><summary><b><large>2. Scheduler Profile — System-level environment initialization</large></b><br>Initializes the compute-node environment before the wrapper script runs</summary>\n",
    "\n",
    "<div style=\"padding-left:30px\">\n",
    "A scheduler profile defines how the compute node environment is set up **before** your wrapper script runs.\n",
    "It dictates availability of the module command, default environment variables, and job-launch behavior.\n",
    "\n",
    "Your apps use:\n",
    "\n",
    "```\n",
    "--tapis-profile tacc-no-modules\n",
    "```\n",
    "\n",
    "Because it ensures:\n",
    "\n",
    "* A clean environment\n",
    "* No automatically loaded modules\n",
    "* Full control inside tapisjob_app.sh\n",
    "\n",
    "**Scheduler profile = system setup.**\n",
    "**envVariables = app configuration.**\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary><b><large>3. tapisjob_app.sh — Wrapper script (the executable logic) (Required)</large></b><br>Performs all runtime logic; loads modules, installs pip, launches user script</summary>\n",
    "<div style=\"padding-left:30px\">\n",
    "This is the **heart of the app at runtime**.\n",
    "\n",
    "Tapis does not execute your OpenSees or Python files directly.\n",
    "Instead, it runs this script, which performs all operational steps:\n",
    "\n",
    "##### **Logs & timers**\n",
    "\n",
    "Creates:\n",
    "\n",
    "* SLURM-job-summary.log\n",
    "* SLURM-full-environment.log\n",
    "  and timestamps total runtime + main program runtime.\n",
    "\n",
    "##### **Validates arguments**\n",
    "\n",
    "Ensures the app received:\n",
    "\n",
    "* Main Program\n",
    "* Main Script\n",
    "* UseMPI\n",
    "* Additional CLI arguments\n",
    "\n",
    "##### **Normalizes the environment**\n",
    "\n",
    "* Ensures python3 is used instead of python\n",
    "* Verifies input directory exists\n",
    "* Shows Job UUID and system paths\n",
    "\n",
    "##### **Loads modules**\n",
    "\n",
    "Using:\n",
    "\n",
    "* MODULE_LOADS_LIST\n",
    "* or MODULE_LOADS_FILE\n",
    "\n",
    "This is necessary because the scheduler profile loads *nothing*.\n",
    "\n",
    "##### **Installs pip packages**\n",
    "\n",
    "Supports:\n",
    "\n",
    "* PIP_INSTALLS_LIST\n",
    "* PIP_INSTALLS_FILE\n",
    "\n",
    "Executed directly on the compute node.\n",
    "\n",
    "##### **Optional: Copies TACC-compiled OpenSeesPy**\n",
    "\n",
    "If GET_TACC_OPENSEESPY=True, it copies:\n",
    "\n",
    "```\n",
    "OpenSeesPy.so → ./opensees.so\n",
    "```\n",
    "\n",
    "This enables users to import opensees reliably.\n",
    "\n",
    "##### **Chooses launcher**\n",
    "\n",
    "Decides whether to prepend:\n",
    "\n",
    "```\n",
    "ibrun\n",
    "```\n",
    "\n",
    "for MPI jobs.\n",
    "\n",
    "##### **Runs the user script**\n",
    "\n",
    "Executes:\n",
    "\n",
    "```\n",
    "[ibrun] <BINARYNAME> <INPUTSCRIPT> [args]\n",
    "```\n",
    "\n",
    "This is the actual scientific computation.\n",
    "\n",
    "##### **Post-processing**\n",
    "\n",
    "* Removes temporary files\n",
    "* Produces timing logs\n",
    "* Returns to parent directory\n",
    "\n",
    "This script is **what makes the app function**.\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "<details><summary><b><large>4. App ZIP Package — Runtime bundle delivered to the compute node (Required)</large></b><br>Bundles the wrapper script and optional documentation into a portable runtime image</summary>\n",
    "<div style=\"padding-left:30px\">\n",
    "Tapis apps using \"runtime\": \"ZIP\" require a single ZIP file containing:\n",
    "\n",
    "* tapisjob_app.sh\n",
    "* ReadMe.md (optional)\n",
    "* profile.json (optional)\n",
    "* Any helper files\n",
    "\n",
    "This ZIP is stored in a Tapis-accessible storage location:\n",
    "\n",
    "```text\n",
    "tapis://designsafe.storage.default/silvia/apps/<appname>/<version>/<zipfile>\n",
    "```\n",
    "\n",
    "When a job runs, Tapis:\n",
    "\n",
    "1. Copies the ZIP into the job directory\n",
    "2. Unpacks it\n",
    "3. Executes tapisjob_app.sh\n",
    "\n",
    "\n",
    "This ZIP therefore functions like a lightweight container.\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "<details><summary><b><large>5. Input Directory — User-provided model files (User-Provided)</large></b><br>User-provided scripts and data used in the computation  </summary>\n",
    "<div style=\"padding-left:30px\">\n",
    "Each app declares one required:\n",
    "\n",
    "```\n",
    "Input Directory\n",
    "```\n",
    "\n",
    "This directory must contain:\n",
    "\n",
    "* The user’s main script (model.tcl, runOSPy.py, …)\n",
    "* Any supporting input files\n",
    "* Any ZIPs to be expanded\n",
    "* Any requirements files (for Python or modules)\n",
    "\n",
    "At runtime, Tapis stages this directory into:\n",
    "\n",
    "```\n",
    "$JOB_WORKING_DIR/inputDirectory/\n",
    "```\n",
    "\n",
    "Your wrapper script then cds into it before running calculations.\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "<details><summary><b><large>6. README.md — Human-Facing Documentation (Optional but Highly Recommended)</large></b><br>Documentation for human users (optional but recommended)    </summary>\n",
    "<div style=\"padding-left:30px\">\n",
    "Although not required by Tapis, providing a ReadMe.md improves:\n",
    "\n",
    "* Portal usability\n",
    "* Training workflows\n",
    "* Reproducibility\n",
    "* Collaboration\n",
    "\n",
    "It typically includes:\n",
    "\n",
    "* App description\n",
    "* Usage instructions\n",
    "* How to import OpenSeesPy\n",
    "* MPI guidance\n",
    "* Example jobs\n",
    "* Known limitations\n",
    "\n",
    "This file is packaged inside the app ZIP but is not executed.\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "\n",
    "Together, these pieces create a robust, portable, and reproducible HPC application.\n",
    "\n",
    "</div>\n",
    "\n",
    "## How Tapis Apps Run\n",
    "\n",
    "<div style=\"margin-left:25px;padding:10px;border:2px solid lightgray\">\n",
    "    \n",
    "When a job is launched, Tapis performs a simple but powerful sequence:\n",
    "\n",
    "<details><summary><b>1. User submits job </b></summary>\n",
    "    \n",
    "    * inputs parameters + input directory\n",
    "    * via WebPortal, Jupyter Notebook, or CLI\n",
    "    \n",
    "</details>\n",
    "<details><summary><b>2. Tapis validates the job request</b></summary>\n",
    "\n",
    "   * Tapis validates the job request against app.json (arguments, file inputs, environment variables)\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary><b>3. Tapis stages the inputs</b></summary>\n",
    "\n",
    "   * Create the job working directory\n",
    "   * Copy the user’s Input Directory\n",
    "   * Copy the app’s ZIP bundle\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary><b>4. Unpack the ZIP Runtime on the Compute Node</b></summary>\n",
    "\n",
    "   * Extract tapisjob_app.sh\n",
    "   * Make the wrapper script executable\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary><b>5. Submit SLURM Job</b></summary>\n",
    "\n",
    "   * Submit to SLURM: Tapis sends the job request to Stampede3’s SLURM scheduler.\n",
    "   * Using the queue, time limit, and resources defined in app.json\n",
    "</details>\n",
    "\n",
    "<details><summary><b>6. SLURM Job starts</b></summary>\n",
    "\n",
    "SLURM allocates one or more **compute nodes**.\n",
    "   \n",
    "On the first compute node, SLURM runs:\n",
    "\n",
    "   ```bash\n",
    "   ./tapisjob.sh <args>\n",
    "   ```\n",
    "\n",
    "The compute node has a clean environment — it's not the login-node environment.\n",
    "That is why you **must load modules inside the script**, because no modules are pre-loaded.\n",
    "\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary><b>7. Wrapper Script Runs</b></summary>\n",
    "\n",
    "   * tapisjob.sh executes the wrapper script tapisjob_app.sh. It Calls:\n",
    "\n",
    "     ```bash\n",
    "     ./tapisjob_app.sh <MainProgram> <MainScript> <UseMPI> [args...]\n",
    "     ```\n",
    "     \n",
    "   * The wrapper script 'tapisjob_app.sh' is executed **inside the compute-node environment**, not on the login node.\n",
    "   * This script is unique to the app. The Agnostic-App Script does the following:\n",
    "       * Loads modules\n",
    "       * Installs pip packages\n",
    "       * Copies TACC OpenSeesPy if requested\n",
    "       * Chooses MPI or serial launcher\n",
    "       * Calls the main binary file.\n",
    "       * Logs everything\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary><b>8. Output Archiving</b></summary>\n",
    "\n",
    "   * Tapis copies job output into:\n",
    "\n",
    "     ```\n",
    "     $WORK/tapis-jobs-archive/<date>/<jobname>-<UUID>/\n",
    "     ```\n",
    "   * Excludes ZIP files if specified\n",
    "   * Preserves logs for debugging\n",
    "  \n",
    "</details>\n",
    "<details><summary><b>9. Job complete</b></summary>\n",
    "    *  logs & results are now available in the portal\n",
    "</details>\n",
    "\n",
    "\n",
    "**Summary** Tapis lifecycle: **stage → unpack → run → archive**.\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "## Tapis as a Platform: Task-Specific and General Apps\n",
    "\n",
    "<div style=\"margin-left:25px;padding:10px;border:2px solid lightgray\">\n",
    "    \n",
    "By combining:\n",
    "\n",
    "* Domain-specific blocks (like OpenSees/OpenSeesPy),\n",
    "* Python environment management,\n",
    "* And generic HPC/Tapis helpers,\n",
    "\n",
    "this notebook demonstrates the **power and versatility of Tapis** as a platform:\n",
    "\n",
    "* You can build **highly task-specific apps** (e.g., a particular OpenSeesPy workflow for a research project).\n",
    "* You can also build **general-purpose apps** (e.g., a generic Python post-processing wrapper) that others in the TACC/DesignSafe community can reuse.\n",
    "\n",
    "Because the logic, documentation, and configuration live together in a **single notebook-driven source**, it’s easier to:\n",
    "\n",
    "* Share apps,\n",
    "* Iterate on them,\n",
    "* And improve our collective **institutional knowledge** about running complex workflows on shared HPC infrastructure.\n",
    "\n",
    "---\n",
    "## Tapis Documentation Resources\n",
    "\n",
    "<div style=\"margin-left:25px;padding:10px;border:2px solid lightgray\">\n",
    "    \n",
    "https://tapis.readthedocs.io/en/latest/technical/apps.html\n",
    "\n",
    "https://tapis-project.github.io/live-docs/?service=Apps\n",
    "\n",
    "https://github.com/tapis-project/tapipy/blob/main/tapipy/resources/openapi_v3-apps.yml\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agnostic-App Features\n",
    "<div style=\"margin-left:25px;padding:10px;border:2px solid lightgray\">\n",
    "   \n",
    "The Agnostic app is designed to be reusable, adaptable, and extensible. This is achieved by including packaged features that can be included or excluded in future apps.\n",
    "\n",
    "- The app-specific execution logic is defined in ***tapisjob_app.sh***\n",
    "- The user-facing inputs and defaults are defined in ***app.json***\n",
    "\n",
    "Each feature in the wrapper is **modular, optional, and controlled by environment variables or app inputs**. Features are organized by *why they exist* (design intent), not just by what they do.\n",
    "\n",
    "---\n",
    "\n",
    "**0. “Feature Families” (Design Intent)**\n",
    "\n",
    "<div style=\"padding-left:30px\">\n",
    "\n",
    "<details><summary><b>Observability & Debugging</b></summary>\n",
    "   - make jobs explainable without reruns\n",
    "   - make support/debugging possible from logs alone\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary><b>Safe File Staging</b></summary>\n",
    "   - support copy-in and bundles without creating archive mess\n",
    "   - avoid accidental deletion or path hazards\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary><b>Environment Construction</b></summary>\n",
    "   - deterministic module loading\n",
    "   - robust Python behavior (*python* vs *python3*)\n",
    "   - reproducible pip installs\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary><b>Execution Semantics</b></summary>\n",
    "   - explicit MPI vs non-MPI launch choice\n",
    "   - binary-aware defaults (OpenSees vs Python)\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary><b>Extensibility Hooks</b></summary>\n",
    "   - user-controlled pre/post steps without modifying the wrapper\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary><b>Output Strategy</b></summary>\n",
    "   - optional zip repacking\n",
    "   - optional in-system moves to WORK/SCRATCH for performance\n",
    "</details>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "**1. Observability & Debugging**\n",
    "\n",
    "<div style=\"padding-left:30px\">\n",
    "\n",
    "<details><summary><b>1.1 Summary Logging (*SUMMARY_SHORT*)</b>\n",
    "The app writes a compact human-focused summary log (default: *SLURM-job-summary.log*) pinned to the original SLURM script root directory.</summary>\n",
    "\n",
    "It records:\n",
    "- App id/version/description\n",
    "- System paths (*HOME*, *WORK*, *SCRATCH*)\n",
    "- User configuration:\n",
    "  - *JobUUID*, *inputDirectory*, *INPUTSCRIPT*, *UseMPI*, *BINARYNAME*, argument list\n",
    "- Feature flags and env variables:\n",
    "  - module/pip inputs, copy/unzip inputs, hooks, output controls\n",
    "- launcher selection (MPI vs direct)\n",
    "- runtime timers (run-only + total)\n",
    "\n",
    "This is the *first* file to read when anything goes wrong.\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary><b>1.2 Full Environment Logging (*FULL_ENV_LOG*)</b>\n",
    "The wrapper also writes a verbose environment dump (*SLURM-full-environment.log*) containing *env | sort*.</summary>\n",
    "\n",
    "Use cases:\n",
    "- module conflicts\n",
    "- path ordering surprises\n",
    "- MPI/runtime environment differences between jobs\n",
    "\n",
    "</details>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "**2. Safe File Staging**\n",
    "\n",
    "<div style=\"padding-left:30px\">\n",
    "\n",
    "<details><summary><b>2.1 Directory discipline: Script root vs Input Directory</b></summary>\n",
    "The wrapper separates:\n",
    "- ***SCRIPT_ROOT_DIR***: where the SLURM job starts\n",
    "- ***inputDirectory***: where user files are staged (and where execution happens)\n",
    "\n",
    "It *cd*s into *inputDirectory* for execution, then returns to script root for packaging/moves.\n",
    "This prevents a common class of mistakes where “global” actions run in the wrong directory.\n",
    "\n",
    "</details>\n",
    "<details><summary><b>2.2 Copy-in staging (*PATH_COPY_IN_LIST*)</b></summary>\n",
    "Optional staging of external paths (WORK/SCRATCH/HOME) into the working directory using *rsync -av*.\n",
    "\n",
    "Why this exists:\n",
    "- keep the Input Directory small\n",
    "- reuse shared datasets\n",
    "- create a runtime layout without hard-coding absolute paths inside scripts\n",
    "\n",
    "</details>\n",
    "<details><summary><b>2.3 Copy-in cleanup (*DELETE_COPIED_IN_ON_EXIT*) — manifest-driven + safe</b></summary>\n",
    "When enabled, the wrapper:\n",
    "- records what was copied in a manifest\n",
    "- uses a Bash *EXIT* trap to cleanup (success or failure)\n",
    "- deletes **only** the manifest-listed items\n",
    "- rejects unsafe paths (absolute paths, *..* traversal)\n",
    "- logs each deletion\n",
    "\n",
    "This allows “temporary convenience inputs” without polluting the final archive.\n",
    "\n",
    "</details>\n",
    "<details><summary><b>2.4 ZIP expansion (*UNZIP_FILES_LIST*)</b>\n",
    "Optional unzip of one or more ZIP bundles staged in the Input Directory.</summary>\n",
    "- supports names with or without *.zip*\n",
    "- quiet unzip (*unzip -o -q*)\n",
    "- logs missing zips as warnings\n",
    "\n",
    "Use this when you bundle many small files into a single upload artifact.\n",
    "\n",
    "</details>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "**3. Environment Construction**\n",
    "\n",
    "<div style=\"padding-left:30px\">\n",
    "\n",
    "<details><summary><b>3.1 Defensive *module* initialization</b></summary>\n",
    "If *module* is not on PATH, the wrapper sources */etc/profile.d/modules.sh* (when present).\n",
    "This prevents jobs from failing on minimal profiles like *tacc-no-modules*.\n",
    "\n",
    "</details>\n",
    "<details><summary><b>3.2 Module loading: file + list (both supported)</b></summary>\n",
    "Two mechanisms (can be used together):\n",
    "\n",
    "- *MODULE_LOADS_FILE*:\n",
    "  - supports *purge*, *use <path>*, *load <module>*, *?optional*, and bare module names\n",
    "  - best for version-controlled, documented module stacks\n",
    "\n",
    "- *MODULE_LOADS_LIST*:\n",
    "  - comma-separated list\n",
    "  - best for quick one-offs\n",
    "\n",
    "</details>\n",
    "<details><summary><b>3.3 Python normalization (newer behavior)</b>\n",
    "Even on HPC systems, *python* and *python3* can resolve to different interpreters.</summary>\n",
    "To remove ambiguity, the wrapper:\n",
    "\n",
    "- normalizes any python-ish *BINARYNAME* to *python3*\n",
    "- injects a PATH shim so *python* executes *python3*\n",
    "- (optionally) shims *pip* → *pip3*\n",
    "- logs *command -v python/python3* and versions\n",
    "\n",
    "This prevents “works on my node” failures caused by hidden interpreter drift.\n",
    "\n",
    "</details>\n",
    "<details><summary><b>3.4 Python package installs: file + list</b></summary>\n",
    "Two mechanisms (can be used together):\n",
    "\n",
    "- *PIP_INSTALLS_FILE*: *pip3 install -r <file>*\n",
    "- *PIP_INSTALLS_LIST*: per-package *pip3 install <pkg>*\n",
    "\n",
    "Both are *fail-fast*: pip errors stop the job with clear logging.\n",
    "\n",
    "</details>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "**4. OpenSees-specific features**\n",
    "\n",
    "<div style=\"padding-left:30px\">\n",
    "\n",
    "<details><summary><b>4.1 Default OpenSees Tcl module loads</b></summary>\n",
    "If *BINARYNAME* is *OpenSees*, *OpenSeesMP*, or *OpenSeesSP*, the wrapper loads:\n",
    "- *hdf5/1.14.4*\n",
    "- *opensees*\n",
    "\n",
    "This is a “binary-aware default” so users don’t have to remember module boilerplate.\n",
    "\n",
    "</details>\n",
    "<details><summary><b>4.2 OpenSeesPy injection (*GET_TACC_OPENSEESPY*)</b></summary>\n",
    "If enabled, the wrapper:\n",
    "- loads *python/3.12.11*, *hdf5/1.14.4*, *opensees*\n",
    "- copies *${TACC_OPENSEES_BIN}/OpenSeesPy.so* to *./opensees.so*\n",
    "- removes *./opensees.so* after the run\n",
    "\n",
    "This is the recommended OpenSeesPy path on Stampede3 (more robust than PyPI wheels).\n",
    "\n",
    "</details>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "**5. Extensibility hooks**\n",
    "\n",
    "<div style=\"padding-left:30px\">\n",
    "\n",
    "<details><summary><b>5.1 Pre-job hook (*PRE_JOB_SCRIPT*)</b>\n",
    "Runs *after* environment construction but *before* the main executable.</summary>\n",
    "- relative paths resolved as './< script >' inside the Input Directory\n",
    "- executable runs directly; otherwise runs via *bash*\n",
    "\n",
    "Default policy: warnings on failure, continue job (policy is intentionally permissive for experimentation).\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary><b>5.2 Post-job hook (*POST_JOB_SCRIPT*)</b>\n",
    "Runs after the main executable with the same resolution and execution rules.</summary>\n",
    "\n",
    "Typical uses:\n",
    "- post-processing\n",
    "- summarizing results\n",
    "- moving/organizing additional artifacts\n",
    "- light cleanup\n",
    "\n",
    "</details>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "**6. Execution semantics: launcher choice**\n",
    "\n",
    "<div style=\"padding-left:30px\">\n",
    "\n",
    "<details><summary><b>6.1 Sequential vs MPI (*UseMPI*)</b></summary>\n",
    "The wrapper selects:\n",
    "- direct run if *UseMPI* is false-like\n",
    "- *ibrun* if *UseMPI* is true-like\n",
    "\n",
    "It logs the decision and the final command line.\n",
    "\n",
    "This keeps MPI explicit and prevents “accidental MPI” jobs.\n",
    "\n",
    "</details>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "**7. Output strategy**\n",
    "\n",
    "<div style=\"padding-left:30px\">\n",
    "\n",
    "<details><summary><b>7.1 Optional repack to ZIP (*ZIP_OUTPUT_SWITCH*)</b></summary>\n",
    "If enabled, the wrapper:\n",
    "- zips the entire Input Directory into *inputDirectory.zip*\n",
    "- deletes the original directory tree\n",
    "\n",
    "This reduces file counts and makes transfers more efficient.\n",
    "\n",
    "</details>\n",
    "<details><summary><b>7.2 Optional in-system output move (*PATH_MOVE_OUTPUT*)</b></summary>\n",
    "If set, the wrapper:\n",
    "- creates *<PATH_MOVE_OUTPUT>/_<JobUUID>/*\n",
    "- moves the primary archive there\n",
    "- copies top-level job logs there too\n",
    "\n",
    "This is a performance feature:\n",
    "- move to **WORK** for interactive inspection in JupyterHub\n",
    "- move to **SCRATCH** for chained HPC workflows\n",
    "\n",
    "</details>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "**8. Practical guidance: mapping features to inputs**\n",
    "\n",
    "<div style=\"padding-left:30px\">\n",
    "\n",
    "<details><summary><b>If you want a simple “mental model”:</b></summary>\n",
    "\n",
    "- **Make the run work**:\n",
    "  - set *Main Program*, *Main Script*, *UseMPI*\n",
    "- **Make the environment correct**:\n",
    "  - use *MODULE_LOADS_FILE* / *MODULE_LOADS_LIST*\n",
    "  - use *PIP_INSTALLS_FILE* / *PIP_INSTALLS_LIST*\n",
    "  - enable *GET_TACC_OPENSEESPY* when using OpenSeesPy\n",
    "- **Make inputs available**:\n",
    "  - use *UNZIP_FILES_LIST* for bundles\n",
    "  - use *PATH_COPY_IN_LIST* for external datasets\n",
    "  - enable *DELETE_COPIED_IN_ON_EXIT* if copy-ins are temporary\n",
    "- **Make results usable**:\n",
    "  - use *ZIP_OUTPUT_SWITCH* for large file trees\n",
    "  - use *PATH_MOVE_OUTPUT* to land outputs in WORK/SCRATCH quickly\n",
    "</details>\n",
    "</div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Note on Python Environments: Limitations and Practical Tradeoffs\n",
    "<div style=\"margin-left:25px;padding:10px;border:2px solid lightgray\">\n",
    "    \n",
    "One important limitation of the agnostic app’s Python support is that it **relies on an existing system-level Python environment**, rather than creating or managing a fully user-defined virtual environment by default. While the app *can* be extended to support user-provided virtual environments, this is intentionally not part of the core workflow, because Python environments are something that should ideally be **set up once, tested thoroughly, and reused**, not rebuilt on every job.\n",
    "\n",
    "### Why Not Build a Virtual Environment Inside the App?\n",
    "\n",
    "Creating or activating a custom virtual environment at runtime adds complexity and cost:\n",
    "\n",
    "* Environment creation is slow and would happen **for every job**, which is wasteful.\n",
    "* Environment reproducibility becomes harder unless carefully pinned.\n",
    "* Python’s open-source ecosystem has many interdependencies, which means **configuration issues can arise frequently**, especially in HPC environments where multiple compiler and MPI stacks coexist.\n",
    "\n",
    "For these reasons, the recommended practice is:\n",
    "\n",
    "* **If you need a custom, long-lived Python environment**, create it once in '$WORK' or a similar persistent location and build a separate, dedicated Tapis app that activates that environment.\n",
    "  This isolates environment management from job execution and avoids rebuilding environments every time.\n",
    "\n",
    "### Why Provide 'PIP_INSTALLS_FILE' and 'PIP_INSTALLS_LIST'?\n",
    "\n",
    "Even though installing packages at runtime is not ideal performance-wise, we included these options because:\n",
    "\n",
    "* They allow lightweight customization **without requiring a separate environment-management app**.\n",
    "* They help maintain portability and reduce user burden—no need to manage a Python venv manually.\n",
    "* The small extra setup time is usually negligible compared to TACC job runtimes.\n",
    "* The convenience and reliability of installing a few packages at submission time **outweigh the risks** of depending on stale or incompatible environments.\n",
    "\n",
    "### But Beware: Python Is Flexible *and* Fragile\n",
    "\n",
    "Python’s strength—its huge open-source ecosystem—is also the source of occasional instability:\n",
    "\n",
    "* Packages may depend on different compiler toolchains, MPI bindings, or C libraries.\n",
    "* Minor version changes can break expected behaviors.\n",
    "* System environments may differ subtly between compute nodes and login nodes.\n",
    "\n",
    "Because of this, our philosophy in the agnostic app is:\n",
    "\n",
    "> **Keep the Python layer as simple, minimal, and controllable as possible.\n",
    "> Add only the packages you need, and prefer stable, TACC-supported modules whenever available.**\n",
    "\n",
    "You **can** add a user-defined virtual environment to your workflow later, but it should be handled intentionally—preferably in a separate, specialized app designed just for environment creation and maintenance.\n",
    "\n",
    "This approach keeps the agnostic app robust, portable, and predictable while still giving users enough flexibility to extend Python functionality when needed.\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tapis-App-Development Workflow\n",
    "<div style=\"margin-left:25px;padding:10px;border:2px solid lightgray\">\n",
    "    \n",
    "This notebook automates the full lifecycle of creating, deploying, and testing **two Tapis v3 Apps**:\n",
    "\n",
    "- designsafe-agnostic-app (general-purpose)\n",
    "- designsafe-openseespy-s3 (OpenSeesPy-only)\n",
    "\n",
    "Below is a detailed breakdown of each step in the workflow. *(Click on each header to expand)*\n",
    "\n",
    "\n",
    "<details><summary><b><large>0. Connect to Tapis</large></b><br>You need to authenticate (TACC/DesignSafe Username and password) and get a token</summary>\n",
    "    <div style=\"padding-left:30px\">\n",
    "Before anything else, you must authenticate with the Tapis v3 API so you can:\n",
    "- upload files,\n",
    "- register apps,\n",
    "- modify permissions,\n",
    "- and submit jobs.\n",
    "\n",
    "In this step, we:\n",
    "- load API credentials (client ID/secret)  \n",
    "- request an OAuth2 token  \n",
    "- create a Python tapis client object  \n",
    "- confirm access to the execution system (stampede3) and the storage system (designsafe.storage.default)\n",
    "\n",
    "This step must succeed before any of the subsequent steps are attempted.\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary><b><large>1. Create app.json</large></b><br>Describes the app, its inputs, execution system, and wrapper script</summary>\n",
    "    <div style=\"padding-left:30px\">\n",
    "The **app definition file** is the heart of every Tapis app.\n",
    "\n",
    "It contains:\n",
    "- app name, version, and description  \n",
    "- which execution system to use  \n",
    "- what queue, how many nodes/cores, time limits  \n",
    "- what runtime type to use (ZIP, Docker, etc.)  \n",
    "- what inputs the user must supply  \n",
    "- environment variables that control runtime behavior  \n",
    "- how to archive results after job completion  \n",
    "\n",
    "In this step, the notebook programmatically builds two JSON objects:\n",
    "1. **Agnostic app**: full-featured, configurable  \n",
    "2. **OpenSeesPy app**: reduced-scope, simplified interface  \n",
    "\n",
    "These JSON objects are saved as:\n",
    "- app.json for the agnostic app  \n",
    "- openseespy-app.json for the reduced-scope one  \n",
    "</div>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary><b><large>2. Create tapisjob_app.sh</large></b><br>Runs your analysis (e.g., ibrun OpenSees main.tcl)   </summary>\n",
    "    <div style=\"padding-left:30px\">\n",
    "This is the **wrapper script** that runs *inside the HPC job*.\n",
    "\n",
    "It performs all runtime logic:\n",
    "- prints app info and job UUID  \n",
    "- changes into the input directory  \n",
    "- loads required TACC modules  \n",
    "- (optionally) copies TACC-compiled OpenSeesPy (opensees.so)  \n",
    "- installs Python packages  \n",
    "- chooses an MPI launcher (ibrun) when appropriate  \n",
    "- executes the user’s script  \n",
    "- logs timing, environment summaries, and success/failure  \n",
    "- optionally zips the output and/or moves results to WORK/HOME/SCRATCH  \n",
    "- cleans up temporary files  \n",
    "\n",
    "The agnostic app uses a longer, more capable script.  \n",
    "The OpenSeesPy app uses a simplified variant with reduced features.\n",
    "\n",
    "The notebook writes both scripts to disk for packaging.\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary><b><large>2a. Zip the App</large></b><br>This app is a ZIP-runtime app  (see app.json)</summary>\n",
    "    <div style=\"padding-left:30px\">\n",
    "Since this is a **ZIP runtime** app, Tapis requires a .zip archive containing:\n",
    "- the tapisjob_app.sh file (required)  \n",
    "- optional documentation files (ReadMe.md)  \n",
    "- optional supporting scripts  \n",
    "\n",
    "The notebook automatically:\n",
    "- zips the bundle  \n",
    "- saves it with a versioned name, e.g.  \n",
    "  - designsafe-agnostic-app.zip  \n",
    "  - designsafe-openseespy-s3.zip  \n",
    "\n",
    "This ZIP file becomes the app’s **containerImage** in app.json.\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary><b><large>3. Create profile.json (Optional)</large></b><br>(Optional) Loads modules/environment -- use an existing one or define a new profile</summary>\n",
    "    <div style=\"padding-left:30px\">\n",
    "Most apps rely on a scheduler profile to control:\n",
    "- module behavior  \n",
    "- environment setup  \n",
    "- SLURM initialization  \n",
    "\n",
    "In this case, both apps use:\n",
    "\n",
    "```bash\n",
    "--tapis-profile tacc-no-modules\n",
    "```\n",
    "\n",
    "This means:\n",
    "\n",
    "* TACC loads **no modules by default**\n",
    "* The wrapper script is responsible for loading Python, OpenSees, HDF5, etc.\n",
    "\n",
    "If a custom profile were needed, the notebook would generate it here.\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary><b><large>4. Create ReadMe.md</large></b><br>Instructions for the app user </summary>\n",
    "<div style=\"padding-left:30px\">\n",
    "\n",
    "A user-facing markdown file is automatically generated for each app.\n",
    "\n",
    "It includes:\n",
    "\n",
    "* what the app does\n",
    "* what parameters it expects\n",
    "* how to use it on DesignSafe\n",
    "* how to import OpenSeesPy correctly\n",
    "* examples for both serial and MPI usage\n",
    "\n",
    "These files are included in the app ZIP bundle.\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "    \n",
    "* The notebook validates this JSON, ensuring it’s syntactically correct and consistent with the script.\n",
    "\n",
    "\n",
    "\n",
    "<details><summary><b><large>5. Upload Files to Storage</large></b><br>To the deployment path in your storage system   </summary>\n",
    "<div style=\"padding-left:30px\">\n",
    "Next, you upload:\n",
    "\n",
    "* the ZIP archive\n",
    "* the app JSON\n",
    "* the ReadMe\n",
    "\n",
    "to a designated deployment folder such as:\n",
    "\n",
    "```\n",
    "designsafe.storage.default:/silvia/apps/designsafe-agnostic-app/<version>/\n",
    "```\n",
    "\n",
    "Tapis retrieves these files at runtime, so they must be readable.\n",
    "\n",
    "The notebook performs this upload automatically using the Python client.\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "<details><summary><b><large>6. Register the App with Tapis</large></b><br>With Tapis via CLI or Python    </summary>\n",
    "<div style=\"padding-left:30px\">\n",
    "You call:\n",
    "\n",
    "```python\n",
    "client.apps.createAppVersion(...)\n",
    "```\n",
    "\n",
    "or, if updating:\n",
    "\n",
    "```python\n",
    "client.apps.patchAppVersion(...)\n",
    "```\n",
    "\n",
    "At this step, the app becomes visible in:\n",
    "\n",
    "* the DesignSafe “My Apps” list,\n",
    "* the Tapis apps registry.\n",
    "\n",
    "The notebook registers:\n",
    "\n",
    "* the agnostic app version\n",
    "* the OpenSeesPy-only app version\n",
    "\n",
    "Both apps are immediately usable after registration.\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary><b><large>7. Make/Unmake App Public (Optional)</large></b><br>Make or unmake the app usable to others on TACC (optional)</summary>\n",
    "<div style=\"padding-left:30px\">\n",
    "If desired, we can make the apps publicly usable on Stampede3:\n",
    "\n",
    "```python\n",
    "client.apps.grantRole(...)\n",
    "```\n",
    "\n",
    "This step is optional.\n",
    "Personal apps only need permissions for your user account.\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary><b><large>8. Set File Permissions</large></b><br>If the app is public, make the app files accessible to others</summary>\n",
    "<div style=\"padding-left:30px\">\n",
    "If the app is made public, the underlying ZIP files must also be made world-readable so other users can launch them.\n",
    "\n",
    "The notebook includes helper commands to apply the correct:\n",
    "\n",
    "* chmod\n",
    "* Tapis files.setPermissions\n",
    "\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "This notebook teaches both:\n",
    "\n",
    "* **how to build general-purpose HPC apps**, and\n",
    "* **how to package simplified “easy button” apps** for portal users.\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Tapis App Public\n",
    "\n",
    "<div style=\"margin-left:25px;padding:10px;border:2px solid lightgray\">\n",
    "    \n",
    "You make a Tapis app public when you want **other users—any DesignSafe or TACC user—to run your app directly**, without needing you to share it privately. A public app:\n",
    "\n",
    "* Appears in other users’ 'apps' listings.\n",
    "* Can be executed by anyone with access to the execution system.\n",
    "* Can be launched through the **DesignSafe Web Portal** by navigating to:\n",
    "  **'https://www.designsafe-ci.org/workspace/<appname>'**\n",
    "  (once your app is public and indexed).\n",
    "\n",
    "To make an app truly public, you must complete **both**:\n",
    "\n",
    "(1) mark the app public in Tapis using Tapipy, and\n",
    "\n",
    "(2) ensure your app files are readable on the filesystem.\n",
    "\n",
    "---\n",
    "\n",
    "<details><summary><b>1. Choose a Public-Friendly Location for 'appPath_Tapis'</b></summary>\n",
    "<div style=\"padding-left:30px\">\n",
    "If the app is intended to be public:\n",
    "\n",
    "* Place 'appPath_Tapis' in an HPC directory readable by all TACC users, typically '$WORK' on Stampede3.\n",
    "* This ensures Tapis—and any user who wants to download or reference your '.zip'—can access it.\n",
    "\n",
    "Even for private apps, '$WORK' is recommended because copying from '$WORK' to the execution directory is fast and reliable.\n",
    "\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "<details><summary><b>2. Mark the App Public Using **Tapipy**</b></summary>\n",
    "<div style=\"padding-left:30px\">\n",
    "With Tapipy, “public” is controlled by **sharing the app with the special “public” role**.\n",
    "\n",
    "* **Share the App Publicly**\n",
    "\n",
    "```python\n",
    "from tapipy.tapis import Tapis\n",
    "\n",
    "t = Tapis(base_url=<BASE_URL>, username=<USER>, password=<PASSWORD>)\n",
    "t.apps.share_app_public(appId=\"APP_ID\", appVersion=\"VERSION\")\n",
    "```\n",
    "\n",
    "* **Unshare (Make Private Again)**\n",
    "\n",
    "```python\n",
    "t.apps.unshare_app_public(appId=\"APP_ID\", appVersion=\"VERSION\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "<details><summary><b>3. Verify That the App Is Public</b></summary>\n",
    "<div style=\"padding-left:30px\">\n",
    "Use Tapipy to retrieve the latest version and inspect the 'isPublic' field:\n",
    "\n",
    "```python\n",
    "app = t.apps.getAppLatestVersion(appId=\"APP_ID\")\n",
    "print(app.isPublic)\n",
    "```\n",
    "\n",
    "A correct public app will show:\n",
    "\n",
    "```\n",
    "True\n",
    "```\n",
    "\n",
    "If 'False', your app is not public yet—even if permissions are correct.\n",
    "\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "<details><summary><b>4. Ensure Filesystem Permissions Allow Public Access</b></summary>\n",
    "<div style=\"padding-left:30px\">\n",
    "Making an app “public” in Tapis does **not** bypass Unix file permissions.\n",
    "Other users—and Tapis itself when executing the app—must have:\n",
    "\n",
    "* **Read access** to the '.zip' file\n",
    "* **Execute (traverse) permission** on every directory in the path\n",
    "\n",
    "**4.1. Make the App Bundle Readable**\n",
    "\n",
    "**bash:**\n",
    "\n",
    "```bash\n",
    "chmod go+r yourfile.zip\n",
    "```\n",
    "\n",
    "**Python:**\n",
    "\n",
    "```python\n",
    "import os, stat\n",
    "\n",
    "path = \"yourfile.zip\"\n",
    "st = os.stat(path)\n",
    "file_perms = stat.S_IRGRP | stat.S_IROTH  # group + others read\n",
    "os.chmod(path, st.st_mode | file_perms)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**4.2. Ensure All Directories Are Traversable**\n",
    "\n",
    "Directories must have '+x' for group and others:\n",
    "\n",
    "**bash:**\n",
    "\n",
    "```bash\n",
    "chmod go+x /work2/groupID/username\n",
    "chmod go+x /work2/groupID/username/system\n",
    "chmod go+x /work2/groupID/username/system/apps\n",
    "chmod go+x /work2/groupID/username/system/apps/app_name\n",
    "chmod go+x /work2/groupID/username/system/apps/app_name/app_version\n",
    "```\n",
    "\n",
    "**Python:**\n",
    "\n",
    "```python\n",
    "import os, stat\n",
    "\n",
    "dir_perms = stat.S_IXGRP | stat.S_IXOTH  # group + others execute\n",
    "\n",
    "dirs = [\n",
    "    \"/work2/groupID/username\",\n",
    "    \"/work2/groupID/username/system\",\n",
    "    \"/work2/groupID/username/system/apps\",\n",
    "    \"/work2/groupID/username/system/apps/app_name\",\n",
    "    \"/work2/groupID/username/system/apps/app_name/app_version\",\n",
    "]\n",
    "\n",
    "for d in dirs:\n",
    "    st = os.stat(d)\n",
    "    os.chmod(d, st.st_mode | dir_perms)\n",
    "```\n",
    "\n",
    "> **Note:** '/work2' on Stampede3 is *not* world-readable by default, so setting traversal permissions is required.\n",
    "\n",
    "Because 'os.chmod()' uses 'st.st_mode | perms':\n",
    "\n",
    "* Your own permissions remain unchanged.\n",
    "* We only **add** missing group/other bits.\n",
    "* Apply permissions **after** copying all app files.\n",
    "\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "--- \n",
    "\n",
    "**Summary Checklist for Public Tapis Apps**\n",
    "\n",
    "| Requirement                                        | Completed By                   |\n",
    "| -------------------------------------------------- | ------------------------------ |\n",
    "| App bundle in a readable shared location ('$WORK') | You                            |\n",
    "| App marked public                                  | 't.apps.share_app_public(...)' |\n",
    "| Verified '\"isPublic\": true'                        | 't.apps.getAppLatestVersion()' |\n",
    "| File readable by group/others                      | 'chmod go+r'                   |\n",
    "| Directories traversable by group/others            | 'chmod go+x'                   |\n",
    "| App available in DesignSafe Web Portal             | Automatic once public          |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<details><summary><b>Troubleshooting: “My Public App Still Doesn’t Work”</b></summary>\n",
    "<div style=\"padding-left:30px\">\n",
    "Even after setting 'isPublic = true' and fixing permissions, you may find that:\n",
    "\n",
    "* Other users can’t see or run your app.\n",
    "* The DesignSafe Web Portal can’t load it at\n",
    "  'https://www.designsafe-ci.org/workspace/<appname>'.\n",
    "* Jobs fail because the app bundle can’t be read.\n",
    "\n",
    "Below are the most common causes and quick checks.\n",
    "\n",
    "---\n",
    "\n",
    "**1. The App Isn’t Actually Public**\n",
    "\n",
    "**Symptom:** Other users can’t see the app in their listings or launch it from the portal.\n",
    "\n",
    "**Check with Tapipy:**\n",
    "\n",
    "```python\n",
    "app = t.apps.getAppLatestVersion(appId=\"APP_ID\")\n",
    "print(app.isPublic)\n",
    "```\n",
    "\n",
    "* If this prints 'False', you haven’t successfully shared it.\n",
    "\n",
    "**Fix:**\n",
    "\n",
    "```python\n",
    "t.apps.share_app_public(appId=\"APP_ID\", appVersion=\"VERSION\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**2. Wrong 'appId' or 'appVersion'**\n",
    "\n",
    "**Symptom:** You shared one version, but users (or the portal) are trying to use another.\n",
    "\n",
    "**Check all versions:**\n",
    "\n",
    "```python\n",
    "apps = t.apps.getApps(appId=\"APP_ID\")\n",
    "for a in apps:\n",
    "    print(a.id, a.version, a.isPublic)\n",
    "```\n",
    "\n",
    "**Fix:**\n",
    "\n",
    "* Make sure the version you intend to expose is the one with 'isPublic = True'.\n",
    "* Share that specific version:\n",
    "\n",
    "  ```python\n",
    "  t.apps.share_app_public(appId=\"APP_ID\", appVersion=\"INTENDED_VERSION\")\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "**3. File Permissions Still Too Tight**\n",
    "\n",
    "**Symptom:** Users see the app, but jobs fail with errors about missing or unreadable files, or they can’t copy the '.zip'.\n",
    "\n",
    "**Checklist:**\n",
    "\n",
    "* App bundle is **readable** by group + others:\n",
    "\n",
    "  ```bash\n",
    "  chmod go+r yourfile.zip\n",
    "  ```\n",
    "\n",
    "* All directories in the path are **traversable** ('+x') by group + others:\n",
    "\n",
    "  ```bash\n",
    "  chmod go+x /work2/groupID/username\n",
    "  chmod go+x /work2/groupID/username/system\n",
    "  chmod go+x /work2/groupID/username/system/apps\n",
    "  chmod go+x /work2/groupID/username/system/apps/app_name\n",
    "  chmod go+x /work2/groupID/username/system/apps/app_name/app_version\n",
    "  ```\n",
    "\n",
    "**If in doubt:**\n",
    "Have another user run 'ls yourfile.zip' and 'ls' each directory in the path. If they can’t traverse or see it, permissions are still too restricted.\n",
    "\n",
    "---\n",
    "\n",
    "**4. 'appPath_Tapis' or Archive Path Doesn’t Match Reality**\n",
    "\n",
    "**Symptom:** The app is public and permissions look correct, but Tapis can’t find or unpack the '.zip' when a job starts.\n",
    "\n",
    "**Things to check in your app definition (JSON):**\n",
    "\n",
    "* 'archiveSystem' / 'execSystemId': point to the correct system (e.g., Stampede3).\n",
    "* 'appPath_Tapis' (or whatever you call the directory): matches the **actual directory** on the system.\n",
    "* 'appArchivePath' (or similar field): matches the **actual filename** (including subdirectories if used).\n",
    "\n",
    "If you moved the '.zip' after creating the app, or changed directory names, you must update the app definition and re-register it.\n",
    "\n",
    "---\n",
    "\n",
    "**5. DesignSafe Web Portal Not Showing Updates Yet**\n",
    "\n",
    "**Symptom:** 'isPublic = true' and the app works via Tapipy/CLI, but\n",
    "'https://www.designsafe-ci.org/workspace/<appname>' isn’t showing or launching the latest version.\n",
    "\n",
    "**Quick checks:**\n",
    "\n",
    "1. Confirm 'isPublic' on the intended version:\n",
    "\n",
    "   ```python\n",
    "   app = t.apps.getAppLatestVersion(appId=\"APP_ID\")\n",
    "   print(app.id, app.version, app.isPublic)\n",
    "   ```\n",
    "\n",
    "2. Make sure 'appId' matches the name the portal expects (case, hyphens, etc.).\n",
    "\n",
    "3. If you recently changed 'isPublic' or app metadata, give the portal a little time to refresh its index, or log out / back in and try again.\n",
    "\n",
    "If it still doesn’t appear after a reasonable delay, verify everything else in this checklist, then contact DesignSafe support with the 'appId' and 'version'.\n",
    "\n",
    "---\n",
    "\n",
    "**6. Users Don’t Have Access to the Execution System**\n",
    "\n",
    "**Symptom:** App appears in listings, but when users try to run it, they get authorization or system-access errors.\n",
    "\n",
    "**Check:**\n",
    "\n",
    "* Which 'execSystemId' the app uses (e.g., Stampede3).\n",
    "* Whether the other user has:\n",
    "\n",
    "  * An active allocation / account on that system.\n",
    "  * Proper onboarding (e.g., they can log in or submit other jobs there).\n",
    "\n",
    "If they don’t have access to the execution system, they won’t be able to run your app, even if it’s public.\n",
    "\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary><b>Resource on Making App Public</b></summary>\n",
    "    <div style=\"padding-left:30px\">\n",
    "https://tapis-project.github.io/live-docs/?service=Apps#tag/Sharing/operation/shareAppPublic\n",
    "\n",
    "https://github.com/tapis-project/tapipy/blob/main/tapipy/resources/openapi_v3-apps.yml\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Workflow\n",
    "\n",
    "<details>\n",
    "    <summary>Outline</summary>\n",
    "    <div style=\"margin-left:25px;padding:10px;border:2px solid lightgray\">\n",
    "    <b>NOTE:</b> <i>The following outline may be missing a few steps that may have been added later in development</i>\n",
    "    \n",
    "    ```\n",
    "    # Initialize Process\n",
    "    ## Initialize Python Environment\n",
    "    ### Load Specialized Utilities Library\n",
    "    ## Set Process-Control Switches\n",
    "    ### Make-App Switches\n",
    "    ### Test-App Switches\n",
    "    ### Make-Public Switches\n",
    "    ## Set App-Author Info\n",
    "    ## Set Execution-System\n",
    "    ## Set App Path for Development\n",
    "    ## Set App Path for Deployment\n",
    "    ## Get Today's Date\n",
    "    # Connect to Tapis\n",
    "    ## Get username\n",
    "    ## Get User- and Execution-System-Specific Work Paths\n",
    "    ### Work Path in the HPC System\n",
    "    ### Work Path in the JupyterHub System\n",
    "    # Configure App\n",
    "    ## Set App ID Data\n",
    "    ### Set Update Type\n",
    "    ## Set App Version\n",
    "    ## Set File Locations\n",
    "    ### Set appPath_Local\n",
    "    ### Set appPath_Tapis\n",
    "    # Create the App Files\n",
    "    ## A. Create **Readme.MD** – App User Documentation\n",
    "    ## B. Create/Select **profile.json** – Environment Setup\n",
    "    ## C. Create **app.json** – App Definition\n",
    "    ## D. Create **tapisjob_app.sh** – Wrapper Script\n",
    "    ### 0. Script initialization: safety flags, required args, and global context\n",
    "    ### 1a. Summary log setup\n",
    "    ### 1b. Environment Log Setup\n",
    "    ### 2. Argument and environment-variable summary helpers\n",
    "    ### 2a. Log App (Arguments bash_script_echoSummary_ARGS)\n",
    "    ### 2b. Log Environment Variable \n",
    "    ### 3. Log MPI/SLURM diagnostics\n",
    "    ### 4a. Error-path timing summary (run vs. total)\n",
    "    ### 4b. Success-path timing summary (binary run only)\n",
    "    ### 5. Final total-runtime footer (successful script completion)\n",
    "    ### 6. Optional pre-run copy of input files/directories\n",
    "    ### 7. Optional ZIP expansion of input bundles\n",
    "    ### 8. Defensive setup of the module command (before user-defined module loads)\n",
    "    ### 9. Loading modules from a user-provided file\n",
    "    ### 10. Loading modules from a comma-separated list (MODULE_LOADS_LIST)\n",
    "    ### 11. Load OpenSees Modules (If Running OpenSees)\n",
    "    ### 12. Installing Python packages from a requirements file (PIP_INSTALLS_FILE)\n",
    "    ### 13. Installing Python packages from a comma-separated list (PIP_INSTALLS_LIST)\n",
    "    ### 14. Choosing how to launch the app (sequential vs MPI)\n",
    "    ### 15. Running the job binary (with timers and error handling)\n",
    "    ### 16. OpenSeesPy: copy TACC-compiled OpenSeesPy.so into the run directory\n",
    "    ### 17. Optional Cleanup: remove temporary TACC OpenSeesPy library after the run\n",
    "    ### 18. Optional: repack the output directory into a single ZIP (ZIP_OUTPUT_SWITCH)\n",
    "    ### 19. Optional: move main output to a faster storage destination (PATH_MOVE_OUTPUT)\n",
    "    ### 20. Optional: Pre-Job Hook -- User-Defined script run BEFORE main binary (PRE_JOB_SCRIPT)\n",
    "    ### 21. Optional: Post-Job Hook -- User-Defined script run AFTER main binary (POST_JOB_SCRIPT)\n",
    "    ### 22. Change Directory (cd) INTO Input Directory\n",
    "    ### 23. Change Directory (cd) OUT OF Input Directory\n",
    "    ### 24. Assemble Main Wrapper File: **tapisjob_app.sh**\n",
    "    ### 25. Replace batch_script patches into the Main Wrapper File\n",
    "    #### 25a. Replace batch_script patches -- All Apps\n",
    "    #### 25b. Replace batch_script patches -- Agnostic App\n",
    "    #### 25c. Replace batch_script patches -- OpenSeesPy App\n",
    "    ## E. Create **tapisjob_app.zip** – App Zip File\n",
    "    ## F. File Check -- Visualize File Contents in Local (Development) Path\n",
    "    ### Show Files for Content -- No Line Numbers\n",
    "    ### Show Files for Debugging -- SHOW Line Numbers\n",
    "    # Validate App Files Locally\n",
    "    # Deploy the App\n",
    "    ## Upload Files to appPath_Tapis\n",
    "    ### Make the App Directory\n",
    "    ### Upload/Copy Files to Deployment System\n",
    "    ### Check Files on Deployment System To Verify Upload\n",
    "    # Register The App\n",
    "    ## List All Tapis Apps to Verify Registration\n",
    "    ## Access App Schema on Tapis to Validate Registration\n",
    "    # Manage Public App\n",
    "    ## Manage App isPublic Status\n",
    "    ### Make The App Public (optional)\n",
    "    ### or Remove The App From Public Access (optional)\n",
    "    ### Verify isPublic Status### Set Permissions for Public App\n",
    "    ## Set Permissions for Public App \n",
    "    ### File Permissions\n",
    "    ### Path/Directory Permissions\n",
    "    # Test App (done in a separate notebook)\n",
    "    ```\n",
    "    \n",
    "    </div>\n",
    "    \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "import textwrap, time\n",
    "import stat\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Specialized Utilities Library\n",
    "I have developed a collection of python defs that are intended to simplify coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Utilities Library\n",
    "import os,sys\n",
    "PathOpsUtils = os.path.expanduser('~/CommunityData/Training/Computational-Workflows-on-DesignSafe/OpsUtils')\n",
    "if not PathOpsUtils in sys.path: sys.path.append(PathOpsUtils)\n",
    "from OpsUtils import OpsUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef8ca5f5b774405a1d7f02d14fd9862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We will use this utility often to view the utility functions:\n",
    "OpsUtils.show_text_file_in_accordion(PathOpsUtils, 'show_text_file_in_accordion.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Set Process-Control Switches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make-App Switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_makeApp = True\n",
    "# do_makeApp = False # remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_makeApp_OpsPy = True\n",
    "# do_makeApp_OpsPy = False # remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the OpsPy app relies on the main app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_makeApp == False:\n",
    "    do_makeApp_OpsPy = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_OpenSees_TCL = True\n",
    "# Test_OpenSees_TCL = False # REMOVE\n",
    "\n",
    "Test_OpenSees_PY = True\n",
    "# Test_OpenSees_PY = False # REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_OpenSees_PY_OpsPy = True\n",
    "# Test_OpenSees_PY_OpsPy = False # REMOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make-Public Switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "makePublic = True\n",
    "# makePublic = False # remove\n",
    "\n",
    "makeUnPublic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "makePublic_OpsPy = True\n",
    "# makePublic_OpsPy = False # remove\n",
    "\n",
    "makeUnPublic_OpsPy = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Set App-Author Info\n",
    "you can paste this in your files, where needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_Author_Info = 'Silvia Mazzoni, DesignSafe (silviamazzoni@yahoo.com)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Set Execution System\n",
    "TACC system where the app will be submit the SLURM job.\n",
    "This app can be run on any system in TACC. You can let the user make this selection. \n",
    "\n",
    "However, this app was developed and tested for stampede3.\n",
    "\n",
    "Options:\n",
    "* **stamped3**: https://docs.tacc.utexas.edu/hpc/stampede3/\n",
    "* **vista**: https://docs.tacc.utexas.edu/hpc/vista/\n",
    "* **frontera**: https://docs.tacc.utexas.edu/hpc/frontera/\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_system_id_app = \"stampede3\"; # options: 'stamped3','frontera','vista'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set App Path for Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "appPath_Local_base = f'~/MyData/myAuthoredTapisApps'; # your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Set App Path for Deployment\n",
    "The app should reside in the app's execution system!\n",
    "MyData should NOT be used, it is here only for demonstration purposes.\n",
    "You cannot set open-access permssion on MyData, so it can't be used if the app is to be made public -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set App Path for Deployment\n",
    "Define Work Path in Tapis format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_system_id = 'cloud.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_system_id_OpsPy = 'cloud.data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Get Today's date\n",
    "you can paste this in your files, where needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "February 14, 2026\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "today_formatted = today.strftime(\"%B %d, %Y\")   # December 04, 2025\n",
    "print(today_formatted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Connect to Tapis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9eac43b43b473b93ce5fe969d0a872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OpsUtils.show_text_file_in_accordion(PathOpsUtils, 'connect_tapis.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Checking Tapis token --\n",
      " Token loaded from file. Token is still valid!\n",
      " Token expires at: 2026-02-14T20:12:52+00:00\n",
      " Token expires in: 3:31:40.598734\n",
      "-- AUTHENTICATED VIA SAVED TOKEN --\n"
     ]
    }
   ],
   "source": [
    "force_connect = False\n",
    "# force_connect = True; # REMOVE do this only if you want to restart the clock on the token.\n",
    "t=OpsUtils.connect_tapis(force_connect=force_connect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Get username\n",
    "you may need it for some paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d800bf1de33340968d32883dbc189584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OpsUtils.show_text_file_in_accordion(PathOpsUtils, 'get_tapis_username.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username silvia\n"
     ]
    }
   ],
   "source": [
    "username = OpsUtils.get_tapis_username(t)\n",
    "print('username',username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get User- and Execution-System-Specific Work Paths\n",
    "While JupyterHub treats Work as part of its environment, Tapis needs its full path, which is user-specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work Path in the HPC system\n",
    "Use tapis to obtain this user & system-dependent base path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WORK': '/work2/05072/silvia/stampede3',\n",
       " 'HOME': '/home1/05072/silvia',\n",
       " 'SCRATCH': '/scratch/05072/silvia'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exec_system_envVar_List = ['WORK','HOME','SCRATCH']; # collect these, just in case\n",
    "\n",
    "exec_system_path_dict = {}\n",
    "for thisKey in exec_system_envVar_List:\n",
    "    exec_system_path_dict[thisKey] = t.systems.hostEval(systemId=exec_system_id_app,envVarName=thisKey).name\n",
    "display(exec_system_path_dict)\n",
    "\n",
    "user_WorkPath_base = exec_system_path_dict[\"WORK\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work Path in the JupyterHub System\n",
    "Check this path within your JupyterHub System."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_WorkPath_base_local = f'~/Work/{exec_system_id_app}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_WorkPath_base: /work2/05072/silvia/stampede3\n",
      "user_WorkPath_base_local: ~/Work/stampede3\n"
     ]
    }
   ],
   "source": [
    "print('user_WorkPath_base:',user_WorkPath_base)\n",
    "print('user_WorkPath_base_local:',user_WorkPath_base_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Configure App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set App ID Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_id = 'designsafe-agnostic-app'\n",
    "app_description = 'Agnostic Tapis App for General Python Execution as well as OpenSees, OpenSeesMP, OpenSeesSP, OpenSeesPy'\n",
    "app_helpUrl = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_id_OpsPy = 'designsafe-openseespy-s3'\n",
    "app_description_OpsPy = f'Basic App to run OpenSeesPy on {exec_system_id_app}.'\n",
    "app_helpUrl_OpsPy = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if App Exists\n",
    "If it exists you will see a version number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_app_version 1.3.10\n"
     ]
    }
   ],
   "source": [
    "current_app_version = OpsUtils.get_latest_app_version(t,app_id)\n",
    "print('current_app_version',current_app_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_app_version_OpsPy 1.2.14\n"
     ]
    }
   ],
   "source": [
    "current_app_version_OpsPy = OpsUtils.get_latest_app_version(t,app_id_OpsPy)\n",
    "print('current_app_version_OpsPy',current_app_version_OpsPy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set App Version\n",
    "we have an utility for that will autoincrement an existing app's version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a64fe15a424fc5851e97a3b0737850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OpsUtils.show_text_file_in_accordion(PathOpsUtils, ['increment_tapis_app_version.py','get_latest_app_version.py','bump_app_version.py'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Update Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "updateType = 'patch'; # options: major, minor, patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine new version number for this update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app exists, now latest_app_version 1.3.10\n",
      "Update type: patch\n",
      "now app_version 1.3.11\n"
     ]
    }
   ],
   "source": [
    "if do_makeApp:\n",
    "    app_version = OpsUtils.increment_tapis_app_version(t,app_id,updateType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app exists, now latest_app_version 1.2.14\n",
      "Update type: patch\n",
      "now app_version 1.2.15\n"
     ]
    }
   ],
   "source": [
    "if do_makeApp_OpsPy:\n",
    "    app_version_OpsPy = OpsUtils.increment_tapis_app_version(t,app_id_OpsPy,updateType)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Set File Locations\n",
    "\n",
    "**appPath_Local**\n",
    "Your local development directory. This is where you create, modify, and organize all application files before packaging or uploading.\n",
    "\n",
    "**appPath_Tapis**\n",
    "The destination directory on the HPC system where your application files will be uploaded and stored and will ultimately reside (including the packaged .zip). These files do **not** run from this location, Tapis copies it over to the execution directory.\n",
    "#### Special Case: Public App\n",
    "* If the app is intended to be public, ensure that appPath_Tapis is located in a directory accessible to all TACC users (for example, your WORK directory on Stampede3) so others can download or reference the files as needed.<br>\n",
    "* Even if the app is not public, placing appPath_Tapis in your WORK directory on Stampede3 is still recommended, as copying files from WORK to the execution-system directory (also on Stampede3) is typically faster and more reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set appPath_Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appPath_Local: /home/jupyter/MyData/myAuthoredTapisApps/designsafe-agnostic-app/1.3.11\n",
      " exists: True\n"
     ]
    }
   ],
   "source": [
    "if do_makeApp:\n",
    "    appPath_Local = f'{appPath_Local_base}/{app_id}/{app_version}'; # your choice\n",
    "    appPath_Local = os.path.abspath(os.path.expanduser(appPath_Local))\n",
    "    os.makedirs(appPath_Local, exist_ok=True)\n",
    "    print(f'appPath_Local: {appPath_Local}\\n exists:',os.path.exists(appPath_Local))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appPath_Local_OpsPy: /home/jupyter/MyData/myAuthoredTapisApps/designsafe-openseespy-s3/1.2.15\n",
      " exists: True\n"
     ]
    }
   ],
   "source": [
    "if do_makeApp_OpsPy:\n",
    "    appPath_Local_OpsPy = f'{appPath_Local_base}/{app_id_OpsPy}/{app_version_OpsPy}'; # your choice\n",
    "    appPath_Local_OpsPy = os.path.abspath(os.path.expanduser(appPath_Local_OpsPy))\n",
    "    os.makedirs(appPath_Local_OpsPy, exist_ok=True)\n",
    "    print(f'appPath_Local_OpsPy: {appPath_Local_OpsPy}\\n exists:',os.path.exists(appPath_Local_OpsPy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set appPath_Tapis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appPath_Tapis_local_anchor /home/jupyter/Work/stampede3\n",
      "appPath_Tapis0 /work2/05072/silvia/stampede3/apps\n",
      "appPath_Tapis0_local /home/jupyter/Work/stampede3/apps\n"
     ]
    }
   ],
   "source": [
    "appPath_Tapis0 = user_WorkPath_base; # we will use this path to create folders and copy app files using TAPIS if we cannot access the system from here\n",
    "appPath_Tapis0_local = f'{user_WorkPath_base_local}'; # we will use this path to create folders and copy app files using python/os commands if TAPIS is slow\n",
    "\n",
    "appPath_Tapis_local_anchor = os.path.abspath(os.path.expanduser(appPath_Tapis0_local))\n",
    "print('appPath_Tapis_local_anchor',appPath_Tapis_local_anchor)\n",
    "\n",
    "appPath_Tapis0 += '/apps'\n",
    "appPath_Tapis0_local  += '/apps'\n",
    "\n",
    "appPath_Tapis0 = os.path.expanduser(appPath_Tapis0)\n",
    "appPath_Tapis0_local = os.path.expanduser(appPath_Tapis0_local)\n",
    "\n",
    "print('appPath_Tapis0',appPath_Tapis0)\n",
    "print('appPath_Tapis0_local',appPath_Tapis0_local)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appPath_Tapis /work2/05072/silvia/stampede3/apps/designsafe-agnostic-app/1.3.11\n",
      "appPath_Tapis_local /home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11\n",
      "container_filename designsafe-agnostic-app.zip\n"
     ]
    }
   ],
   "source": [
    "if do_makeApp:\n",
    "    appPath_Tapis = f\"{appPath_Tapis0}/{app_id}/{app_version}\"\n",
    "    appPath_Tapis_local =f\"{appPath_Tapis0_local}/{app_id}/{app_version}\"\n",
    "    container_filename = f'{app_id}.zip'\n",
    "    \n",
    "    print('appPath_Tapis',appPath_Tapis)\n",
    "    print('appPath_Tapis_local',appPath_Tapis_local)\n",
    "    print('container_filename',container_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appPath_Tapis_OpsPy /work2/05072/silvia/stampede3/apps/designsafe-openseespy-s3/1.2.15\n",
      "appPath_Tapis_local_OpsPy /home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15\n",
      "container_filename_OpsPy designsafe-openseespy-s3.zip\n"
     ]
    }
   ],
   "source": [
    "if do_makeApp_OpsPy:\n",
    "    appPath_Tapis_OpsPy = f\"{appPath_Tapis0}/{app_id_OpsPy}/{app_version_OpsPy}\"   \n",
    "    appPath_Tapis_local_OpsPy =  f\"{appPath_Tapis0_local}/{app_id_OpsPy}/{app_version_OpsPy}\"\n",
    "    container_filename_OpsPy = f'{app_id_OpsPy}.zip'\n",
    "    \n",
    "    print('appPath_Tapis_OpsPy',appPath_Tapis_OpsPy)\n",
    "    print('appPath_Tapis_local_OpsPy',appPath_Tapis_local_OpsPy)\n",
    "    print('container_filename_OpsPy',container_filename_OpsPy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Create the App Files\n",
    "\n",
    "A Tapis app requires a small set of **core files** that define what the app *is*, how it *runs*, and what users *see* when launching it.\n",
    "These files together form the runtime “package” that Tapis deploys onto the HPC system.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Readme.md — App Documentation *(optional but recommended)*\n",
    "\n",
    "A human-readable guide for users of your app.\n",
    "Include:\n",
    "\n",
    "* What the app does\n",
    "* Expected inputs and outputs\n",
    "* Example usage\n",
    "* Notes on OpenSees/OpenSeesPy behavior (if relevant)\n",
    "\n",
    "This file does *not* affect execution, but it is extremely helpful for portal users.\n",
    "\n",
    "You should generate this file LAST, and update it every time you modify the app. (ChatGPT is great for this task).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Scheduler Profile — Environment Setup *(optional but common)*\n",
    "\n",
    "A profile file (e.g., tacc-no-modules, or a custom profile) that defines:\n",
    "\n",
    "* Which modules are available to load\n",
    "* What environment variables are pre-set\n",
    "* Whether the system provides module support automatically\n",
    "\n",
    "This profile is executed on the compute node *before* your wrapper script runs by tapisJob.sh.\n",
    "You may use an existing TACC profile or define your own.\n",
    "\n",
    "In this case, I have opted to use a blank profile and load the modules manually in the tapisJob_app.sh. <br>\n",
    "**However**, creating a profile once and using it during job submittal can save a lot of slurm-job time. This route can reduce some user errors, but can also add new ones.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. app.json — Tapis App Definition\n",
    "\n",
    "This JSON file is the **heart of the app**. It tells Tapis:\n",
    "\n",
    "* The app name, version, and description\n",
    "* What inputs the user must provide\n",
    "* Parameters and flags (e.g., MPI usage, script names)\n",
    "* Execution system (Stampede3) and queue\n",
    "* How files should be staged and archived\n",
    "* What runtime image to unpack (the ZIP file)\n",
    "\n",
    "Tapis reads this file to create, validate, and register your app.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. tapisjob_app.sh — Wrapper Script (the executable logic)\n",
    "\n",
    "This is the script **Tapis actually runs on the HPC compute node**.\n",
    "It performs:\n",
    "\n",
    "* Environment and module setup\n",
    "* Optional pip installations\n",
    "* Optional OpenSeesPy .so copy\n",
    "* Logging, timers, and job summaries\n",
    "* Launching the main executable (OpenSeesMP, python3, etc.)\n",
    "* Cleanup and end-of-job reporting\n",
    "\n",
    "This file is packaged into the ZIP runtime image and becomes the *entry point* for the app.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Create **Readme.MD** – App User Documentation\n",
    "This file is helpful in communicating content to the app user.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_makeApp:\n",
    "    thisFilename = 'ReadMe.MD'\n",
    "    thisText_ReadMeMd = textwrap.dedent(\"\"\"\n",
    "\n",
    "# __app_id__\n",
    "***__app_description__***\n",
    "\n",
    "- **Version:** __app_version__  \n",
    "- **Author:** *__app_Author_Info__*  \n",
    "- **Date:** __today_formatted__  \n",
    "- **Platform:** DesignSafe / TACC Stampede3  \n",
    "- **Runtime:** ZIP (HPC Batch)  \n",
    "- **Default queue:** *skx-dev* (can be overridden at submission)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Purpose and Design Philosophy\n",
    "\n",
    "*__app_id__* is a **general-purpose, HPC-oriented Tapis application** designed to support *many* computational workflows without baking assumptions into the app itself.\n",
    "\n",
    "Instead of creating separate apps for:\n",
    "\n",
    "* OpenSees vs OpenSeesMP\n",
    "* Tcl vs Python\n",
    "* Serial vs MPI\n",
    "* Small vs large output jobs\n",
    "\n",
    "this app acts as a **configurable execution driver**.\n",
    "\n",
    "All behavior is controlled by:\n",
    "\n",
    "* **app inputs**\n",
    "* **environment variables**\n",
    "* **wrapper logic**\n",
    "\n",
    "This makes the app:\n",
    "\n",
    "* reusable\n",
    "* transparent\n",
    "* automatable\n",
    "* easy to fork and extend\n",
    "\n",
    "Tapis orchestrates the job.\n",
    "SLURM executes it.\n",
    "**The wrapper enforces semantics and safety.**\n",
    "\n",
    "---\n",
    "\n",
    "## 2. High-Level Execution Model\n",
    "\n",
    "At runtime, the following happens:\n",
    "\n",
    "1. Tapis stages *inputDirectory*\n",
    "2. A SLURM batch job is submitted\n",
    "3. *tapisjob_app.sh* executes on the first node\n",
    "4. The wrapper:\n",
    "\n",
    "   * prepares the environment\n",
    "   * stages inputs\n",
    "   * selects MPI vs non-MPI execution\n",
    "   * runs the main executable\n",
    "   * manages outputs\n",
    "   * produces structured logs\n",
    "\n",
    "The **minimum mental model** for the app is:\n",
    "\n",
    "**[UseMPI?]  BINARYNAME  INPUTSCRIPT  ARGUMENTS**\n",
    "\n",
    "<details><summary><b>Detailed Execution Mode</b></summary>\n",
    "1. Tapis stages your **Input Directory** to the job working directory.\n",
    "2. SLURM starts the batch job on Stampede3.\n",
    "3. *tapisjob_app.sh* runs on the first allocated node and:\n",
    "   - sets up summary and full environment logs\n",
    "   - *cd*s into the Input Directory\n",
    "   - prepares inputs (optional copy-in, optional unzip)\n",
    "   - loads modules (optional file + optional list)\n",
    "   - normalizes Python (*python* → *python3*)\n",
    "   - installs Python packages (optional file + optional list)\n",
    "   - optionally injects TACC-compiled OpenSeesPy (*opensees.so*)\n",
    "   - optionally runs pre/post hooks\n",
    "   - chooses MPI launcher (*ibrun*) or direct run\n",
    "   - runs your executable + script + args\n",
    "   - optionally zips output and/or moves results inside the exec system\n",
    "   - records timers and exits with clear error handling\n",
    "\n",
    "    \n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "## 3. Input parameters (what each one means)\n",
    "\n",
    "This section is the “user manual” for every input you see in the portal.\n",
    "\n",
    "### 3.1 File input\n",
    "\n",
    "#### **Input Directory** (required)\n",
    "**What it is:** A *single directory* staged by Tapis into the job.  \n",
    "**What should be inside:**\n",
    "- your main script (Tcl or Python)\n",
    "- any supporting files your script needs (models, data, configs)\n",
    "- optional helper files:\n",
    "  - *modules.txt* (for *MODULE_LOADS_FILE*)\n",
    "  - *requirements.txt* (for *PIP_INSTALLS_FILE*)\n",
    "  - *prehook.sh* / *posthook.sh* (for hook variables)\n",
    "  - zipped bundles referenced by *UNZIP_FILES_LIST*\n",
    "\n",
    "**Runtime behavior:** The wrapper *cd*s into this directory before running the main command.  \n",
    "**Implication:** relative paths in your script should assume this directory is the working directory.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2 Required app arguments\n",
    "\n",
    "#### **Main Program** (required)\n",
    "**What it is:** The executable to run (binary name).  \n",
    "**Common values:**\n",
    "- *OpenSees* (serial Tcl)\n",
    "- *OpenSeesMP* / *OpenSeesSP* (MPI Tcl)\n",
    "- *python3* (Python workflows, including OpenSeesPy)\n",
    "\n",
    "**Where it must come from:**\n",
    "- available via modules (recommended), or\n",
    "- present in the working directory / PATH\n",
    "\n",
    "**Wrapper notes:**\n",
    "- If *Main Program* is *python* or *python3*, the wrapper normalizes to *python3*.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Main Script** (required)\n",
    "**What it is:** The filename of the input script passed to the executable.  \n",
    "**Rules:**\n",
    "- filename only (no path)\n",
    "- must exist inside the **Input Directory**\n",
    "\n",
    "Examples:\n",
    "- *model.tcl*\n",
    "- *run_analysis.py*\n",
    "- *Ex1a.Canti2D.Push.argv.tacc.py*\n",
    "\n",
    "---\n",
    "\n",
    "#### **UseMPI** (required)\n",
    "Controls whether the wrapper launches the executable through *ibrun*.\n",
    "\n",
    "| UseMPI value | What runs |\n",
    "|---|---|\n",
    "| *False* | *<Main Program> <Main Script> [args...]* |\n",
    "| *True*  | *ibrun <Main Program> <Main Script> [args...]* |\n",
    "\n",
    "**Use *True* when:**\n",
    "- OpenSeesMP / OpenSeesSP\n",
    "- Python + *mpi4py*\n",
    "\n",
    "**Use *False* when:**\n",
    "- serial OpenSees (Tcl)\n",
    "- serial Python / OpenSeesPy\n",
    "- Python using threading / *concurrent.futures* within a node\n",
    "\n",
    "> Note: the wrapper treats many “true-like” values as True (*True*, *1*, *Yes*, case-insensitive).\n",
    "\n",
    "---\n",
    "\n",
    "#### **CommandLine Arguments** (optional)\n",
    "Free-form arguments appended after the Main Script.\n",
    "\n",
    "Example:\n",
    "```text\n",
    "--NodalMass 4.19 --outDir outCase1\n",
    "```\n",
    "\n",
    "Final command structure:\n",
    "```bash\n",
    "[ibrun] <MainProgram> <MainScript> <Arguments...>\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3.3 Scheduler inputs\n",
    "\n",
    "#### **TACC Scheduler Profile** (defaulted)\n",
    "The app uses the *tacc-no-modules* profile by default so **no modules are implicitly loaded**.\n",
    "This is intentional: module state is controlled explicitly by the wrapper to improve reproducibility.\n",
    "\n",
    "#### **TACC Reservation** (optional)\n",
    "Provide a reservation string if you have one.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Environment variables (advanced configuration)\n",
    "\n",
    "These values are presented as app inputs in the portal. Most are optional. If you never set them, the wrapper runs with conservative defaults.\n",
    "\n",
    "### 4.1 OpenSeesPy injection\n",
    "\n",
    "#### **GET_TACC_OPENSEESPY** (default: *True*)\n",
    "If True-like, the wrapper attempts to use the **TACC-compiled OpenSeesPy** by:\n",
    "- loading *python/3.12.11*, *hdf5/1.14.4*, *opensees*\n",
    "- copying *${TACC_OPENSEES_BIN}/OpenSeesPy.so* into the working directory as *./opensees.so*\n",
    "\n",
    "**Use this when:**\n",
    "- you want reliable OpenSeesPy on Stampede3 (recommended)\n",
    "\n",
    "**In your Python script:**\n",
    "```python\n",
    "import opensees as ops\n",
    "```\n",
    "\n",
    "**Notes / failure modes:**\n",
    "- if *TACC_OPENSEES_BIN* is unset or *OpenSeesPy.so* is missing, the wrapper logs a warning and skips the copy.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2 Module loading (two mechanisms)\n",
    "The two mechanisms are complementary -- you can use both.\n",
    "\n",
    "#### A. **MODULE_LOADS_FILE** (optional)\n",
    "A filename (in the Input Directory) containing module commands, one per line.\n",
    "\n",
    "Supported line formats:\n",
    "- *purge*\n",
    "- *use <path>*\n",
    "- *load <module>*\n",
    "- *?module* (optional *try-load*)\n",
    "- bare module names\n",
    "\n",
    "This is best for **version-controlled, documented module stacks**. It also makes submittal via the web-portal interface easier.\n",
    "\n",
    "#### B. **MODULE_LOADS_LIST** (optional)\n",
    "Comma-separated list of modules to load, e.g.:\n",
    "```text\n",
    "python/3.12.11,opensees,hdf5/1.14.4,pylauncher\n",
    "```\n",
    "\n",
    "**Tip:** use *MODULE_LOADS_FILE* when the setup is more than a few modules or needs comments.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.3 Python package installs (two mechanisms)\n",
    "The two mechanisms are complementary -- you can use both.\n",
    "\n",
    "#### A. **PIP_INSTALLS_FILE** (optional)\n",
    "A requirements-style file (in the Input Directory), e.g. *requirements.txt*.\n",
    "\n",
    "Wrapper behavior:\n",
    "- runs *pip3 install -r <file>*\n",
    "- fails the job if pip fails (with a clear error)\n",
    "\n",
    "It makes submittal via the web-portal interface easier.\n",
    "\n",
    "#### B. **PIP_INSTALLS_LIST** (optional)\n",
    "Comma-separated list of packages, e.g.:\n",
    "```text\n",
    "mpi4py,pandas,numpy,matplotlib\n",
    "```\n",
    "\n",
    "Wrapper behavior:\n",
    "- installs each package with *pip3 install <pkg>*\n",
    "- fails the job if any install fails\n",
    "\n",
    "---\n",
    "\n",
    "### 4.4 Input preparation\n",
    "\n",
    "#### A. **UNZIP_FILES_LIST** (optional)\n",
    "Comma-separated list of ZIP files *in the Input Directory* to expand before execution.\n",
    "Entries may omit the *.zip* suffix.\n",
    "\n",
    "Use this when:\n",
    "- you staged one bundled zip instead of many small files\n",
    "\n",
    "#### B. **PATH_COPY_IN_LIST** (optional)\n",
    "Comma-separated list of **absolute paths** (within the execution system) to copy into the working directory before execution.\n",
    "\n",
    "Example:\n",
    "```text\n",
    "$WORK/FileSet2,$SCRATCH/FileSet3/thisFile.at2\n",
    "```\n",
    "\n",
    "Use this when:\n",
    "- you need large/shared datasets without duplicating them into the Input Directory\n",
    "- you want a specific runtime layout inside the working directory\n",
    "\n",
    "#### C. **DELETE_COPIED_IN_ON_EXIT** (default: *0*)\n",
    "If set to *1* / True-like, the wrapper deletes only the copied-in items listed in its manifest on exit.\n",
    "\n",
    "Safety rules:\n",
    "- refuses absolute paths\n",
    "- refuses *..* traversal\n",
    "- deletes only what landed in the working directory\n",
    "\n",
    "Use this when:\n",
    "- copy-in files are “temporary conveniences” and should not be archived\n",
    "\n",
    "---\n",
    "\n",
    "### 4.5 Pre/Post hooks\n",
    "\n",
    "#### A. **PRE_JOB_SCRIPT** (optional)\n",
    "Script to run after environment setup but before the main executable.\n",
    "- if relative, interpreted as *./script* inside the Input Directory\n",
    "- if executable, run directly; otherwise run via *bash*\n",
    "\n",
    "#### B. **POST_JOB_SCRIPT** (optional)\n",
    "Script to run after the main executable (same resolution rules as pre-hook).\n",
    "\n",
    "**Default policy:** hook failures are logged as warnings and the job continues (you can change this policy in the wrapper if desired).\n",
    "\n",
    "---\n",
    "\n",
    "### 4.6 Output management\n",
    "\n",
    "#### A. **ZIP_OUTPUT_SWITCH** (default: *False*)\n",
    "If True-like:\n",
    "- zips the entire Input Directory after execution into *inputDirectory.zip*\n",
    "- removes the original directory\n",
    "\n",
    "Use this when:\n",
    "- output is large and contains many small files\n",
    "- you want a single artifact to move / download\n",
    "\n",
    "#### B. **PATH_MOVE_OUTPUT** (optional)\n",
    "If set, the wrapper moves the main output artifact into:\n",
    "```text\n",
    "<PATH_MOVE_OUTPUT>/_<JobUUID>/\n",
    "```\n",
    "and copies top-level logs into that same folder.\n",
    "\n",
    "Recommended:\n",
    "- move to *$WORK/...* for interactive inspection in JupyterHub\n",
    "- move to *$SCRATCH/...* for chained HPC workflows\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Logs you should look at first\n",
    "\n",
    "Every job produces:\n",
    "- ***SLURM-job-summary.log*** (compact “what happened”)\n",
    "- ***SLURM-full-environment.log*** (full *env | sort* dump)\n",
    "\n",
    "The summary log also records:\n",
    "- launcher decision\n",
    "- module/pip actions\n",
    "- timers (run-only and total)\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Typical patterns\n",
    "\n",
    "### Serial OpenSees (Tcl)\n",
    "- Main Program: *OpenSees*\n",
    "- UseMPI: *False*\n",
    "\n",
    "### OpenSeesMP / OpenSeesSP (MPI)\n",
    "- Main Program: *OpenSeesMP* (or *OpenSeesSP*)\n",
    "- UseMPI: *True*\n",
    "\n",
    "### OpenSeesPy (serial)\n",
    "- Main Program: *python3*\n",
    "- UseMPI: *False*\n",
    "- *GET_TACC_OPENSEESPY=True*\n",
    "\n",
    "### Python + mpi4py\n",
    "- Main Program: *python3*\n",
    "- UseMPI: *True*\n",
    "- *PIP_INSTALLS_LIST=mpi4py* (or requirements file)\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Summary\n",
    "\n",
    "*__app_id__* provides a single, well-instrumented execution interface for:\n",
    "- OpenSees (Tcl), OpenSeesMP/SP (MPI), OpenSeesPy\n",
    "- general Python workflows\n",
    "- reusable HPC job patterns (copy-in, unzip, hooks, packaging, output movement)\n",
    "\n",
    "It is designed to be **debuggable, reproducible, and extensible**, and to serve as a template for future apps.\n",
    "\n",
    "    \n",
    "    \"\"\")\n",
    "    thisText_ReadMeMd = thisText_ReadMeMd.replace(\"__app_id__\", app_id)\n",
    "    thisText_ReadMeMd = thisText_ReadMeMd.replace(\"__app_Author_Info__\", app_Author_Info)\n",
    "    thisText_ReadMeMd = thisText_ReadMeMd.replace(\"__app_version__\", app_version)\n",
    "    thisText_ReadMeMd = thisText_ReadMeMd.replace(\"__app_description__\", app_description)\n",
    "    thisText_ReadMeMd = thisText_ReadMeMd.replace(\"__today_formatted__\", today_formatted)\n",
    "    with open(f\"{appPath_Local}/{thisFilename}\", \"w\") as f:\n",
    "        f.write(thisText_ReadMeMd)\n",
    "    # write it here\n",
    "    with open(f\"./{thisFilename}_{app_id}\", \"w\") as f:\n",
    "        f.write(thisText_ReadMeMd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0cfa1c172c40e8a83f7297bd551d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if do_makeApp:\n",
    "    OpsUtils.show_text_file_in_accordion(appPath_Local, thisFilename, showLineNumbers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_makeApp_OpsPy:\n",
    "    thisFilename = 'ReadMe.MD'\n",
    "    thisText_ReadMeMd_OpsPy = textwrap.dedent(\"\"\"\n",
    "\n",
    "# __app_id_OpsPy__\n",
    "***__app_description_OpsPy__***\n",
    "\n",
    "\n",
    "* **Version:** __app_version_OpsPy__\n",
    "* **Author:** *__app_Author_Info__*\n",
    "* **Date:** __today_formatted__\n",
    "* **Runtime:** ZIP\n",
    "* **Execution system:** Stampede3 (SLURM)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Overview\n",
    "\n",
    "**__app_id_OpsPy__** is a lightweight, ZIP-runtime **Tapis batch app** designed to run **OpenSeesPy** workflows on **Stampede3** through the **DesignSafe** platform.\n",
    "\n",
    "The app intentionally keeps configuration minimal while still supporting:\n",
    "\n",
    "* Serial Python runs\n",
    "* MPI-based Python runs using `mpi4py`\n",
    "* Automatic staging of inputs and outputs\n",
    "* Optional module loading\n",
    "* Optional pip installs\n",
    "* Detailed job summary logging\n",
    "\n",
    "This app is ideal for:\n",
    "\n",
    "* Teaching and tutorials\n",
    "* Small–to–moderate OpenSeesPy models\n",
    "* Parameter studies\n",
    "* MPI-enabled OpenSeesPy workflows\n",
    "* Users who want **zero manual SLURM scripting**\n",
    "\n",
    "---\n",
    "\n",
    "## 2. What the App Does (Execution Flow)\n",
    "\n",
    "When a job starts, the app performs the following steps:\n",
    "\n",
    "1. **Stages the Input Directory** into the job working directory\n",
    "2. **Loads user-specified TACC modules** (via `MODULE_LOADS_LIST`)\n",
    "3. **Optionally installs Python packages** using pip\n",
    "4. **Copies the TACC-compiled OpenSeesPy library** (`OpenSeesPy.so`) into the working directory as:\n",
    "\n",
    "   ```\n",
    "   ./opensees.so\n",
    "   ```\n",
    "5. **Selects the launcher**\n",
    "\n",
    "   * Serial execution → direct `python3`\n",
    "   * MPI execution → `ibrun python3`\n",
    "6. **Runs your Python script**\n",
    "7. **Writes a compact, human-readable job summary log**\n",
    "8. **Cleans up temporary OpenSeesPy artifacts**\n",
    "9. **Archives outputs back to DesignSafe storage**\n",
    "\n",
    "No Docker image is used.\n",
    "All execution occurs directly on Stampede3 compute nodes under SLURM.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Required Input\n",
    "\n",
    "### **Input Directory (REQUIRED)**\n",
    "\n",
    "Upload a single directory containing:\n",
    "\n",
    "* Your **main OpenSeesPy script** (`.py`)\n",
    "* Any data files the script reads\n",
    "* Optional:\n",
    "\n",
    "  * `requirements.txt`\n",
    "  * auxiliary Python modules\n",
    "  * model input files\n",
    "\n",
    "The directory is staged and exposed as:\n",
    "\n",
    "```\n",
    "$PWD/inputDirectory/\n",
    "```\n",
    "\n",
    "Your script is executed **from inside this directory**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. App Arguments (Portal Inputs)\n",
    "\n",
    "### **1. Main Program**\n",
    "\n",
    "*Fixed and hidden*\n",
    "\n",
    "```\n",
    "python3\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Main Script (REQUIRED)**\n",
    "\n",
    "The **filename only** of your Python script\n",
    "(must exist inside the Input Directory)\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "run_model.py\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. UseMPI (True / False)**\n",
    "\n",
    "Controls how the script is launched.\n",
    "\n",
    "| UseMPI | Behavior                  |\n",
    "| ------ | ------------------------- |\n",
    "| False  | `python3 script.py`       |\n",
    "| True   | `ibrun python3 script.py` |\n",
    "\n",
    "**Guidance**\n",
    "\n",
    "* Use **True** when using:\n",
    "\n",
    "  * `mpi4py`\n",
    "  * OpenSeesPy MPI domain decomposition\n",
    "* Use **False** for:\n",
    "\n",
    "  * serial scripts\n",
    "  * `concurrent.futures` on a single node\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Environment Variables (Pre-Configured)\n",
    "\n",
    "These variables are defined in the app and usually **do not need to be changed**.\n",
    "\n",
    "| Variable              | Default                                  | Purpose                                                |\n",
    "| --------------------- | ---------------------------------------- | ------------------------------------------------------ |\n",
    "| `GET_TACC_OPENSEESPY` | True                                     | Copies TACC-compiled OpenSeesPy into the job directory |\n",
    "| `MODULE_LOADS_LIST`   | `python/3.12.11,opensees,hdf5/1.14.4`    | Modules loaded before execution                        |\n",
    "| `PIP_INSTALLS_LIST`   | `mpi4py,pandas,numpy,matplotlib,futures` | Python packages installed via pip                      |\n",
    "\n",
    "You may override these values if needed.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Importing OpenSeesPy Correctly\n",
    "\n",
    "Because the app **injects a TACC-compiled shared library** into the working directory, your script must import OpenSeesPy as:\n",
    "\n",
    "```python\n",
    "import opensees as ops\n",
    "```\n",
    "\n",
    "or:\n",
    "\n",
    "```python\n",
    "import opensees\n",
    "```\n",
    "\n",
    "❌ **Do not** use:\n",
    "\n",
    "```python\n",
    "import openseespy.opensees\n",
    "```\n",
    "\n",
    "unless you intentionally install the PyPI wheel and disable `GET_TACC_OPENSEESPY`.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. MPI Usage with OpenSeesPy\n",
    "\n",
    "For MPI workflows, your script should explicitly use `mpi4py`:\n",
    "\n",
    "```python\n",
    "from mpi4py import MPI\n",
    "import opensees as ops\n",
    "```\n",
    "\n",
    "Portal settings:\n",
    "\n",
    "* **UseMPI:** True\n",
    "* **nodeCount / coresPerNode:** set appropriately\n",
    "\n",
    "The app will automatically launch with:\n",
    "\n",
    "```\n",
    "ibrun python3 your_script.py\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Job Logging & Diagnostics\n",
    "\n",
    "Each job produces a **compact summary log** named:\n",
    "\n",
    "```\n",
    "SLURM-job-summary.log\n",
    "```\n",
    "\n",
    "This file includes:\n",
    "\n",
    "* App metadata\n",
    "* Loaded modules\n",
    "* Installed pip packages\n",
    "* Launch mode (MPI vs serial)\n",
    "* Runtime durations\n",
    "* Error diagnostics (if the job fails)\n",
    "\n",
    "This log is intended for **human-readable debugging** and complements SLURM output files.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Output & Archiving\n",
    "\n",
    "All files produced during execution remain inside the Input Directory and are archived to:\n",
    "\n",
    "```\n",
    "$WORK/tapis-jobs-archive/<date>/<jobname>-<jobuuid>/\n",
    "```\n",
    "\n",
    "Archived content includes:\n",
    "\n",
    "* Job summary log\n",
    "* Environment logs\n",
    "* Script outputs\n",
    "* Any files created by your Python workflow\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Common Failure Modes\n",
    "\n",
    "| Symptom                 | Likely Cause                          |\n",
    "| ----------------------- | ------------------------------------- |\n",
    "| `ImportError: opensees` | Incorrect import statement            |\n",
    "| MPI job hangs           | `UseMPI=True` but script not MPI-safe |\n",
    "| pip install failure     | Incompatible package version          |\n",
    "| Job exits immediately   | Script filename mismatch              |\n",
    "\n",
    "Check **SLURM-job-summary.log** first.\n",
    "\n",
    "---\n",
    "\n",
    "## 11. Intended Scope\n",
    "\n",
    "This app is designed for:\n",
    "\n",
    "* OpenSeesPy-based research workflows\n",
    "* Education and training\n",
    "* Lightweight automation through the DesignSafe portal\n",
    "\n",
    "It is **not** intended to replace:\n",
    "\n",
    "* Custom SLURM scripts\n",
    "* Large-scale production pipelines\n",
    "* Long-running, multi-stage workflows\n",
    "\n",
    "For those use cases, consider developing a custom Tapis app or using OpenSeesMP-specific apps.\n",
    "\n",
    "---\n",
    "\n",
    "## 12. License & Reuse\n",
    "\n",
    "Developed by DesignSafe.\n",
    "This app may be reused, forked, and extended for broader OpenSeesPy workflows.\n",
    "\n",
    "\n",
    "    \"\"\")\n",
    "    thisText_ReadMeMd_OpsPy = thisText_ReadMeMd_OpsPy.replace(\"__app_Author_Info__\", app_Author_Info)\n",
    "    thisText_ReadMeMd_OpsPy = thisText_ReadMeMd_OpsPy.replace(\"__app_id_OpsPy__\", app_id_OpsPy)\n",
    "    thisText_ReadMeMd_OpsPy = thisText_ReadMeMd_OpsPy.replace(\"__app_version_OpsPy__\", app_version_OpsPy)\n",
    "    thisText_ReadMeMd_OpsPy = thisText_ReadMeMd_OpsPy.replace(\"__app_description_OpsPy__\", app_description_OpsPy)\n",
    "    thisText_ReadMeMd_OpsPy = thisText_ReadMeMd_OpsPy.replace(\"__today_formatted__\", today_formatted)\n",
    "    with open(f\"{appPath_Local_OpsPy}/{thisFilename}\", \"w\") as f:\n",
    "        f.write(thisText_ReadMeMd_OpsPy)\n",
    "\n",
    "    # write it here\n",
    "    with open(f\"./{thisFilename}_{app_id_OpsPy}\", \"w\") as f:\n",
    "        f.write(thisText_ReadMeMd_OpsPy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35cd0cf967e4a6ba941668a5ec1f7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if do_makeApp_OpsPy:\n",
    "    OpsUtils.show_text_file_in_accordion(appPath_Local, [thisFilename], showLineNumbers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Create/Select **profile.json** – Environment Setup\n",
    "This file defines the modules that will be loaded before your script runs. It is executed on the compute node.\n",
    "\n",
    "You can define this environement once, or you can use available environments, such as opensees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list of existing profiles, see if any are useful to you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415f6dc6258242d5aa2f77a3e587b5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Output(),), titles=('Existing Profiles',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "here_out = widgets.Output()\n",
    "here_accordion = widgets.Accordion(children=[here_out])\n",
    "# here_accordion.selected_index = 0\n",
    "here_accordion.set_title(0, f'Existing Profiles')\n",
    "display(here_accordion)\n",
    "\n",
    "with here_out:\n",
    "    systemProfiles = t.systems.getSchedulerProfiles(orderBy='name')\n",
    "    for thisProfile in systemProfiles:\n",
    "        this_out = widgets.Output()\n",
    "        this_accordion = widgets.Accordion(children=[this_out])\n",
    "        # here_accordion.selected_index = 0\n",
    "        this_accordion.set_title(0, thisProfile.name)\n",
    "        display(this_accordion)\n",
    "        with this_out:\n",
    "            print(thisProfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Create **app.json** – App Definition\n",
    "Defines the app’s metadata, inputs, parameters, and execution configuration.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisText_options_COMMANDLINE_ARGS = textwrap.dedent(\"\"\",\n",
    "        {\n",
    "          \"name\": \"CommandLine Arguments\",\n",
    "          \"description\": \"Optional command-line arguments appended after Main Script (e.g., '--npts 2000 --dir X' or any format consistent with how your input script parses them).\",\n",
    "          \"arg\": null,\n",
    "          \"inputMode\": \"INCLUDE_ON_DEMAND\",\n",
    "          \"notes\": {\"isHidden\": __isHidden__}\n",
    "        }\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisText_options_ENV_VARS = textwrap.dedent(\"\"\",\n",
    "        {\n",
    "          \"key\": \"UNZIP_FILES_LIST\",\n",
    "          \"value\": \"\",\n",
    "          \"inputMode\": \"INCLUDE_ON_DEMAND\",\n",
    "          \"description\": \"Comma-separated list of ZIP files in the Input Directory to unzip before the run. Example: 'inputs.zip,gm_files.zip'.\",\n",
    "          \"notes\": {\"isHidden\": __isHidden__}\n",
    "        },\n",
    "        {\n",
    "          \"key\": \"PATH_COPY_IN_LIST\",\n",
    "          \"value\": \"\",\n",
    "          \"inputMode\": \"INCLUDE_ON_DEMAND\",\n",
    "          \"description\": \"Absolute Path (within the Execution System) of folder that will be copied into the job working directory **before** execution.  (Example: '$HOME/FileSet1,$WORK/FileSet2,$SCRATCH/FileSet3/thisFile.at2')\",\n",
    "          \"notes\": {\"isHidden\": __isHidden__}\n",
    "        },\n",
    "        {\n",
    "          \"key\": \"DELETE_COPIED_IN_ON_EXIT\",\n",
    "          \"value\": \"0\",\n",
    "          \"inputMode\": \"INCLUDE_ON_DEMAND\",\n",
    "          \"description\": \"If set to a true-like value, removes files or directories that were copied into the job working directory via PATH_COPY_IN_LIST after the job completes, preventing temporary inputs from being included in the final archive.\",\n",
    "          \"notes\": { \"isHidden\": __isHidden__ }\n",
    "        },\n",
    "        {\n",
    "          \"key\": \"MODULE_LOADS_FILE\",\n",
    "          \"value\": \"\",\n",
    "          \"inputMode\": \"INCLUDE_ON_DEMAND\",\n",
    "          \"description\": \"Name of a file in the Input Directory containing a list of modules to load (newline- or comma-separated). Example: 'modules.txt'.\",\n",
    "          \"notes\": {\"isHidden\": __isHidden__}\n",
    "        },\n",
    "        {\n",
    "          \"key\": \"PIP_INSTALLS_FILE\",\n",
    "          \"value\": \"\",\n",
    "          \"inputMode\": \"INCLUDE_ON_DEMAND\",\n",
    "          \"description\": \"Name of a file in the Input Directory containing a list of Python packages to pip install (newline- or comma-separated). Example: 'requirements.txt'.\",\n",
    "          \"notes\": {\"isHidden\": __isHidden__}\n",
    "        },\n",
    "        {\n",
    "          \"key\": \"ZIP_OUTPUT_SWITCH\",\n",
    "          \"value\": \"False\",\n",
    "          \"inputMode\": \"INCLUDE_BY_DEFAULT\",\n",
    "          \"description\": \"If 'True', zip the job output directory into a single archive before Tapis archiving. NOTE: the value must be defined as a string.\",\n",
    "          \"notes\": {\"isHidden\": __isHidden__,\n",
    "                      \"enum_values\": [{\"True\": \"True: Zip All Output into a file\"},{\"False\": \"False: No Zipping\"}]}\n",
    "        },\n",
    "        {\n",
    "          \"key\": \"PATH_MOVE_OUTPUT\",\n",
    "          \"value\": \"\",\n",
    "          \"inputMode\": \"INCLUDE_BY_DEFAULT\",\n",
    "          \"description\": \"Destination path (Absolute and within the Execution System) where outputs will be moved **after** execution. (E.g., '$HOME/OutSet1', '$WORK/OutSet2', '$SCRATCH/OutSet3')\",\n",
    "          \"notes\": {\"isHidden\": __isHidden__}\n",
    "        },\n",
    "        {\n",
    "          \"key\": \"PRE_JOB_SCRIPT\",\n",
    "          \"value\": \"\",\n",
    "          \"inputMode\": \"INCLUDE_BY_DEFAULT\",\n",
    "          \"description\": \"Filename of user-defined PRE-JOB script (or absolute path). This file must reside in the Input Directory. It is run after the system has been configured, but before the main binary. (e.g. prehook.sh,$WORK/.../pre-hook.sh)\",\n",
    "          \"notes\": {\"isHidden\": __isHidden__}\n",
    "        },\n",
    "        {\n",
    "          \"key\": \"POST_JOB_SCRIPT\",\n",
    "          \"value\": \"\",\n",
    "          \"inputMode\": \"INCLUDE_BY_DEFAULT\",\n",
    "          \"description\": \"Filename of user-defined POST-JOB script (or absolute path). This file must reside in the Input Directory. It is run after the the main binary. (e.g. prehook.sh,$WORK/.../pre-hook.sh)\",\n",
    "          \"notes\": {\"isHidden\": __isHidden__}\n",
    "        }\n",
    "\n",
    "        \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exec_system_id_app stampede3\n"
     ]
    }
   ],
   "source": [
    "thisFilename = 'app.json'\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Configurable knobs for different systems / queues / resources\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "print('exec_system_id_app',exec_system_id_app)\n",
    "\n",
    "# Default resources (you can override per app / per system)\n",
    "node_count = 1\n",
    "if exec_system_id_app == \"frontera\":\n",
    "    exec_system_queue = \"development\" ; # frontera\n",
    "    cores_per_node = 56\n",
    "else:\n",
    "    exec_system_queue = \"skx-dev\"; # stampede3\n",
    "    cores_per_node = 48\n",
    "memory_mb = 192000   # 192 GB\n",
    "max_minutes = 120    # 2 hours\n",
    "\n",
    "# Typically archive to the same system, but you can decouple this\n",
    "# archive_system_id = exec_system_id_app\n",
    "# archive_system_dir = \"HOST_EVAL($WORK)/tapis-jobs-archive/${JobCreateDate}/${JobName}-${JobUUID}\"\n",
    "# use MyData:\n",
    "archive_system_id = 'designsafe.storage.default'\n",
    "archive_system_dir = username + \"/tapis-jobs-archive/${JobCreateDate}/${JobName}-${JobUUID}\"\n",
    "\n",
    "# Tapis MPI flags (wrapper also has a user-level UseMPI flag)\n",
    "# the following defines whether the tapis_app.sh is run using mpi, not your script\n",
    "isMpi = 'false'\n",
    "if isMpi == 'true':\n",
    "    mpiCmd = '\"ibrun\"'\n",
    "else:\n",
    "    mpiCmd = 'null'\n",
    "\n",
    "# Scheduler profile (matches TACC config)\n",
    "#   Examples:\n",
    "#   - 'tacc-no-modules'         (no preloaded modules; user must load via MODULE_LOADS_LIST)\n",
    "#   - 'python312_stampede3'     (if you later create one)\n",
    "thisSchedulerProfile = 'tacc-no-modules'\n",
    "\n",
    "isHidden = 'false'\n",
    "\n",
    "thisText_appJson_Raw = textwrap.dedent(\"\"\"\n",
    "{\n",
    "  \"id\": \"__app_id__\",\n",
    "  \"version\": \"__app_version__\",\n",
    "  \"description\": \"__app_description__\",\n",
    "  \"owner\": \"${apiUserId}\",\n",
    "  \"enabled\": true,\n",
    "  \"runtime\": \"ZIP\",\n",
    "  \"runtimeVersion\": null,\n",
    "  \"runtimeOptions\": null,\n",
    "  \"containerImage\": \"__container_filename_path__\",\n",
    "  \"jobType\": \"BATCH\",\n",
    "  \"maxJobs\": -1,\n",
    "  \"maxJobsPerUser\": -1,\n",
    "  \"strictFileInputs\": true,\n",
    "  \"jobAttributes\": {\n",
    "    \"execSystemConstraints\": null,\n",
    "    \"execSystemId\": \"__execSystemId__\",\n",
    "    \"execSystemExecDir\": \"${JobWorkingDir}\",\n",
    "    \"execSystemInputDir\": \"${JobWorkingDir}\",\n",
    "    \"execSystemOutputDir\": \"${JobWorkingDir}\",\n",
    "    \"execSystemLogicalQueue\": \"__execSystemLogicalQueue__\",\n",
    "    \"archiveSystemId\": \"__archiveSystemId__\",\n",
    "    \"archiveSystemDir\": \"__archiveSystemDir__\",\n",
    "    \"archiveOnAppError\": true,\n",
    "    \"isMpi\": __isMpi__,\n",
    "    \"mpiCmd\": __mpiCmd__,\n",
    "    \"parameterSet\": {\n",
    "      \"appArgs\": [\n",
    "        {\n",
    "          \"name\": \"Main Program\",\n",
    "          \"description\": \"Binary executable to run. (e.g., OpenSees, OpenSeesMP, OpenSeesSP, python3 -- OpenSeesPy: use python3).    The executable must be available in the job's execution system. Some executables require you to load specific modules.\",\n",
    "          \"arg\": \"python3\",\n",
    "          \"inputMode\": \"REQUIRED\",\n",
    "          \"notes\": {\n",
    "                      \"isHidden\": __isHidden__,\n",
    "                      \"enum_values\": [{\"OpenSees\": \"OpenSees\"},{\"OpenSeesMP\": \"OpenSeesMP\"},{\"OpenSeesSP\": \"OpenSeesSP\"},{\"python3\": \"Python\"}]\n",
    "                  }\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"Main Script\",\n",
    "          \"description\": \"Filename (no path) of the input script passed to the executable (Example: Ex1a.Canti2D.Push.mpi4py.tacc.py). This file must reside in the Input Directory.  Note: This App uses TACC-Compiled OpenSeesPy: use 'import opensees' or 'import opensees as ops' in your script.\",\n",
    "          \"arg\": null,\n",
    "          \"inputMode\": \"REQUIRED\",\n",
    "          \"notes\": {\n",
    "                        \"inputType\": \"fileInput\",\n",
    "                        \"isHidden\": false\n",
    "                  }\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"UseMPI\",\n",
    "          \"description\": \"Flag indicating whether the application should launch the main program with an MPI parallel-execution command (ibrun). **True**: enable distributed-memory parallelism, allowing multi-core or multi-node execution. (Suitable for OpenSeesMP / OpenSeesSP / Python with mpi4py (OpenSeesPy)). **False**: execution stays on one node. (Suitable for OpenSees, Python, or Python with concurrent.futures for one-node parallelism.)\",\n",
    "          \"arg\": \"False\",\n",
    "          \"inputMode\": \"REQUIRED\",\n",
    "          \"notes\": {\n",
    "            \"isHidden\": false,\n",
    "            \"enum_values\": [\n",
    "              {\"True\": \"True — Enable MPI mode -- Use multi-node or multi-core parallelism.\"},\n",
    "              {\"False\": \"False — No MPI -- Use single-node process.\" }\n",
    "            ]\n",
    "          }\n",
    "        }__COMMANDLINE_ARGS__\n",
    "      ],\n",
    "      \"containerArgs\": [],\n",
    "      \"schedulerOptions\": [\n",
    "        {\n",
    "          \"name\": \"TACC Scheduler Profile\",\n",
    "          \"description\": \"Scheduler profile (e.g., tacc-no-modules) -- the app loads the modules you specify.\",\n",
    "          \"inputMode\": \"__SchedulerProfile_FIXITY__\",\n",
    "          \"arg\": \"--tapis-profile __schedulerProfile__\",\n",
    "          \"notes\": {\"isHidden\": __isHidden__}\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"TACC Reservation\",\n",
    "          \"description\": \"If you have a TACC reservation, enter the reservation string here.\",\n",
    "          \"inputMode\": \"INCLUDE_ON_DEMAND\",\n",
    "          \"arg\": null,\n",
    "          \"notes\": {\n",
    "              \"isHidden\": false\n",
    "          }\n",
    "        }        \n",
    "      ],\n",
    "      \"envVariables\": [\n",
    "        {\n",
    "          \"key\": \"GET_TACC_OPENSEESPY\",\n",
    "          \"value\": \"__GET_TACC_OPENSEESPY_DEFAULT__\",\n",
    "          \"inputMode\": \"INCLUDE_BY_DEFAULT\",\n",
    "          \"description\": \"If 'True', use the TACC-compiled OpenSeesPy (not the PyPI wheel). In your script, import OpenSeesPy using 'import opensees' or 'import opensees as ops'.\",\n",
    "          \"notes\": {\n",
    "                      \"isHidden\": __isHidden__,\n",
    "                      \"enum_values\": [{\"True\": \"True: Copy TACC-Compiled OpenSeesPy\"},{\"False\": \"False: no TACC-Compiled OpenSeesPy\"}]\n",
    "                    }\n",
    "        },\n",
    "        {\n",
    "          \"key\": \"PIP_INSTALLS_LIST\",\n",
    "          \"value\": \"mpi4py,pandas,numpy,matplotlib,futures\",\n",
    "          \"inputMode\": \"__PIP_INSTALLS_LIST_inputMode__\",\n",
    "          \"description\": \"Comma-separated list of Python packages to pip install before the run. Example: 'numpy,scipy,mpi4py' Defaults:'mpi4py,pandas,numpy,scipy'.\",\n",
    "          \"notes\": {\"isHidden\": __isHidden__}\n",
    "        },\n",
    "        {\n",
    "          \"key\": \"MODULE_LOADS_LIST\",\n",
    "          \"value\": \"python/3.12.11,opensees,hdf5/1.14.4,pylauncher\",\n",
    "          \"inputMode\": \"__MODULE_LOADS_LIST_inputMode__\",\n",
    "          \"description\": \"Comma-separated list of TACC modules to load before the run. Defaults: 'opensees,hdf5/1.14.4' 'python/3.12.11' and 'pylauncher' are included if  GET_TACC_OPENSEESPY=True.\",\n",
    "          \"notes\": {\"isHidden\": __isHidden__}\n",
    "        }__ENV_VARS__\n",
    "      ],\n",
    "      \"archiveFilter\": {\n",
    "        \"includes\": [],\n",
    "        \"excludes\": [\"__container_filename__\"],\n",
    "        \"includeLaunchFiles\": true\n",
    "      }\n",
    "    },\n",
    "    \"fileInputs\": [\n",
    "      {\n",
    "        \"name\": \"Input Directory\",\n",
    "        \"inputMode\": \"__fileInputs_InputDirectory_INPUTMODE__\",\n",
    "        \"sourceUrl\": null,\n",
    "        \"targetPath\": \"inputDirectory\",\n",
    "        \"envKey\": \"inputDirectory\",\n",
    "        \"description\": \"Directory containing the main script and any supporting files (models, data, etc.). (Example: tapis://designsafe.storage.community/app_examples/opensees/OpenSeesPy)\",\n",
    "        \"notes\": {\n",
    "          \"selectionMode\": \"directory\",\n",
    "          \"isHidden\": false\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"fileInputArrays\": [],\n",
    "    \"nodeCount\": __nodeCount__,\n",
    "    \"coresPerNode\": __coresPerNode__,\n",
    "    \"memoryMB\": __memoryMB__,\n",
    "    \"maxMinutes\": __maxMinutes__,\n",
    "    \"subscriptions\": [],\n",
    "    \"tags\": []\n",
    "  },\n",
    "  \"tags\": [\n",
    "    \"portalName: DesignSafe\",\n",
    "    \"portalName: CEP\"\n",
    "  ],\n",
    "  \"notes\": {\n",
    "    \"label\": \"__app_id__\",\n",
    "    \"helpUrl\": \"__app_helpUrl__\",\n",
    "    \"hideNodeCountAndCoresPerNode\": false,\n",
    "    \"isInteractive\": __isInteractive__,\n",
    "    \"icon\": \"__icon__\",\n",
    "    \"category\": \"__category__\"\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common content\n",
    "app_icon = 'OpenSees'\n",
    "app_category = 'Simulation'\n",
    "app_isInteractive = 'false'\n",
    "thisText_appJson_Raw = thisText_appJson_Raw.replace(\"__icon__\", app_icon)\n",
    "thisText_appJson_Raw = thisText_appJson_Raw.replace(\"__category__\", app_category)\n",
    "thisText_appJson_Raw = thisText_appJson_Raw.replace(\"__isInteractive__\", app_isInteractive)\n",
    "\n",
    "# System / queue / archive placeholders\n",
    "thisText_appJson_Raw = thisText_appJson_Raw.replace(\"__execSystemId__\", exec_system_id_app)\n",
    "thisText_appJson_Raw = thisText_appJson_Raw.replace(\"__execSystemLogicalQueue__\", exec_system_queue)\n",
    "thisText_appJson_Raw = thisText_appJson_Raw.replace(\"__archiveSystemId__\", archive_system_id)\n",
    "thisText_appJson_Raw = thisText_appJson_Raw.replace(\"__archiveSystemDir__\", archive_system_dir)\n",
    "\n",
    "# Resource placeholders\n",
    "thisText_appJson_Raw = thisText_appJson_Raw.replace(\"__nodeCount__\", str(node_count))\n",
    "thisText_appJson_Raw = thisText_appJson_Raw.replace(\"__coresPerNode__\", str(cores_per_node))\n",
    "thisText_appJson_Raw = thisText_appJson_Raw.replace(\"__memoryMB__\", str(memory_mb))\n",
    "thisText_appJson_Raw = thisText_appJson_Raw.replace(\"__maxMinutes__\", str(max_minutes))\n",
    "\n",
    "# MPI + scheduler profile\n",
    "thisText_appJson_Raw = thisText_appJson_Raw.replace(\"__isMpi__\", isMpi)\n",
    "thisText_appJson_Raw = thisText_appJson_Raw.replace(\"__mpiCmd__\", mpiCmd)\n",
    "thisText_appJson_Raw = thisText_appJson_Raw.replace(\"__schedulerProfile__\", thisSchedulerProfile)\n",
    "\n",
    "thisText_appJson_Raw = thisText_appJson_Raw.replace(\"__fileInputs_InputDirectory_INPUTMODE__\", 'REQUIRED')\n",
    "\n",
    "thisText_Raw = thisText_appJson_Raw\n",
    "\n",
    "# different settings for the two apps:\n",
    "MODULE_LOADS_LIST_inputMode_app = 'INCLUDE_ON_DEMAND'\n",
    "MODULE_LOADS_LIST_inputMode_appOpsPy = 'INCLUDE_BY_DEFAULT'\n",
    "PIP_INSTALLS_LIST_inputMode_app = 'INCLUDE_ON_DEMAND'\n",
    "PIP_INSTALLS_LIST_inputMode_appOpsPy = 'INCLUDE_BY_DEFAULT'\n",
    "\n",
    "\n",
    "__GET_TACC_OPENSEESPY_DEFAULT___app = \"False\"\n",
    "__GET_TACC_OPENSEESPY_DEFAULT___appOpsPy = \"True\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_makeApp:\n",
    "    thisText_appJson = thisText_Raw   \n",
    "    # App-Specific Input ----------------\n",
    "    # Basic placeholder replacements\n",
    "    thisText_appJson = thisText_appJson.replace(\"__app_id__\", app_id)\n",
    "    thisText_appJson = thisText_appJson.replace(\"__app_version__\", app_version)\n",
    "    thisText_appJson = thisText_appJson.replace(\"__app_description__\", app_description)\n",
    "    thisText_appJson = thisText_appJson.replace(\n",
    "        \"__container_filename_path__\",\n",
    "        f\"/{appPath_Tapis}/{container_filename}\"\n",
    "    )\n",
    "    thisText_appJson = thisText_appJson.replace(\"__container_filename__\", container_filename)\n",
    "\n",
    "    thisText_appJson = thisText_appJson.replace(\"__app_helpUrl__\", app_helpUrl)\n",
    "    thisText_appJson = thisText_appJson.replace(\"__SchedulerProfile_FIXITY__\", 'INCLUDE_BY_DEFAULT')\n",
    "\n",
    "    thisText_appJson = thisText_appJson.replace(\"__COMMANDLINE_ARGS__\", thisText_options_COMMANDLINE_ARGS)\n",
    "    thisText_appJson = thisText_appJson.replace(\"__ENV_VARS__\", thisText_options_ENV_VARS)    \n",
    "\n",
    "    thisText_appJson = thisText_appJson.replace(\"__isHidden__\", isHidden)\n",
    "\n",
    "    thisText_appJson = thisText_appJson.replace(\"__MODULE_LOADS_LIST_inputMode__\", MODULE_LOADS_LIST_inputMode_app)\n",
    "    thisText_appJson = thisText_appJson.replace(\"__PIP_INSTALLS_LIST_inputMode__\", PIP_INSTALLS_LIST_inputMode_app)\n",
    "    \n",
    "    thisText_appJson = thisText_appJson.replace(\"__GET_TACC_OPENSEESPY_DEFAULT__\", __GET_TACC_OPENSEESPY_DEFAULT___app)\n",
    "\n",
    "    \n",
    "    \n",
    "    with open(f\"{appPath_Local}/{thisFilename}\", \"w\") as f:\n",
    "        f.write(thisText_appJson)\n",
    "\n",
    "    # print('thisText_appJson',thisText_appJson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bd953dec7b4998be147fe48f485dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if do_makeApp:\n",
    "    OpsUtils.show_text_file_in_accordion(appPath_Local, [thisFilename], background='#d4fbff', showLineNumbers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_makeApp_OpsPy:\n",
    "    isHidden_OpsPy = 'true'\n",
    "    \n",
    "    thisFilename = 'app.json'\n",
    "    thisText_appJson_OpsPy = thisText_Raw\n",
    "    # App-Specific Input ----------------\n",
    "    # Basic placeholder replacements\n",
    "    thisText_appJson_OpsPy = thisText_appJson_OpsPy.replace(\"__app_id__\", app_id_OpsPy)\n",
    "    thisText_appJson_OpsPy = thisText_appJson_OpsPy.replace(\"__app_version__\", app_version_OpsPy)\n",
    "    thisText_appJson_OpsPy = thisText_appJson_OpsPy.replace(\"__app_description__\", app_description_OpsPy)\n",
    "    thisText_appJson_OpsPy = thisText_appJson_OpsPy.replace(\n",
    "        \"__container_filename_path__\",\n",
    "        f\"/{appPath_Tapis_OpsPy}/{container_filename_OpsPy}\"\n",
    "    )\n",
    "    thisText_appJson_OpsPy = thisText_appJson_OpsPy.replace(\"__container_filename__\", container_filename_OpsPy)\n",
    "\n",
    "    thisText_appJson_OpsPy = thisText_appJson_OpsPy.replace(\"__app_helpUrl__\", app_helpUrl_OpsPy)\n",
    "    thisText_appJson_OpsPy = thisText_appJson_OpsPy.replace(\"__isHidden__\", isHidden_OpsPy)\n",
    "    thisText_appJson_OpsPy = thisText_appJson_OpsPy.replace(\"__SchedulerProfile_FIXITY__\", 'FIXED')\n",
    "    \n",
    "    thisText_appJson_OpsPy = thisText_appJson_OpsPy.replace(\"__COMMANDLINE_ARGS__\", '')\n",
    "    thisText_appJson_OpsPy = thisText_appJson_OpsPy.replace(\"__ENV_VARS__\", '')\n",
    "\n",
    "    thisText_appJson_OpsPy = thisText_appJson_OpsPy.replace(\"__MODULE_LOADS_LIST_inputMode__\", MODULE_LOADS_LIST_inputMode_appOpsPy)\n",
    "    thisText_appJson_OpsPy = thisText_appJson_OpsPy.replace(\"__PIP_INSTALLS_LIST_inputMode__\", PIP_INSTALLS_LIST_inputMode_appOpsPy)    \n",
    "    \n",
    "    thisText_appJson_OpsPy = thisText_appJson_OpsPy.replace(\"__GET_TACC_OPENSEESPY_DEFAULT__\", __GET_TACC_OPENSEESPY_DEFAULT___appOpsPy)    \n",
    "    \n",
    "    with open(f\"{appPath_Local_OpsPy}/{thisFilename}\", \"w\") as f:\n",
    "        f.write(thisText_appJson_OpsPy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c987b2e100104a84b81ea2488ef717e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if do_makeApp_OpsPy:\n",
    "    OpsUtils.show_text_file_in_accordion(appPath_Local, [thisFilename], background='#d4fbff', showLineNumbers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### D. Create **tapisjob_app.sh** – Wrapper Script\n",
    "Wrapper script executed by the job; this is the command that launches your code (e.g., runs *OpenSeesMP*, Python, or a script)\n",
    "\n",
    "We are braking up this file into individual chunks, each with its own task. We can then choose whether to include each task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Script initialization: safety flags, required args, and global context\n",
    "\n",
    "This first block sets up the **execution contract** for the SLURM wrapper: how it’s called, which environment variables must exist, and some global metadata/timers.\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "    \n",
    "##### A. Safe shell behavior + debug trace\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "set -euo pipefail\n",
    "set -x\n",
    "```\n",
    "\n",
    "* #!/bin/bash – run with Bash explicitly.\n",
    "* set -e – exit immediately if any command returns a non-zero status.\n",
    "* set -u – treat use of **unset variables** as an error.\n",
    "* set -o pipefail – if any command in a pipeline fails, the whole pipeline fails.\n",
    "* set -x – print each command before executing it (very helpful for debugging SLURM jobs).\n",
    "\n",
    "Together, these make the script **fail fast and visibly** instead of silently limping along with partial state.\n",
    "\n",
    "##### B. App metadata (filled in by the template)\n",
    "\n",
    "```bash\n",
    "echo \"  App_Id            : __app_id__\"\n",
    "echo \"  App_Version       : __app_version__\"\n",
    "echo \"  App_Description   : __app_description__\"\n",
    "```\n",
    "\n",
    "These placeholders are filled by the app definition (app.json / template). Printing them at the top:\n",
    "\n",
    "* Confirms which app/version is actually running.\n",
    "* Helps when scanning raw job output or debugging “which app did I launch?”\n",
    "\n",
    "##### C. Required positional arguments\n",
    "\n",
    "```bash\n",
    "BINARYNAME=\"${1:?missing binary name}\"\n",
    "INPUTSCRIPT0=\"${2:?missing input script}\"\n",
    "UseMPI=\"${3:?missing mpi-call switch}\"\n",
    "shift 3\n",
    "```\n",
    "\n",
    "The wrapper **requires three positional arguments**:\n",
    "\n",
    "1. BINARYNAME – the executable to run\n",
    "   e.g., OpenSees, OpenSeesMP, or python3.\n",
    "\n",
    "2. INPUTSCRIPT0 – the path to the input script\n",
    "   e.g., models/bridge.tcl or analysis.py.\n",
    "\n",
    "3. UseMPI – a flag indicating whether to use MPI\n",
    "   (later interpreted as true/false-like in the launcher logic).\n",
    "\n",
    "The :? syntax enforces these as **mandatory**: if any is missing, the script aborts with a clear error like missing binary name. shift 3 then removes these from $@, leaving only user/script arguments in $*.\n",
    "\n",
    "You also log:\n",
    "\n",
    "```bash\n",
    "echo \"ARGS: $*\"\n",
    "```\n",
    "\n",
    "so you can see the remaining command-line arguments passed through to the binary.\n",
    "\n",
    "##### D. Environment-derived parameters\n",
    "\n",
    "```bash\n",
    "INPUTSCRIPT=\"${INPUTSCRIPT0##*/}\"\n",
    "echo \"INPUTSCRIPT: $INPUTSCRIPT\"\n",
    "\n",
    "inputDirectory=\"${inputDirectory:?inputDirectory not set}\"\n",
    "echo \"inputDirectory: $inputDirectory\"\n",
    "```\n",
    "\n",
    "* INPUTSCRIPT is normalized to **just the basename** of the input file (foo.tcl instead of path/to/foo.tcl). This is the name you actually run inside the working directory.\n",
    "* inputDirectory is required to be set in the environment (from the Tapis app / job definition). If it’s missing, the script fails early with inputDirectory not set.\n",
    "\n",
    "This clearly separates:\n",
    "\n",
    "* Where the **input bundle** lives (inputDirectory), from\n",
    "* Which **file inside that directory** is the main driver (INPUTSCRIPT).\n",
    "\n",
    "##### E. Job metadata from Tapis\n",
    "\n",
    "```bash\n",
    "JobUUID=\"${_tapisJobUUID:-}\"\n",
    "echo \"JobUUID: ${JobUUID}\"\n",
    "```\n",
    "\n",
    "* Pulls the Tapis job UUID from _tapisJobUUID if present.\n",
    "* Logs it so:\n",
    "\n",
    "  * You can correlate this run with Tapis records,\n",
    "  * Later blocks (like PATH_MOVE_OUTPUT) can use JobUUID to create per-job output directories.\n",
    "\n",
    "##### F. Remember the script’s starting directory\n",
    "\n",
    "```bash\n",
    "SCRIPT_ROOT_DIR=\"$(pwd)\"\n",
    "```\n",
    "\n",
    "This captures the **directory where the wrapper started**, which you later use to:\n",
    "\n",
    "* Anchor the summary log (SUMMARY_SHORT),\n",
    "* Normalize relative paths provided by the user,\n",
    "* Reason about where the job “began” vs. where it might cd during execution.\n",
    "\n",
    "##### G. Normalize Python binary name\n",
    "\n",
    "```bash\n",
    "if [[ \"$BINARYNAME\" == \"python3\" || \"$BINARYNAME\" == \"python\" ]]; then\n",
    "    echo \" -- overwrite python with python3, if needed --\"\n",
    "    BINARYNAME=\"python3\"\n",
    "    python -V || true\n",
    "    python3 -V || true\n",
    "fi\n",
    "```\n",
    "\n",
    "If the caller passed either python or python3:\n",
    "\n",
    "* You **force BINARYNAME=\"python3\"** to avoid ambiguity. This makes the environment consistent and avoids issues with different python symlinks.\n",
    "* You print both python -V and python3 -V (without failing if they’re missing) so the logs show exactly which Python interpreters are visible on the path.\n",
    "\n",
    "This is especially important for OpenSeesPy and other Python-based workflows, where the **exact Python version** matters.\n",
    "\n",
    "##### H. Start the “total script” timer\n",
    "\n",
    "```bash\n",
    "TOTAL_START_EPOCH=$(date +%s)\n",
    "TOTAL_START_HUMAN=\"$(date)\"\n",
    "```\n",
    "\n",
    "These mark the beginning of the **entire job wrapper’s lifetime**:\n",
    "\n",
    "* TOTAL_START_EPOCH – numeric timestamp for precise duration calculations.\n",
    "* TOTAL_START_HUMAN – human-readable timestamp for the summary log.\n",
    "\n",
    "Later echoTimers blocks use this to report:\n",
    "\n",
    "* How long the full script ran (setup + run + post-processing),\n",
    "* Both in h/m/s and in raw seconds, for both normal completion and error exits.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_run_INITIALIZE = textwrap.dedent(\"\"\"\n",
    "    #!/bin/bash\n",
    "    set -euo pipefail\n",
    "    set -x\n",
    "\n",
    "    # ---- app written by __app_Author_Info__ ----\n",
    "    echo \"  App_Id            : __app_id__\"\n",
    "    echo \"  App_Version       : __app_version__\"\n",
    "    echo \"  App_Description   : __app_description__\"\n",
    "    \n",
    "    echo \" ---- required args ---- \"\n",
    "    echo\n",
    "    BINARYNAME=\"${1:?missing binary name}\"\n",
    "    INPUTSCRIPT0=\"${2:?missing input script}\"\n",
    "    UseMPI=\"${3:?missing mpi-call switch}\"\n",
    "    shift 3\n",
    "\n",
    "    echo \"ARGS: $*\"\n",
    "\n",
    "    echo \" ---- env params ---- \"\n",
    "    INPUTSCRIPT=\"${INPUTSCRIPT0##*/}\"\n",
    "    echo \"INPUTSCRIPT: $INPUTSCRIPT\"\n",
    "    inputDirectory=\"${inputDirectory:?inputDirectory not set}\"\n",
    "    echo \"inputDirectory: $inputDirectory\"\n",
    "    \n",
    "    # -- Job info\n",
    "    JobUUID=\"${_tapisJobUUID:-}\"\n",
    "    echo \"JobUUID: ${JobUUID}\"\n",
    "\n",
    "    SCRIPT_ROOT_DIR=\"$(pwd)\"\n",
    "\n",
    "    # Normalize python binary name\n",
    "    if [[ \"$BINARYNAME\" == \"python3\" || \"$BINARYNAME\" == \"python\" ]]; then\n",
    "        echo \" -- overwrite python with python3, if needed --\"\n",
    "        BINARYNAME=\"python3\"\n",
    "        python -V || true\n",
    "        python3 -V || true\n",
    "    fi\n",
    "\n",
    "    # ---- TIMERS: total script ----\n",
    "    TOTAL_START_EPOCH=$(date +%s)\n",
    "    TOTAL_START_HUMAN=\"$(date)\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Summary Log Setup\n",
    "This block sets up a compact log files for each job run.\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "\n",
    "* **SUMMARY_SHORT** (default: SLURM-job-summary.log in SCRIPT_ROOT_DIR):\n",
    "  A compact, human-focused summary pinned to the directory where the SLURM script starts (SCRIPT_ROOT_DIR).\n",
    "\n",
    "  * If SUMMARY_SHORT is not set, it is initialized to ${SCRIPT_ROOT_DIR}/SLURM-job-summary.log.\n",
    "  * If the user provides a *relative* path, it is converted into an absolute path under SCRIPT_ROOT_DIR.\n",
    "    This guarantees that the summary log always lives in a predictable location associated with the job’s starting directory.\n",
    "\n",
    "After resolving these paths, the script:\n",
    "\n",
    "1. **Echoes the chosen log file locations** to stdout so the user immediately sees where logs will be written.\n",
    "2. **Initializes the compact summary log** with a banner and basic app metadata:\n",
    "\n",
    "   * App ID, version, description, and help URL (filled in by template placeholders such as __app_id__, __app_version__, etc.).\n",
    "3. **Records key system paths** ($HOME, $WORK, $SCRATCH) and the SLURM-SCRIPT_ROOT_DIR, providing a quick reference for where job data may live.\n",
    "4. **Prints a user-configuration summary**, including:\n",
    "\n",
    "   * JobUUID (the Tapis/Job identifier),\n",
    "   * inputDirectory,\n",
    "   * INPUTSCRIPT,\n",
    "   * UseMPI,\n",
    "   * any additional argument/parameter details (__echoSummary_ARGS__),\n",
    "   * any relevant environment variable summaries (__echoSummary_ENV_VARS__).\n",
    "5. **Logs timing and environment info**, including:\n",
    "\n",
    "   * A pointer to the full environment log,\n",
    "   * The overall job start time in both human-readable and epoch formats.\n",
    "\n",
    "The complete list of the environment variables is, optionally, logged in the verbose script, shown next.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_echoSummary_START = textwrap.dedent(\"\"\"\n",
    "\n",
    "    echo \"=start==============================================================\"\n",
    "    echo \"===================== SUMMARY-LOG SETUP ===========================\"\n",
    "    echo \"===================================================================\"\n",
    "    # Compact, human-focused summary (default name below)\n",
    "    # SUMMARY_SHORT=\"${SUMMARY_SHORT:-./SLURM-job-summary.log}\"\n",
    "   \n",
    "    # Compact, human-focused summary (default name below), pinned to start dir\n",
    "    if [[ -z \"${SUMMARY_SHORT:-}\" ]]; then\n",
    "      SUMMARY_SHORT=\"${SCRIPT_ROOT_DIR}/SLURM-job-summary.log\"\n",
    "    elif [[ \"${SUMMARY_SHORT}\" != /* ]]; then\n",
    "      # If user gave a relative path, make it absolute from the start dir\n",
    "      SUMMARY_SHORT=\"${SCRIPT_ROOT_DIR}/${SUMMARY_SHORT}\"\n",
    "    fi\n",
    "\n",
    "    echo \"Compact summary log: ${SUMMARY_SHORT}\"  \n",
    "    \n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"================== JOB SUMMARY ====================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"  App Id            : __app_id__\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"  App Version       : __app_version__\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"  App Description   : __app_description__\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"  App helpURL       : __app_helpUrl__\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"================== SYSTEM-PATH DEFINITIONS ========================\" >> \"$SUMMARY_SHORT\"\n",
    "    printf '  $HOME    : %s\\n'   \"${HOME}\" >> \"$SUMMARY_SHORT\"\n",
    "    printf '  $WORK    : %s\\n'   \"${WORK:-<unset>}\" >> \"$SUMMARY_SHORT\"\n",
    "    printf '  $SCRATCH : %s\\n'   \"${SCRATCH:-<unset>}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"  SLURM-SCRIPT_ROOT_DIR   : ${SCRIPT_ROOT_DIR}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"================= USER-CONFIGURATION SUMMARY ======================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"JobUUID        : ${JobUUID}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"inputDirectory : ${inputDirectory}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"INPUTSCRIPT    : ${INPUTSCRIPT}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"UseMPI     : ${UseMPI}\" >> \"$SUMMARY_SHORT\"\n",
    "    __echoSummary_ARGS__\n",
    "    echo \"============== APP-DEFINED ENVIRONMENT VALUES ==+==================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"  MODULE_LOADS_LIST   : ${MODULE_LOADS_LIST:-<unset>}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"  PIP_INSTALLS_LIST   : ${PIP_INSTALLS_LIST:-<unset>}\" >> \"$SUMMARY_SHORT\"\n",
    "    __echoSummary_ENV_VARS__\n",
    "    __echoSummary_MPI__\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"Environment: see full-env log for full env dump\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"Total start time: ${TOTAL_START_HUMAN} (epoch ${TOTAL_START_EPOCH})\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Environment Log Setup\n",
    "\n",
    "This block configures how the job’s runtime environment is captured for debugging and reproducibility, while avoiding excessive clutter in the main SLURM output file.\n",
    "\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "\n",
    "The script separates environment logging into two optional files:\n",
    "\n",
    "---\n",
    "\n",
    "### **REDACTED_ENV_LOG** (default: `./SLURM-environment.redacted.log`)\n",
    "\n",
    "This is the **default and recommended environment snapshot**.\n",
    "\n",
    "It creates a sorted dump of the full environment (`env | sort`) but:\n",
    "\n",
    "* **Redacts sensitive variables** (e.g., variables containing `TOKEN`, `SECRET`, `PASSWORD`, `KEY`, `AWS`, etc.).\n",
    "* Masks credentials embedded in URLs (e.g., `scheme://user:pass@host` → `scheme://<REDACTED>@host`).\n",
    "* Writes the output to a dedicated file.\n",
    "* Does **not** print the environment to stdout.\n",
    "\n",
    "This keeps your SLURM job output clean while preserving a reproducible and security-conscious runtime snapshot.\n",
    "\n",
    "You can disable it by setting:\n",
    "\n",
    "```bash\n",
    "REDACTED_ENV_LOG=\"\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **FULL_ENV_LOG** (default: disabled)\n",
    "\n",
    "If explicitly enabled, this writes the complete, unredacted environment to a separate file:\n",
    "\n",
    "```bash\n",
    "FULL_ENV_LOG=./my-full-env.log\n",
    "```\n",
    "\n",
    "Because this may contain credentials or tokens, it is disabled by default and should only be used for deep debugging.\n",
    "\n",
    "---\n",
    "\n",
    "### Additional Behavior\n",
    "\n",
    "* The environment is written only to log files — it is **no longer printed to the main job stdout**, preventing excessive noise in `.out` files.\n",
    "* Log files are created with restricted permissions (`umask 077`) to reduce accidental exposure.\n",
    "* The summary log (`SUMMARY_SHORT`) records which environment logs were created.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Environment Logging Matters in HPC\n",
    "\n",
    "On HPC systems (such as Stampede3 at TACC), your runtime environment is dynamically constructed at job launch. It may include:\n",
    "\n",
    "* Loaded modules and toolchains\n",
    "* MPI and compiler versions\n",
    "* SLURM-provided variables\n",
    "* Scratch paths and allocation settings\n",
    "* Software stack adjustments made by Tapis\n",
    "\n",
    "Small changes in modules, paths, or compiler/MPI versions can alter numerical results, performance, or even job behavior. Capturing the environment ensures that:\n",
    "\n",
    "* Runs are reproducible\n",
    "* Differences between jobs can be diagnosed\n",
    "* Toolchain or module changes can be traced\n",
    "* Support teams can debug issues efficiently\n",
    "\n",
    "Together, the summary log and the redacted environment log provide:\n",
    "\n",
    "* A lightweight, human-readable job summary\n",
    "* A reproducible runtime snapshot\n",
    "* Improved security\n",
    "* Cleaner SLURM output\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_echoSummary_VERBOSE = textwrap.dedent(r\"\"\"\n",
    "    echo \"=start==============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================== ENVIRONMENT-LOG SETUP =======================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "    # --- files (set to \"\" to disable) ---\n",
    "    # Redacted env log is the safe default\n",
    "    REDACTED_ENV_LOG=\"${REDACTED_ENV_LOG:-./SLURM-environment.redacted.log}\"\n",
    "\n",
    "    # Full env log is OFF by default (enable only if you really want it)\n",
    "    FULL_ENV_LOG=\"${FULL_ENV_LOG:-}\"\n",
    "\n",
    "    # Create files as private as possible (env can contain tokens)\n",
    "    umask 077\n",
    "\n",
    "    # Regex (case-insensitive) for variable names that should be redacted\n",
    "    # Tune as needed for your environment.\n",
    "    REDACT_ENV_NAME_REGEX='(TOKEN|SECRET|PASSWORD|PASS|PWD|KEY|API|AUTH|BEARER|COOKIE|CREDENTIAL|PRIVATE|SSH|AWS|AZURE|GCP|GOOGLE|SLACK|GITHUB|GITLAB|JWT|SAS|SIGNATURE|SESSION|SENTRY|MONGO|DBPASS|DB_PASSWORD|DATABASE_URL|CONNECTION_STRING)'\n",
    "\n",
    "    redact_env_stream () {\n",
    "      # Reads KEY=VALUE lines, outputs redacted KEY=... when KEY matches regex,\n",
    "      # and also masks credentials embedded in URLs like scheme://user:pass@host\n",
    "      awk -v re=\"$REDACT_ENV_NAME_REGEX\" '\n",
    "        BEGIN { IGNORECASE=1 }\n",
    "        {\n",
    "          line=$0\n",
    "          split(line, a, \"=\")\n",
    "          key=a[1]\n",
    "          val=substr(line, length(key)+2)\n",
    "\n",
    "          # redact by variable name\n",
    "          if (key ~ re) {\n",
    "            print key \"=<REDACTED>\"\n",
    "            next\n",
    "          }\n",
    "\n",
    "          # redact creds embedded in URLs: scheme://user:pass@host -> scheme://<REDACTED>@host\n",
    "          gsub(/:\\/\\/[^\\/:@]+:[^\\/@]+@/, \"://<REDACTED>@\", line)\n",
    "\n",
    "          print line\n",
    "        }\n",
    "      '\n",
    "    }\n",
    "\n",
    "    if [[ -n \"${REDACTED_ENV_LOG}\" ]]; then\n",
    "      echo \"Redacted environment will be written to: ${REDACTED_ENV_LOG}\" >> \"$SUMMARY_SHORT\"\n",
    "      {\n",
    "        echo \"===================================================================\"\n",
    "        echo \"REDACTED ENVIRONMENT DUMP (env | sort)\"\n",
    "        echo \"Generated: $(date -Is)\"\n",
    "        echo \"Redaction rule: names matching /${REDACT_ENV_NAME_REGEX}/ -> <REDACTED>\"\n",
    "        echo \"Also masks URL credentials like scheme://user:pass@host\"\n",
    "        echo \"===================================================================\"\n",
    "        env | sort | redact_env_stream\n",
    "        echo \"===================================================================\"\n",
    "      } > \"${REDACTED_ENV_LOG}\"\n",
    "    else\n",
    "      echo \"Redacted environment dump disabled (REDACTED_ENV_LOG is empty).\" >> \"$SUMMARY_SHORT\"\n",
    "    fi\n",
    "\n",
    "    if [[ -n \"${FULL_ENV_LOG}\" ]]; then\n",
    "      echo \"WARNING: full environment dump ENABLED: ${FULL_ENV_LOG}\" >> \"$SUMMARY_SHORT\"\n",
    "      {\n",
    "        echo \"===================================================================\"\n",
    "        echo \"FULL ENVIRONMENT DUMP (env | sort)\"\n",
    "        echo \"Generated: $(date -Is)\"\n",
    "        echo \"===================================================================\"\n",
    "        env | sort\n",
    "        echo \"===================================================================\"\n",
    "      } > \"${FULL_ENV_LOG}\"\n",
    "    else\n",
    "      echo \"Full environment dump not enabled (FULL_ENV_LOG is empty).\" >> \"$SUMMARY_SHORT\"\n",
    "    fi\n",
    "\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Argument and environment-variable summary helpers\n",
    "\n",
    "These two small snippets are plugged into the main summary block via the '__echoSummary_ARGS__' and '__echoSummary_ENV_VARS__' placeholders. They keep the Jupyter-generated script readable while still providing a rich job summary.\n",
    "\n",
    "#### 4a. Log App (Arguments bash_script_echoSummary_ARGS)\n",
    "\n",
    "This helper records **what is actually being run** and **with which arguments**:\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "* BINARYNAME\n",
    "  The executable or driver being launched (e.g., OpenSees, OpenSeesMP, python, etc.). Capturing this is useful when you have multiple entry points or versions and want to verify which one this job used.\n",
    "\n",
    "* ARGS ('$*')\n",
    "  The full, space-separated list of command-line arguments passed into the app’s main binary. This gives a single, human-readable line summarizing the effective runtime configuration (input file, flags, options) as seen by the executable.\n",
    "\n",
    "Together these two lines give you a quick “command line snapshot” for reproducing the run.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_echoSummary_ARGS = textwrap.dedent(\"\"\"\n",
    "    echo \"BINARYNAME     : ${BINARYNAME}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"ARGS           : $*\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. Log Environment Variable\n",
    "\n",
    "This helper captures **higher-level environment knobs** that control how the job environment is prepared, plus some optional MPI/SLURM diagnostics.\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "Environment “knobs” (each shows **<unset>** if not defined):\n",
    "\n",
    "* **MODULE_LOADS_LIST** / **MODULE_LOADS_FILE**\n",
    "  Describe which environment modules (e.g., *hdf5*, *opensees*) should be loaded. One is for inline lists; the other can point to a file listing modules.\n",
    "\n",
    "* **PIP_INSTALLS_LIST** / **PIP_INSTALLS_FILE**\n",
    "  Optional Python package installs to perform at runtime (inline list vs. file-driven). This is useful for lightweight, job-specific Python environments.\n",
    "\n",
    "* **GET_TACC_OPENSEESPY**\n",
    "  Switch/flag indicating whether to fetch a TACC-provided OpenSeesPy setup.\n",
    "\n",
    "* **UNZIP_FILES_LIST**\n",
    "  Files or archives to unzip before execution (e.g., input bundles).\n",
    "\n",
    "* **PATH_COPY_IN_LIST**\n",
    "  Paths to copy *into* the job’s working directory prior to running the app.\n",
    "\n",
    "* **DELETE_COPIED_IN_ON_EXIT**\n",
    "  If set to a true-like value, removes files or directories that were copied into the job working directory via PATH_COPY_IN_LIST after the job completes, preventing temporary inputs from being included in the final archive..\n",
    "\n",
    "* **ZIP_OUTPUT_SWITCH**\n",
    "  Controls whether output should be zipped at the end of the job.\n",
    "\n",
    "* **PATH_MOVE_OUTPUT**\n",
    "  Destination path to move packaged output to (e.g., a work or archive directory).\n",
    "\n",
    "These lines make it very easy to see, after the fact, how the environment and I/O preparation were configured for a given run.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_echoSummary_ENV_VARS = textwrap.dedent(\"\"\"\n",
    "    echo \"  MODULE_LOADS_FILE        : ${MODULE_LOADS_FILE:-<unset>}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"  PIP_INSTALLS_FILE        : ${PIP_INSTALLS_FILE:-<unset>}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"  GET_TACC_OPENSEESPY      : ${GET_TACC_OPENSEESPY:-<unset>}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"  UNZIP_FILES_LIST         : ${UNZIP_FILES_LIST:-<unset>}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"  PATH_COPY_IN_LIST        : ${PATH_COPY_IN_LIST:-<unset>}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"  DELETE_COPIED_IN_ON_EXIT : ${DELETE_COPIED_IN_ON_EXIT:-<unset>}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"  ZIP_OUTPUT_SWITCH        : ${ZIP_OUTPUT_SWITCH:-<unset>}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"  PATH_MOVE_OUTPUT         : ${PATH_MOVE_OUTPUT:-<unset>}\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Log MPI/SLURM diagnostics\n",
    "\n",
    "The block then prints some **optional MPI info**, purely for logging.\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "\n",
    "* It computes a **rank** (**RANK**) and **world size** (**SIZE**) in a robust way, checking common environment variables from:\n",
    "\n",
    "  * PMI (*PMI_RANK*, *PMI_SIZE*),\n",
    "  * OpenMPI (*OMPI_COMM_WORLD_RANK*, *OMPI_COMM_WORLD_SIZE*),\n",
    "  * SLURM (*SLURM_PROCID*, *SLURM_NTASKS*).\n",
    "* It also records the short hostname (*HOST*).\n",
    "\n",
    "These values are then written to **SUMMARY_SHORT** with explanatory messages. As the inline comment notes, **these MPI-derived values are *not* used to control the app**—they’re just there to document how the job “looks” from an MPI/SLURM perspective, which can be very helpful when debugging parallel vs. non-parallel runs or Slurm task layouts.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_echoSummary_MPI = textwrap.dedent(\"\"\"\n",
    "    echo \"================= MPI INFO (optional info) =======================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"# -- mpi info: pick up rank and world size across IMPI/OpenMPI/SLURM. none of these are used by the app/SLURM job!\" >> \"$SUMMARY_SHORT\"\n",
    "    RANK=${PMI_RANK:-${OMPI_COMM_WORLD_RANK:-${SLURM_PROCID:-0}}}\n",
    "    SIZE=${PMI_SIZE:-${OMPI_COMM_WORLD_SIZE:-${SLURM_NTASKS:-1}}}\n",
    "    HOST=$(hostname -s)\n",
    "    echo \"RANK: $RANK -- RANK should be zero since it belongs to the SLURM-JOB-APP, which is not run via an MPI!\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"of SIZE: $SIZE\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"on Host: $HOST\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"MPI rank/size: $RANK / $SIZE\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Error-path timing summary (run vs. total)\n",
    "\n",
    "This block computes and records **timing information when the job exits via an error path**. It assumes that RUN_START_EPOCH and TOTAL_START_EPOCH were captured earlier in the script.\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "A. **Capture end times**\n",
    "\n",
    "```bash\n",
    "RUN_END_EPOCH=$(date +%s)\n",
    "RUN_END_HUMAN=\"$(date)\"\n",
    "...\n",
    "TOTAL_END_EPOCH=$(date +%s)\n",
    "TOTAL_END_HUMAN=\"$(date)\"\n",
    "```\n",
    "\n",
    "* RUN_END_EPOCH / RUN_END_HUMAN\n",
    "  The end time (in seconds since epoch and human-readable form) for just the **binary run** portion of the job (e.g., OpenSees / OpenSeesMP execution window).\n",
    "\n",
    "* TOTAL_END_EPOCH / TOTAL_END_HUMAN\n",
    "  The end time for the **entire script**, including setup, pre/post-processing, and the binary run.\n",
    "\n",
    "B. **Compute durations and split into h/m/s**\n",
    "\n",
    "```bash\n",
    "RUN_DURATION=$(( RUN_END_EPOCH - RUN_START_EPOCH ))\n",
    "RH=$(( RUN_DURATION / 3600 ))\n",
    "RM=$(( (RUN_DURATION % 3600) / 60 ))\n",
    "RS=$(( RUN_DURATION % 60 ))\n",
    "\n",
    "TOTAL_DURATION=$(( TOTAL_END_EPOCH - TOTAL_START_EPOCH ))\n",
    "TH=$(( TOTAL_DURATION / 3600 ))\n",
    "TM=$(( (TOTAL_DURATION % 3600) / 60 ))\n",
    "TS=$(( TOTAL_DURATION % 60 ))\n",
    "```\n",
    "\n",
    "* RUN_DURATION is the elapsed time (in seconds) for the **binary run** only.\n",
    "  It’s then decomposed into RH (hours), RM (minutes), and RS (seconds).\n",
    "\n",
    "* TOTAL_DURATION is the elapsed time for the **full script lifetime**, likewise decomposed into TH, TM, and TS.\n",
    "\n",
    "This split makes it easy to glance at both the total runtime and the heavy compute portion.\n",
    "\n",
    "C. **Log timing details to the summary (on error)**\n",
    "\n",
    "```bash\n",
    "echo \"Run end time (on error): ${RUN_END_HUMAN}\" >> \"$SUMMARY_SHORT\"\n",
    "echo \"Run end epoch (on error): ${RUN_END_EPOCH}\" >> \"$SUMMARY_SHORT\"\n",
    "echo \"Binary run runtime (on error): ${RH}h ${RM}m ${RS}s (${RUN_DURATION} seconds)\" >> \"$SUMMARY_SHORT\"\n",
    "...\n",
    "echo \"Total script runtime (on error): ${TH}h ${TM}m ${TS}s (${TOTAL_DURATION} seconds)\" >> \"$SUMMARY_SHORT\"\n",
    "```\n",
    "\n",
    "All values are appended to SUMMARY_SHORT with explicit **“(on error)”** annotations, so the user knows this timing snapshot comes from an abnormal termination path rather than the normal job footer.\n",
    "\n",
    "* The **binary runtime** lines answer:\n",
    "  *“How long did the core application actually run before failing?”*\n",
    "\n",
    "* The **total script runtime** lines answer:\n",
    "  *“How long was this SLURM job alive in total, including setup and teardown?”*\n",
    "\n",
    "This error-timer block gives a clear post-mortem view of when the failure occurred and how much wall-clock time was spent in the main compute segment versus the overall job.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_echoTimers_START = textwrap.dedent(\"\"\"\n",
    "\n",
    "        echo \"=start==============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "        echo \"===================== TIMERS AFTER RUN ============================\" >> \"$SUMMARY_SHORT\"\n",
    "        echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "        # ---- TIMERS: run + total on error ----\n",
    "        RUN_END_EPOCH=$(date +%s)\n",
    "        RUN_END_HUMAN=\"$(date)\"\n",
    "        RUN_DURATION=$(( RUN_END_EPOCH - RUN_START_EPOCH ))\n",
    "        RH=$(( RUN_DURATION / 3600 ))\n",
    "        RM=$(( (RUN_DURATION % 3600) / 60 ))\n",
    "        RS=$(( RUN_DURATION % 60 ))\n",
    "    \n",
    "        TOTAL_END_EPOCH=$(date +%s)\n",
    "        TOTAL_END_HUMAN=\"$(date)\"\n",
    "        TOTAL_DURATION=$(( TOTAL_END_EPOCH - TOTAL_START_EPOCH ))\n",
    "        TH=$(( TOTAL_DURATION / 3600 ))\n",
    "        TM=$(( (TOTAL_DURATION % 3600) / 60 ))\n",
    "        TS=$(( TOTAL_DURATION % 60 ))\n",
    "    \n",
    "    \n",
    "        echo \"==============\" >> \"$SUMMARY_SHORT\"\n",
    "        echo \"Run end time (on error): ${RUN_END_HUMAN}\" >> \"$SUMMARY_SHORT\"\n",
    "        echo \"Run end epoch (on error): ${RUN_END_EPOCH}\" >> \"$SUMMARY_SHORT\"\n",
    "        echo \"Binary run runtime (on error): ${RH}h ${RM}m ${RS}s (${RUN_DURATION} seconds)\" >> \"$SUMMARY_SHORT\"\n",
    "        echo \"\" >> \"$SUMMARY_SHORT\"\n",
    "        echo \"Total end time (on error): ${TOTAL_END_HUMAN}\" >> \"$SUMMARY_SHORT\"\n",
    "        echo \"Total end epoch (on error): ${TOTAL_END_EPOCH}\" >> \"$SUMMARY_SHORT\"\n",
    "        echo \"Total script runtime (on error): ${TH}h ${TM}m ${TS}s (${TOTAL_DURATION} seconds)\" >> \"$SUMMARY_SHORT\"\n",
    "        echo \"==============\" >> \"$SUMMARY_SHORT\"\n",
    "        echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Success-path timing summary (binary run only)\n",
    "\n",
    "This block records **how long the main binary ran when it completes successfully**. It assumes RUN_START_EPOCH was set earlier, right before launching the main executable.\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "1. **Capture end time of the binary run**\n",
    "\n",
    "```bash\n",
    "RUN_END_EPOCH=$(date +%s)\n",
    "RUN_END_HUMAN=\"$(date)\"\n",
    "```\n",
    "\n",
    "* RUN_END_EPOCH is the end time in seconds since the Unix epoch.\n",
    "* RUN_END_HUMAN is the same time in a human-readable string (from date).\n",
    "\n",
    "2. **Compute elapsed runtime and split into h/m/s**\n",
    "\n",
    "```bash\n",
    "RUN_DURATION=$(( RUN_END_EPOCH - RUN_START_EPOCH ))\n",
    "RH=$(( RUN_DURATION / 3600 ))\n",
    "RM=$(( (RUN_DURATION % 3600) / 60 ))\n",
    "RS=$(( RUN_DURATION % 60 ))\n",
    "```\n",
    "\n",
    "* RUN_DURATION is the total elapsed time (in seconds) for the **main binary run**.\n",
    "* RH, RM, RS break that into hours, minutes, and seconds for easier reading.\n",
    "\n",
    "3. **Append a concise timing block to the summary log**\n",
    "\n",
    "```bash\n",
    "echo \"==============\" >> \"$SUMMARY_SHORT\"\n",
    "echo \"Run end time: ${RUN_END_HUMAN}\" >> \"$SUMMARY_SHORT\"\n",
    "echo \"Run end epoch: ${RUN_END_EPOCH}\" >> \"$SUMMARY_SHORT\"\n",
    "echo \"Binary run runtime: ${RH}h ${RM}m ${RS}s (${RUN_DURATION} seconds)\" >> \"$SUMMARY_SHORT\"\n",
    "echo \"==============\" >> \"$SUMMARY_SHORT\"\n",
    "```\n",
    "\n",
    "These lines write a small, clearly delimited footer to SUMMARY_SHORT that tells you:\n",
    "\n",
    "* When the binary finished (Run end time, both human and epoch),\n",
    "* How long it ran (Binary run runtime in h:m:s and raw seconds).\n",
    "\n",
    "Unlike the error-path timer block, this snippet is used for the **normal, successful completion of the binary run** and focuses only on the binary’s runtime, not the total script lifetime.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_echoTimers_AFTER = textwrap.dedent(\"\"\"\n",
    "\n",
    "    echo \"=start==============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================== TIMERS AT END RUN ===========================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    # ---- TIMER: binary run success ----\n",
    "    RUN_END_EPOCH=$(date +%s)\n",
    "    RUN_END_HUMAN=\"$(date)\"\n",
    "    RUN_DURATION=$(( RUN_END_EPOCH - RUN_START_EPOCH ))\n",
    "    RH=$(( RUN_DURATION / 3600 ))\n",
    "    RM=$(( (RUN_DURATION % 3600) / 60 ))\n",
    "    RS=$(( RUN_DURATION % 60 ))\n",
    "\n",
    "\n",
    "    echo \"==============\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"Run end time: ${RUN_END_HUMAN}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"Run end epoch: ${RUN_END_EPOCH}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"Binary run runtime: ${RH}h ${RM}m ${RS}s (${RUN_DURATION} seconds)\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"==============\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Final total-runtime footer (successful script completion)\n",
    "This block adds a **“job is fully done”** footer to the summary log, capturing how long the *entire* SLURM script ran when it exits cleanly.\n",
    "\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "\n",
    "1. **Visual separator**\n",
    "\n",
    "```bash\n",
    "echo \"===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "```\n",
    "\n",
    "Adds a strong horizontal divider so it’s obvious where the final timing section begins.\n",
    "\n",
    "2. **Capture total script end time**\n",
    "\n",
    "```bash\n",
    "TOTAL_END_EPOCH=$(date +%s)\n",
    "TOTAL_END_HUMAN=\"$(date)\"\n",
    "TOTAL_DURATION=$(( TOTAL_END_EPOCH - TOTAL_START_EPOCH ))\n",
    "TH=$(( TOTAL_DURATION / 3600 ))\n",
    "TM=$(( (TOTAL_DURATION % 3600) / 60 ))\n",
    "TS=$(( TOTAL_DURATION % 60 ))\n",
    "```\n",
    "\n",
    "* TOTAL_END_EPOCH / TOTAL_END_HUMAN:\n",
    "  When the script fully finishes (in epoch seconds and human-readable form).\n",
    "\n",
    "* TOTAL_DURATION:\n",
    "  Wall-clock time from TOTAL_START_EPOCH (set near the top of the script) to final exit — this includes:\n",
    "\n",
    "  * Environment/module setup\n",
    "  * Any pre-processing\n",
    "  * The main binary run\n",
    "  * Any post-processing and packaging\n",
    "\n",
    "* TH, TM, TS:\n",
    "  The total duration broken into hours, minutes, and seconds.\n",
    "\n",
    "3. **Write a clear “script is done” block**\n",
    "\n",
    "```bash\n",
    "echo \"==============\" >> \"$SUMMARY_SHORT\"\n",
    "echo \"Total end time: ${TOTAL_END_HUMAN}\" >> \"$SUMMARY_SHORT\"\n",
    "echo \"Total end epoch: ${TOTAL_END_EPOCH}\" >> \"$SUMMARY_SHORT\"\n",
    "echo \"Total script runtime (including setup + post): ${TH}h ${TM}m ${TS}s (${TOTAL_DURATION} seconds)\" >> \"$SUMMARY_SHORT\"\n",
    "echo \"DONE!!!\" >> \"$SUMMARY_SHORT\"\n",
    "echo \"==============\" >> \"$SUMMARY_SHORT\"\n",
    "```\n",
    "\n",
    "This footer:\n",
    "\n",
    "* Marks the **final end time** of the job,\n",
    "* Reports the **full script runtime**, explicitly noting that it includes setup and post-processing,\n",
    "* Finishes with a loud, human-readable \"DONE!!!\" so that a quick scan of the summary log immediately confirms a successful, end-to-end completion.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_echoTimers_END = textwrap.dedent(\"\"\"\n",
    "\n",
    "    echo \"=start==============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================== TIMERS AT END TOTAL =========================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "    # ---- TIMER: total script success ----\n",
    "    TOTAL_END_EPOCH=$(date +%s)\n",
    "    TOTAL_END_HUMAN=\"$(date)\"\n",
    "    TOTAL_DURATION=$(( TOTAL_END_EPOCH - TOTAL_START_EPOCH ))\n",
    "    TH=$(( TOTAL_DURATION / 3600 ))\n",
    "    TM=$(( (TOTAL_DURATION % 3600) / 60 ))\n",
    "    TS=$(( TOTAL_DURATION % 60 ))\n",
    "\n",
    "    echo \"==============\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"Total end time: ${TOTAL_END_HUMAN}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"Total end epoch: ${TOTAL_END_EPOCH}\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"Total script runtime (including setup + post): ${TH}h ${TM}m ${TS}s (${TOTAL_DURATION} seconds)\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"DONE!!!\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"==============\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Optional pre-run copy of input files/directories (with optional cleanup)\n",
    "\n",
    "This block implements an **optional “copy-in” step** that pulls files or directories into the current working directory **before the main run**, and (optionally) **removes those copied items after the job completes**.\n",
    "\n",
    "The behavior is entirely driven by environment variables and requires **no changes to the application code**.\n",
    "\n",
    "* `PATH_COPY_IN_LIST` — what to copy in\n",
    "* `DELETE_COPIED_IN_ON_EXIT` — whether copied items should be deleted at job end\n",
    "\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "\n",
    "---\n",
    "\n",
    "**A. Section header in the summary log**\n",
    "\n",
    "```bash\n",
    "echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "echo \" ---- copy files or directories over, optional ---- \" >> \"$SUMMARY_SHORT\"\n",
    "```\n",
    "\n",
    "This simply marks, in `SUMMARY_SHORT`, that a copy-in phase may occur.\n",
    "\n",
    "---\n",
    "\n",
    "**B. Initialize copy-in tracking and cleanup controls**\n",
    "\n",
    "```bash\n",
    "COPY_IN_MANIFEST=\"${COPY_IN_MANIFEST:-.tapis_copy_in_manifest.txt}\"\n",
    "DELETE_COPIED_IN_ON_EXIT=\"${DELETE_COPIED_IN_ON_EXIT:-0}\"\n",
    ": > \"${COPY_IN_MANIFEST}\"\n",
    "```\n",
    "\n",
    "* `COPY_IN_MANIFEST` records **exactly which paths were copied into the working directory** during this job.\n",
    "* The manifest is created (or cleared) at the start of the run.\n",
    "* Cleanup is **opt-in** and only occurs if:\n",
    "\n",
    "  ```bash\n",
    "  DELETE_COPIED_IN_ON_EXIT=1\n",
    "  ```\n",
    "\n",
    "This ensures deletion is **explicit, traceable, and reproducible**.\n",
    "\n",
    "---\n",
    "\n",
    "**C. Register a cleanup handler (runs on success or failure)**\n",
    "\n",
    "```bash\n",
    "trap cleanup_copied_in EXIT\n",
    "```\n",
    "\n",
    "A cleanup function is registered using a Bash `EXIT` trap, meaning it runs:\n",
    "\n",
    "* after a successful job\n",
    "* after an application error\n",
    "* after an unexpected script failure\n",
    "\n",
    "This guarantees consistent cleanup behavior whenever it is enabled.\n",
    "\n",
    "---\n",
    "\n",
    "**D. Check whether any paths were requested**\n",
    "\n",
    "```bash\n",
    "if [[ -n \"${PATH_COPY_IN_LIST:-}\" ]]; then\n",
    "```\n",
    "\n",
    "* If `PATH_COPY_IN_LIST` is **unset or empty**, the entire block is skipped.\n",
    "* If set, it must be a **comma-separated list of paths** to files or directories to copy into the working directory.\n",
    "\n",
    "Example:\n",
    "\n",
    "```bash\n",
    "PATH_COPY_IN_LIST=\"/work2/data/mesh,/scratch/configs,input.dat\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**E. Parse the comma-separated list**\n",
    "\n",
    "```bash\n",
    "IFS=',' read -ra _copy_items <<< \"${PATH_COPY_IN_LIST}\"\n",
    "```\n",
    "\n",
    "This splits the list into an array (`_copy_items`) so each entry can be handled independently.\n",
    "\n",
    "---\n",
    "\n",
    "**F. Iterate over requested paths (trimming, validation, copy, and tracking)**\n",
    "\n",
    "```bash\n",
    "for _src in \"${_copy_items[@]}\"; do\n",
    "  # Trim leading/trailing whitespace\n",
    "  _src=\"${_src#\"${_src%%[![:space:]]*}\"}\"\n",
    "  _src=\"${_src%\"${_src##*[![:space:]]}\"}\"\n",
    "\n",
    "  [[ -z \"${_src}\" ]] && continue\n",
    "\n",
    "  if [[ -e \"${_src}\" ]]; then\n",
    "    rsync -av -- \"${_src}\" .\n",
    "    _base=\"$(basename -- \"${_src}\")\"\n",
    "    printf '%s\\n' \"${_base}\" >> \"${COPY_IN_MANIFEST}\"\n",
    "    echo \"Copied in from: ${_src} -> $(pwd)\" >> \"$SUMMARY_SHORT\"\n",
    "  else\n",
    "    echo \"WARNING: path to copy does not exist: ${_src}\"\n",
    "    echo \"WARNING: path to copy does not exist: ${_src}\" >> \"$SUMMARY_SHORT\"\n",
    "  fi\n",
    "done\n",
    "```\n",
    "\n",
    "For each candidate path:\n",
    "\n",
    "• Whitespace trimming\n",
    "\n",
    "    Leading and trailing spaces are removed, allowing clean usage like:\n",
    "    \n",
    "    ```bash\n",
    "    PATH_COPY_IN_LIST=\"input1, input2, /some/other/dir\"\n",
    "    ```\n",
    "\n",
    "• Skip empty entries\n",
    "\n",
    "    Trailing commas or consecutive commas produce empty entries, which are safely ignored.\n",
    "    \n",
    "    • Existence check\n",
    "    \n",
    "    * If the source exists:\n",
    "    \n",
    "      * `rsync -av` copies it into the **current working directory (`.`)**.\n",
    "      * Both files and directories are supported.\n",
    "      * The **destination name** (basename) is written to the copy-in manifest for potential cleanup.\n",
    "      * The action is logged to `SUMMARY_SHORT`.\n",
    "    \n",
    "    * If the source does not exist:\n",
    "    \n",
    "      * A warning is printed to stdout and recorded in the summary log for diagnostics.\n",
    "\n",
    "---\n",
    "\n",
    "**G. Optional cleanup at job completion**\n",
    "\n",
    "If the user enables cleanup:\n",
    "\n",
    "```bash\n",
    "DELETE_COPIED_IN_ON_EXIT=1\n",
    "```\n",
    "\n",
    "the cleanup handler:\n",
    "\n",
    "* reads the copy-in manifest\n",
    "* deletes **only the paths that were copied in**\n",
    "* refuses to delete:\n",
    "\n",
    "  * absolute paths\n",
    "  * paths containing `..`\n",
    "  * anything outside the working directory\n",
    "\n",
    "Each deletion is logged to `SUMMARY_SHORT`, ensuring transparency and auditability.\n",
    "\n",
    "---\n",
    "\n",
    "**Why this pattern is used**\n",
    "\n",
    "This approach provides:\n",
    "\n",
    "* **Flexible input staging** without hard-coding paths into the app\n",
    "* **Fast local access** to large or frequently accessed files\n",
    "* **Reproducibility** via explicit environment variables\n",
    "* **Safety** via manifest-based deletion\n",
    "* **Clean job directories** when temporary inputs are no longer needed\n",
    "\n",
    "It is especially useful for large meshes, auxiliary scripts, configuration directories, or scratch-only inputs that should not persist beyond the job lifecycle.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_option_COPY_FILES = textwrap.dedent(\"\"\"\n",
    "    echo \"=start==============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"=========== PRE-RUN COPY OF INPUT FILES/DIRECTORIES ===============\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "\n",
    "    COPY_IN_MANIFEST=\"${COPY_IN_MANIFEST:-.copy_in_manifest.txt}\"\n",
    "    DELETE_COPIED_IN_ON_EXIT=\"${DELETE_COPIED_IN_ON_EXIT:-0}\"\n",
    "    \n",
    "    # Create/clear manifest for this run\n",
    "    : > \"${COPY_IN_MANIFEST}\"\n",
    "    \n",
    "    cleanup_copied_in() {\n",
    "      # Only delete if explicitly enabled\n",
    "      [[ \"${DELETE_COPIED_IN_ON_EXIT}\" == \"1\" ]] || return 0\n",
    "    \n",
    "      # Only act if manifest exists and is non-empty\n",
    "      [[ -s \"${COPY_IN_MANIFEST}\" ]] || return 0\n",
    "    \n",
    "      echo \"Cleanup enabled: deleting copied-in items listed in ${COPY_IN_MANIFEST}\" | tee -a \"$SUMMARY_SHORT\"\n",
    "    \n",
    "      # Delete only paths inside the current working directory\n",
    "      while IFS= read -r _rel; do\n",
    "        [[ -z \"${_rel}\" ]] && continue\n",
    "    \n",
    "        # Safety: disallow absolute paths and parent traversal\n",
    "        if [[ \"${_rel}\" = /* ]] || [[ \"${_rel}\" == *\"..\"* ]]; then\n",
    "          echo \"WARNING: refusing to delete suspicious path from manifest: ${_rel}\" | tee -a \"$SUMMARY_SHORT\"\n",
    "          continue\n",
    "        fi\n",
    "    \n",
    "        # Safety: ensure it actually exists in $PWD\n",
    "        if [[ -e \"${_rel}\" ]]; then\n",
    "          rm -rf -- \"${_rel}\"\n",
    "          echo \"Deleted copied-in item: ${_rel}\" | tee -a \"$SUMMARY_SHORT\"\n",
    "        fi\n",
    "      done < \"${COPY_IN_MANIFEST}\"\n",
    "    }\n",
    "    \n",
    "    # Ensure cleanup runs on exit (success or failure)\n",
    "    trap cleanup_copied_in EXIT\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    echo \" ---- copy files or directories over, optional ---- \" >> \"$SUMMARY_SHORT\"\n",
    "    if [[ -n \"${PATH_COPY_IN_LIST:-}\" ]]; then\n",
    "      IFS=',' read -ra _copy_items <<< \"${PATH_COPY_IN_LIST}\"\n",
    "\n",
    "      for _src in \"${_copy_items[@]}\"; do\n",
    "        # Trim leading/trailing whitespace\n",
    "        _src=\"${_src#\"${_src%%[![:space:]]*}\"}\"\n",
    "        _src=\"${_src%\"${_src##*[![:space:]]}\"}\"\n",
    "\n",
    "        # Skip empty entries (e.g., trailing comma)\n",
    "        [[ -z \"${_src}\" ]] && continue\n",
    "\n",
    "        if [[ -e \"${_src}\" ]]; then\n",
    "          # Copy into working directory (preserve name; rsync will create dir if source is a dir)\n",
    "          rsync -av -- \"${_src}\" .\n",
    "    \n",
    "          # Track what landed in the working dir so we can delete it later if enabled\n",
    "          _base=\"$(basename -- \"${_src}\")\"\n",
    "          printf '%s\\n' \"${_base}\" >> \"${COPY_IN_MANIFEST}\"\n",
    "          \n",
    "          echo \"Copied in from: ${_src} -> $(pwd)\" >> \"$SUMMARY_SHORT\"\n",
    "        else\n",
    "          echo \"WARNING: path to copy does not exist: ${_src}\"\n",
    "          echo \"WARNING: path to copy does not exist: ${_src}\" >> \"$SUMMARY_SHORT\"\n",
    "        fi\n",
    "      done\n",
    "    fi\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Optional ZIP expansion of input bundles\n",
    "\n",
    "This block implements an **optional “unzip inputs” step** that expands one or more ZIP archives into the current working directory before the main run. It is driven by the UNZIP_FILES_LIST environment variable.\n",
    "\n",
    "**NOTE: This script is executed after the file-copy script, so that you may unzip files that have been copied into the working diretory!!**\n",
    "\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "1. **Section header + echo requested list**\n",
    "\n",
    "```bash\n",
    "echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "echo \" ---- expand input ZIP, optional ---- \"      >> \"$SUMMARY_SHORT\"\n",
    "UNZIP_FILES_LIST=\"${UNZIP_FILES_LIST:-}\"\n",
    "echo \"UNZIP_FILES_LIST list: ${UNZIP_FILES_LIST}\" >> \"$SUMMARY_SHORT\"\n",
    "```\n",
    "\n",
    "* Writes a header into SUMMARY_SHORT so the log clearly shows when ZIP expansion is being handled.\n",
    "* Normalizes UNZIP_FILES_LIST to an empty string if unset.\n",
    "* Logs the raw UNZIP_FILES_LIST value for debugging (what the job *thought* it should unzip).\n",
    "\n",
    "2. **Parse the comma-separated list (first pass)**\n",
    "\n",
    "```bash\n",
    "if [[ -n \"$UNZIP_FILES_LIST\" ]]; then\n",
    "  IFS=',' read -ra ZIP_LIST <<< \"$UNZIP_FILES_LIST\"\n",
    "  for f in \"${ZIP_LIST[@]}\"; do\n",
    "    # trim whitespace\n",
    "    f=\"$(echo \"$f\" | xargs)\"\n",
    "  done\n",
    "fi\n",
    "```\n",
    "\n",
    "* If UNZIP_FILES_LIST is non-empty, it is split on commas into ZIP_LIST.\n",
    "* Each entry is passed through xargs to **trim whitespace** (e.g., to tolerate file1, file2 , data/job.zip).\n",
    "* This first loop is effectively a “sanity pass” for the raw list.\n",
    "\n",
    "3. **Parse again and actually unzip (second pass)**\n",
    "\n",
    "```bash\n",
    "UNZIP_FILES_LIST=\"${UNZIP_FILES_LIST:-}\"\n",
    "echo \"UNZIP_FILES_LIST list: ${UNZIP_FILES_LIST}\" >> \"$SUMMARY_SHORT\"\n",
    "if [[ -n \"$UNZIP_FILES_LIST\" ]]; then\n",
    "  IFS=',' read -ra ZIP_LIST <<< \"$UNZIP_FILES_LIST\"\n",
    "  for f in \"${ZIP_LIST[@]}\"; do\n",
    "    # trim whitespace\n",
    "    f=\"$(echo \"$f\" | xargs)\"\n",
    "    [[ -z \"$f\" ]] && continue\n",
    "```\n",
    "\n",
    "* The list is echoed again (still helpful for debugging when reading the summary).\n",
    "* UNZIP_FILES_LIST is split again and each item is:\n",
    "\n",
    "  * Whitespace-trimmed,\n",
    "  * Skipped if empty ([[ -z \"$f\" ]] && continue), so stray commas do not cause errors.\n",
    "\n",
    "4. **Normalize filenames and unzip**\n",
    "\n",
    "```bash\n",
    "    # add .zip if missing\n",
    "    case \"$f\" in\n",
    "      *.zip) zipfile=\"$f\" ;;\n",
    "      *)     zipfile=\"${f}.zip\" ;;\n",
    "    esac\n",
    "\n",
    "    if [[ -f \"$zipfile\" ]]; then\n",
    "      echo \"Unzipping $zipfile ...\"\n",
    "      unzip -o -q \"$zipfile\"\n",
    "      echo \"Unzipped: $zipfile into $(pwd)\" >> \"$SUMMARY_SHORT\"\n",
    "    else\n",
    "      echo \"Warning: $zipfile not found, skipping.\"\n",
    "      echo \"WARNING: $zipfile not found, skipping unzip\" >> \"$SUMMARY_SHORT\"\n",
    "    fi\n",
    "  done\n",
    "fi\n",
    "```\n",
    "\n",
    "For each cleaned entry:\n",
    "\n",
    "* If the user **did not** include .zip, the script automatically appends it, so both input and input.zip are accepted.\n",
    "* If the resolved zipfile exists in the current directory:\n",
    "\n",
    "  * It is unzipped in-place with unzip -o -q:\n",
    "\n",
    "    * -o overwrites existing files without prompting,\n",
    "    * -q keeps output quiet in the terminal.\n",
    "  * A one-line summary (\"Unzipped: ... into $(pwd)\") is written to SUMMARY_SHORT.\n",
    "* If the file does **not** exist:\n",
    "\n",
    "  * A warning is printed to stdout and also logged to SUMMARY_SHORT, so missing ZIPs are obvious when reviewing job output.\n",
    "\n",
    "In short, this block provides a flexible, environment-driven way to expand one or more input ZIP bundles (meshes, scripts, parameter sets, etc.) into the job’s working directory without hardcoding filenames in the app logic.\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_option_UNZIP = textwrap.dedent(\"\"\"\n",
    "    echo \"=start==============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"=========== ZIP EXPANSION OF INPUT BUNDLES ========================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "    echo \" ---- expand input ZIP, optional ---- \"      >> \"$SUMMARY_SHORT\"\n",
    "    UNZIP_FILES_LIST=\"${UNZIP_FILES_LIST:-}\"\n",
    "    echo \"UNZIP_FILES_LIST list: ${UNZIP_FILES_LIST}\" >> \"$SUMMARY_SHORT\"\n",
    "    if [[ -n \"$UNZIP_FILES_LIST\" ]]; then\n",
    "      IFS=',' read -ra ZIP_LIST <<< \"$UNZIP_FILES_LIST\"\n",
    "      for f in \"${ZIP_LIST[@]}\"; do\n",
    "        # trim whitespace\n",
    "        f=\"$(echo \"$f\" | xargs)\"\n",
    "      done\n",
    "    fi\n",
    "\n",
    "    UNZIP_FILES_LIST=\"${UNZIP_FILES_LIST:-}\"\n",
    "    echo \"UNZIP_FILES_LIST list: ${UNZIP_FILES_LIST}\" >> \"$SUMMARY_SHORT\"\n",
    "    if [[ -n \"$UNZIP_FILES_LIST\" ]]; then\n",
    "      IFS=',' read -ra ZIP_LIST <<< \"$UNZIP_FILES_LIST\"\n",
    "      for f in \"${ZIP_LIST[@]}\"; do\n",
    "        # trim whitespace\n",
    "        f=\"$(echo \"$f\" | xargs)\"\n",
    "        [[ -z \"$f\" ]] && continue\n",
    "    \n",
    "        # add .zip if missing\n",
    "        case \"$f\" in\n",
    "          *.zip) zipfile=\"$f\" ;;\n",
    "          *)     zipfile=\"${f}.zip\" ;;\n",
    "        esac\n",
    "    \n",
    "        if [[ -f \"$zipfile\" ]]; then\n",
    "          echo \"Unzipping $zipfile ...\"\n",
    "          unzip -o -q \"$zipfile\"\n",
    "          echo \"Unzipped: $zipfile into $(pwd)\" >> \"$SUMMARY_SHORT\"\n",
    "        else\n",
    "          echo \"Warning: $zipfile not found, skipping.\"\n",
    "          echo \"WARNING: $zipfile not found, skipping unzip\" >> \"$SUMMARY_SHORT\"\n",
    "        fi\n",
    "      done\n",
    "    fi\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Defensive setup of the module command (before user-defined module loads)\n",
    "This block **does not actually load any modules**. Instead, it makes sure the module command itself is defined *before* later logic tries to use it with a user-provided module list or file.\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "Why this is necessary, even though module names come from the user later:\n",
    "\n",
    "* On many HPC systems, module is **not a standalone executable**; it’s a shell function or alias injected by login/profile scripts (e.g., /etc/profile.d/modules.sh).\n",
    "* Batch jobs (like Tapis/SLURM jobs) often run in a **non-interactive, non-login shell**, which may **not** source those profile scripts automatically.\n",
    "* If that happens and we immediately try to do something like module load hdf5 opensees, the job will fail with:\n",
    "\n",
    "  ```text\n",
    "  module: command not found\n",
    "  ```\n",
    "\n",
    "  even though the system *does* support modules.\n",
    "\n",
    "This snippet therefore:\n",
    "\n",
    "1. Writes a small header to SUMMARY_SHORT noting that we’re setting up the module environment.\n",
    "2. Checks if module is available:\n",
    "\n",
    "   ```bash\n",
    "   if ! command -v module >/dev/null 2>&1; then\n",
    "   ```\n",
    "\n",
    "   This catches cases where the shell hasn’t been initialized with the Modules environment.\n",
    "3. If module is missing, it **manually sources** the standard Modules init script:\n",
    "\n",
    "   ```bash\n",
    "   if [[ -f /etc/profile.d/modules.sh ]]; then\n",
    "       source /etc/profile.d/modules.sh\n",
    "   fi\n",
    "   ```\n",
    "\n",
    "   This is a defensive “bootstrap” step: it recreates what a login shell would normally do, so that module load ... will work.\n",
    "\n",
    "After this block has run, we can safely process **user-provided module lists/files** (via MODULE_LOADS_LIST, MODULE_LOADS_FILE, etc.) knowing that the module command exists. It’s basically insurance against subtle “works in interactive shell, fails in batch job” problems.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_option_MODULE_ENV_SETUP = textwrap.dedent(\"\"\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"============== DEFENSIVE SETUP OF MODULE COMMAND ==================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \" ---- set up module environment ---- \" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"Ensure 'module' command is available (defensive; usually provided by profile)\" >> \"$SUMMARY_SHORT\"\n",
    "    if ! command -v module >/dev/null 2>&1; then\n",
    "      if [[ -f /etc/profile.d/modules.sh ]]; then\n",
    "        # shellcheck source=/etc/profile.d/modules.sh\n",
    "        source /etc/profile.d/modules.sh\n",
    "      fi\n",
    "    fi\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Loading modules from a user-provided file\n",
    "\n",
    "This block defines a helper function to read a **module recipe file** and then uses it (if MODULE_LOADS_FILE is set) to configure the environment in a controlled, reproducible way.\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "    \n",
    "**A. What the helper does**\n",
    "\n",
    "load_modules_from_file is a small parser for a **module config file**. It’s designed so users (or the app) can ship a simple text file that describes all module operations, instead of hard-coding them in the script.\n",
    "\n",
    "Key behaviors:\n",
    "\n",
    "a. **Graceful skip if file doesn’t exist**\n",
    "\n",
    "   ```bash\n",
    "   [[ -f \"$reqfile\" ]] || { echo \"No module file: $reqfile (skipping)\"; return 0; }\n",
    "   ```\n",
    "\n",
    "   If the file isn’t there, it just prints a note and returns successfully (no hard failure).\n",
    "\n",
    "b. **Line-by-line parsing with comments and whitespace**\n",
    "\n",
    "   ```bash\n",
    "   while IFS= read -r raw || [[ -n \"$raw\" ]]; do\n",
    "     line=\"${raw%%#*}\"                         # strip inline comments\n",
    "     line=\"$(printf '%s' \"$line\" | awk '{$1=$1}1')\"  # trim whitespace\n",
    "     [[ -z \"$line\" ]] && continue              # skip empty/comment-only lines\n",
    "   ```\n",
    "\n",
    "   * Supports full-line comments and inline comments (# ...).\n",
    "   * Trims whitespace so users can format the file nicely.\n",
    "   * Skips blank/comment-only lines.\n",
    "\n",
    "c. **Supported commands / syntaxes**\n",
    "\n",
    "   Each non-empty line is interpreted with a case:\n",
    "\n",
    "   * purge\n",
    "\n",
    "     ```bash\n",
    "     module purge\n",
    "     ```\n",
    "\n",
    "     Clears the environment module stack. Logged to SUMMARY_SHORT. Useful to reset toolchains.\n",
    "\n",
    "   * \"use <path>\"\n",
    "\n",
    "     ```bash\n",
    "     module use /some/modulefiles/path\n",
    "     ```\n",
    "\n",
    "     Adds a directory to the MODULEPATH, allowing access to additional modulefiles.\n",
    "\n",
    "   * \"load <something>\"\n",
    "\n",
    "     ```bash\n",
    "     module load gcc/13.2\n",
    "     ```\n",
    "\n",
    "     Explicit load directive; user writes exactly what they’d type in a shell.\n",
    "\n",
    "   * ?something (line begins with literal ?)\n",
    "\n",
    "     ```bash\n",
    "     module try-load something\n",
    "     ```\n",
    "\n",
    "     Optional modules: attempt to load but **don’t treat failure as fatal**. This is handy for “use if available, otherwise ignore” cases.\n",
    "\n",
    "   * Any other non-empty token\n",
    "\n",
    "     ```bash\n",
    "     module load $line\n",
    "     ```\n",
    "\n",
    "     For simple lines like hdf5 or opensees, it assumes module load <line>.\n",
    "\n",
    "   Every action is mirrored into SUMMARY_SHORT for later auditing.\n",
    "\n",
    "**B. How it’s used with MODULE_LOADS_FILE**\n",
    "\n",
    "After defining the helper, the script:\n",
    "\n",
    "a. Logs the configuration:\n",
    "\n",
    "   ```bash\n",
    "   echo \"MODULE_LOADS_FILE: ${MODULE_LOADS_FILE:-}\" >> \"$SUMMARY_SHORT\"\n",
    "   ```\n",
    "\n",
    "b. If MODULE_LOADS_FILE is set **and** points to a real file, it:\n",
    "\n",
    "   * Prints a message to stdout (Loading modules from file: ...),\n",
    "\n",
    "   * Does a **defensive module purge** before applying the file:\n",
    "\n",
    "     ```bash\n",
    "     module purge || true\n",
    "     echo \"module purge (before MODULE_LOADS_FILE)\" >> \"$SUMMARY_SHORT\"\n",
    "     ```\n",
    "\n",
    "     This helps avoid weird toolchain conflicts from whatever modules might already be loaded (from system defaults, profiles, etc.). The file itself can still contain its own purge if needed, but this gives you a clean starting point.\n",
    "\n",
    "   * Calls load_modules_from_file \"$MODULE_LOADS_FILE\" to apply the recipe.\n",
    "\n",
    "   * Runs module list || true so the final module state is visible in the job output.\n",
    "\n",
    "   * Logs that user-defined modules were loaded.\n",
    "\n",
    "**C. Why do this if we also support a “list” variable?**\n",
    "\n",
    "You’re giving users **two ways** to specify modules:\n",
    "\n",
    "* A **file-based recipe** (MODULE_LOADS_FILE), which:\n",
    "\n",
    "  * Supports comments,\n",
    "  * Supports ordering, purge, use, load, and optional ?module,\n",
    "  * Can be version-controlled alongside the app.\n",
    "\n",
    "* A **simple list variable** (MODULE_LOADS_LIST, handled elsewhere), which is great for quick overrides or programmatic injection.\n",
    "\n",
    "This block specifically handles the **file-based, richer syntax**:\n",
    "\n",
    "* It centralizes all the module operations in one place (the file), instead of scattering module load ... calls throughout the script.\n",
    "* It gives power users a way to express more complex sequences (e.g., purge, use /path, load toolchain, ?debug-tools) while still keeping the main wrapper script generic.\n",
    "* It makes the environment **reproducible and inspectable**: you can archive the module file with the job, and the summary log clearly shows every module action that was executed.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_option_MODULE_LOAD_FILE = textwrap.dedent(r\"\"\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"========== LOADING MODULES FROM A USER-PROVIDED FILE ==============\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \" ---- helper function: load modules from a file (supports comments, purge, use, ?optional, load) ----\" >> \"$SUMMARY_SHORT\"\n",
    "    load_modules_from_file() {\n",
    "      local reqfile=\"$1\"\n",
    "      [[ -f \"$reqfile\" ]] || { echo \"No module file: $reqfile (skipping)\"; return 0; }\n",
    "\n",
    "      while IFS= read -r raw || [[ -n \"$raw\" ]]; do\n",
    "        # strip inline comments and trim\n",
    "        line=\"${raw%%#*}\"\n",
    "        line=\"$(printf '%s' \"$line\" | awk '{$1=$1}1')\"\n",
    "        [[ -z \"$line\" ]] && continue\n",
    "\n",
    "        case \"$line\" in\n",
    "          purge)\n",
    "            module purge\n",
    "            echo \"module purge (from MODULE_LOADS_FILE)\" >> \"$SUMMARY_SHORT\"\n",
    "            ;;\n",
    "          \"use \"*)\n",
    "            # NOTE: do NOT lowercase paths (could be case-sensitive)\n",
    "            usepath=\"${line#use }\"\n",
    "            usepath=\"$(printf '%s' \"$usepath\" | awk '{$1=$1}1')\"\n",
    "            module use \"$usepath\"\n",
    "            echo \"module use $usepath (from MODULE_LOADS_FILE)\" >> \"$SUMMARY_SHORT\"\n",
    "            ;;\n",
    "          \"load \"*)\n",
    "            orig=\"${line#load }\"\n",
    "            orig=\"$(printf '%s' \"$orig\" | awk '{$1=$1}1')\"\n",
    "            mod=\"${orig,,}\"   # lowercase module name\n",
    "\n",
    "            if [[ \"$mod\" != \"$orig\" ]]; then\n",
    "              echo \"NOTE: lowercased module name: '$orig' -> '$mod' (from MODULE_LOADS_FILE)\" >> \"$SUMMARY_SHORT\"\n",
    "            fi\n",
    "\n",
    "            if module load \"$mod\"; then\n",
    "              echo \"module load $mod (from MODULE_LOADS_FILE)\" >> \"$SUMMARY_SHORT\"\n",
    "            else\n",
    "              echo \"WARNING: module load failed: $mod (from MODULE_LOADS_FILE)\" >> \"$SUMMARY_SHORT\"\n",
    "            fi\n",
    "            ;;\n",
    "          \\?*)\n",
    "            # optional module lines that start with literal '?'\n",
    "            orig=\"${line#\\?}\"\n",
    "            orig=\"$(printf '%s' \"$orig\" | awk '{$1=$1}1')\"\n",
    "            mod=\"${orig,,}\"   # lowercase module name\n",
    "\n",
    "            if [[ \"$mod\" != \"$orig\" ]]; then\n",
    "              echo \"NOTE: lowercased optional module name: '$orig' -> '$mod' (from MODULE_LOADS_FILE)\" >> \"$SUMMARY_SHORT\"\n",
    "            fi\n",
    "\n",
    "            if module try-load \"$mod\"; then\n",
    "              echo \"module try-load $mod (from MODULE_LOADS_FILE)\" >> \"$SUMMARY_SHORT\"\n",
    "            else\n",
    "              echo \"WARNING: module try-load failed: $mod (from MODULE_LOADS_FILE)\" >> \"$SUMMARY_SHORT\"\n",
    "            fi\n",
    "            ;;\n",
    "          *)\n",
    "            orig=\"$line\"\n",
    "            mod=\"${orig,,}\"   # lowercase module name\n",
    "\n",
    "            if [[ \"$mod\" != \"$orig\" ]]; then\n",
    "              echo \"NOTE: lowercased module name: '$orig' -> '$mod' (from MODULE_LOADS_FILE)\" >> \"$SUMMARY_SHORT\"\n",
    "            fi\n",
    "\n",
    "            if module load \"$mod\"; then\n",
    "              echo \"module load $mod (from MODULE_LOADS_FILE)\" >> \"$SUMMARY_SHORT\"\n",
    "            else\n",
    "              echo \"WARNING: module load failed: $mod (from MODULE_LOADS_FILE)\" >> \"$SUMMARY_SHORT\"\n",
    "            fi\n",
    "            ;;\n",
    "        esac\n",
    "\n",
    "      done < \"$reqfile\"\n",
    "    }\n",
    "\n",
    "    echo \"===========================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \" ---- modules to load from file or list (overrides/augments defaults) ----\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"MODULE_LOADS_FILE: ${MODULE_LOADS_FILE:-}\" >> \"$SUMMARY_SHORT\"\n",
    "    if [[ -n \"${MODULE_LOADS_FILE:-}\" && -f \"$MODULE_LOADS_FILE\" ]]; then\n",
    "      echo \"Loading modules from file: $MODULE_LOADS_FILE\"\n",
    "      load_modules_from_file \"$MODULE_LOADS_FILE\"\n",
    "      module list || true\n",
    "      echo \"Loaded user-defined modules from file: $MODULE_LOADS_FILE\" >> \"$SUMMARY_SHORT\"\n",
    "    fi\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Loading modules from a comma-separated list (MODULE_LOADS_LIST)\n",
    "\n",
    "This block provides a **lightweight, environment-variable–driven** way to load modules, complementary to the file-based approach handled by MODULE_LOADS_FILE.\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "It assumes that the module command has already been made available (by the earlier module-environment setup step) and that any default or file-based module configuration has already been applied. This list-based mechanism is ideal for **quick overrides or additions** without editing a module file.\n",
    "\n",
    "What it does:\n",
    "\n",
    "1. **Log the incoming configuration**\n",
    "\n",
    "   The script writes the current value of MODULE_LOADS_LIST into SUMMARY_SHORT, so you can see exactly which modules were requested for this job:\n",
    "\n",
    "   * If the variable is unset or empty, it logs an empty value and does nothing else.\n",
    "   * If it’s set, the value (e.g., gcc/13.2,hdf5, opensees) is recorded as-is for later debugging.\n",
    "\n",
    "2. **Parse the comma-separated list**\n",
    "\n",
    "   If MODULE_LOADS_LIST is non-empty:\n",
    "\n",
    "   * It is split on commas into an array of module names.\n",
    "   * Each entry is passed through xargs to **trim leading/trailing whitespace**, so both hdf5 and \" hdf5 \" work the same way.\n",
    "   * Empty entries (e.g., from trailing commas or accidental ,,) are skipped safely.\n",
    "\n",
    "3. **Load each requested module**\n",
    "\n",
    "   For each non-empty module token:\n",
    "\n",
    "   * A message like loading module <mod> ... is printed to stdout so the job output shows what’s happening in real time.\n",
    "   * module load <mod> is invoked to actually bring the module into the environment.\n",
    "   * The action is mirrored into SUMMARY_SHORT as\n",
    "     module load <mod> (from MODULE_LOADS_LIST)\n",
    "     so you have a persistent record in the summary log.\n",
    "\n",
    "Why this exists in addition to the module file:\n",
    "\n",
    "* The **file-based approach** (MODULE_LOADS_FILE) is best for structured, version-controlled environment recipes (with purge, use, optional ?module, etc.).\n",
    "* The **list-based approach** (MODULE_LOADS_LIST) is best for:\n",
    "\n",
    "  * Quick tweaks in a job submission,\n",
    "  * Adding one or two extra modules on top of existing defaults,\n",
    "  * Programmatic injection of modules from the Tapis job JSON or another wrapper.\n",
    "\n",
    "Together, they let you keep a stable, shared “baseline” module file while still allowing per-job or per-user customization via a simple environment variable.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_option_MODULE_LOAD_LIST = textwrap.dedent(\"\"\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"==== LOADING MODULES FROM A USER-PROVIDED COMMA-SEPARATED LIST ====\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"MODULE_LOADS_LIST: ${MODULE_LOADS_LIST:-}\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "    if [[ -n \"${MODULE_LOADS_LIST:-}\" ]]; then\n",
    "      echo \"Loading modules from: $MODULE_LOADS_LIST\"\n",
    "      IFS=',' read -ra MOD_LIST <<< \"$MODULE_LOADS_LIST\"\n",
    "\n",
    "      for mod in \"${MOD_LIST[@]}\"; do\n",
    "        mod=\"$(echo \"$mod\" | xargs)\"          # trim whitespace\n",
    "        [[ -z \"$mod\" ]] && continue\n",
    "        mod=\"${mod,,}\"                       # <-- convert to lowercase\n",
    "\n",
    "        echo \"loading module $mod ...\"\n",
    "        module load \"$mod\"\n",
    "        echo \"module load $mod (from MODULE_LOADS_LIST)\" >> \"$SUMMARY_SHORT\"\n",
    "      done\n",
    "    fi\n",
    "\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. Load OpenSees Modules (If Running OpenSees)\n",
    "\n",
    "Conceptually, this snippet says:\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "> “If the main binary is an OpenSees **Tcl** executable, make sure the standard OpenSees modules are loaded.”\n",
    "\n",
    "Concretely:\n",
    "\n",
    "* It writes a header to SUMMARY_SHORT for bookkeeping.\n",
    "* It checks BINARYNAME:\n",
    "\n",
    "  * If it’s OpenSees, OpenSeesMP, or OpenSeesSP, it:\n",
    "\n",
    "    * module load hdf5/1.14.4 || true\n",
    "    * module load opensees || true\n",
    "    * logs Loaded default OpenSees-Tcl modules: hdf5/1.14.4, opensees.\n",
    "\n",
    "So this is your **baseline environment** for Tcl-based OpenSees runs, independent of any user-supplied module file or list.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_option_OPS_MODULES_LOAD = textwrap.dedent(\"\"\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================== LOAD OPENSEES MODULES =======================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    # ---- OpenSees Tcl: load default modules if using OpenSees binaries ----\n",
    "    if [[ \"$BINARYNAME\" == \"OpenSees\" || \"$BINARYNAME\" == \"OpenSeesMP\" || \"$BINARYNAME\" == \"OpenSeesSP\" ]]; then\n",
    "        module load hdf5/1.14.4 || true\n",
    "        module load opensees || true\n",
    "        echo \"Loaded default OpenSees-Tcl modules: hdf5/1.14.4, opensees\" >> \"$SUMMARY_SHORT\"\n",
    "    fi\n",
    "    \n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Add the pylauncher module, just in case.\n",
    "Just making sure that it is available if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bash_script_option_PYLAUNCHER_MODULES_LOAD = textwrap.dedent(\"\"\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================== LOAD PyLauncher MODULES =======================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    if [[ \"$BINARYNAME\" == \"python3\" || \"$BINARYNAME\" == \"python\" || \"$BINARYNAME\" == \"Python3\" || \"$BINARYNAME\" == \"Python\" ]]; then\n",
    "        module load pylauncher || true\n",
    "    fi\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. Forcing `python` to Use `python3` in a Batch App\n",
    "\n",
    "This block ensures that **any command that calls `python` actually runs `python3`**, even if the system has multiple Python installations and `python` would normally resolve to a different interpreter.\n",
    "\n",
    "This matters because:\n",
    "\n",
    "- Your wrapper script may launch the main program with `python3`, **but user code or dependencies may still invoke `python`** (for example via `subprocess.run([\"python\", ...])`, `os.system(\"python ...\")`, Makefiles, or CLI tools installed with pip).\n",
    "- On HPC systems, `python` and `python3` often point to different versions/environments, which can lead to confusing runtime errors (missing packages, wrong ABI, wrong OpenSeesPy build, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "\n",
    "A. **Creates a small “shim” directory** inside the job’s start directory:\n",
    "\n",
    "   - `SCRIPT_ROOT_DIR/.pyshim/bin`\n",
    "\n",
    "B. **Writes a lightweight wrapper script named `python`** into that directory:\n",
    "\n",
    "   - When anything runs `python ...`, the wrapper executes `python3 ...` with the same arguments.\n",
    "\n",
    "C. **(Optional) Writes a wrapper script named `pip`**:\n",
    "\n",
    "   - When anything runs `pip ...`, it executes `pip3 ...`.\n",
    "   - This helps because many workflows assume `pip` exists (not just `pip3`).\n",
    "\n",
    "D. **Prepends the shim directory to `PATH`**:\n",
    "\n",
    "   - This is the key step: placing the shim directory *first* in `PATH` guarantees that `python` resolves to the shim (and thus `python3`) before any other `python` executable found elsewhere.\n",
    "\n",
    "E. **Logs resolution and versions to the summary log**:\n",
    "\n",
    "   - Records what `python` and `python3` resolve to (`command -v ...`)\n",
    "   - Records the reported versions (`python -V`, `python3 -V`)\n",
    "   - This makes debugging easy if something still behaves unexpectedly.\n",
    "\n",
    "---\n",
    "\n",
    "**Why This Works in Batch Jobs**\n",
    "\n",
    "- `alias python=python3` is **not reliable** in non-interactive batch shells.\n",
    "- Changing system-wide alternatives is **not appropriate** (and often not possible) on shared HPC systems.\n",
    "- A PATH-prepended shim is **simple, local to the job**, and reliably affects:\n",
    "  - the wrapper script itself\n",
    "  - user scripts\n",
    "  - subprocess calls\n",
    "  - pip-installed console entry points that internally call `python`\n",
    "\n",
    "---\n",
    "\n",
    "**Notes and Best Practices**\n",
    "\n",
    "- Place this block **after module loads** (so you wrap the final Python environment you intend to use).\n",
    "- If a later `module load` changes `PATH`, it could override ordering; in that case, place the shim block **after** those loads.\n",
    "- This block does not change `python3`; it only ensures that `python` (and optionally `pip`) consistently follow `python3` (and `pip3`).\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_option_PYTHON_ALIAS = textwrap.dedent(\"\"\"\n",
    "    # -------------------------------------------------------------------\n",
    "    # Force `python` to mean `python3` (and optionally `pip` -> `pip3`)\n",
    "    # Put this AFTER your module loads (so it wraps the final python).\n",
    "    # -------------------------------------------------------------------\n",
    "    PY_SHIM_DIR=\"${SCRIPT_ROOT_DIR}/.pyshim/bin\"\n",
    "    mkdir -p \"$PY_SHIM_DIR\"\n",
    "    \n",
    "    cat > \"${PY_SHIM_DIR}/python\" <<'EOF'\n",
    "    #!/usr/bin/env bash\n",
    "    exec python3 \"$@\"\n",
    "    EOF\n",
    "    chmod +x \"${PY_SHIM_DIR}/python\"\n",
    "    \n",
    "    # Optional but usually helpful (many tools call `pip`)\n",
    "    cat > \"${PY_SHIM_DIR}/pip\" <<'EOF'\n",
    "    #!/usr/bin/env bash\n",
    "    exec pip3 \"$@\"\n",
    "    EOF\n",
    "    chmod +x \"${PY_SHIM_DIR}/pip\"\n",
    "    \n",
    "    # Prepend shim dir so it wins over any other `python` in PATH\n",
    "    export PATH=\"${PY_SHIM_DIR}:$PATH\"\n",
    "    \n",
    "    # Log what will be used\n",
    "    echo \"python resolves to: $(command -v python)\"   >> \"$SUMMARY_SHORT\"\n",
    "    echo \"python3 resolves to: $(command -v python3)\" >> \"$SUMMARY_SHORT\"\n",
    "    python -V  >> \"$SUMMARY_SHORT\" 2>&1 || true\n",
    "    python3 -V >> \"$SUMMARY_SHORT\" 2>&1 || true\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #### 12. Installing Python packages from a requirements file (PIP_INSTALLS_FILE)\n",
    "\n",
    "This block gives the app a **file-based way to install Python dependencies at runtime**, similar in spirit to MODULE_LOADS_FILE for environment modules.\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "What it does:\n",
    "\n",
    "1. **Log the section and show the Python version**\n",
    "\n",
    "   * Writes a header (\"---- Python / pip setup / from FILE ----\") into SUMMARY_SHORT so you can see that a pip-setup phase ran.\n",
    "   * Runs python3 -V || true:\n",
    "\n",
    "     * Prints the currently active python3 version to stdout (useful for debugging mismatched environments).\n",
    "     * The || true ensures that if python3 is missing or misconfigured, the script does **not** die right here; the job will still proceed, and the failure mode is tied to pip3 instead.\n",
    "\n",
    "2. **Check for a requirements file**\n",
    "\n",
    "   ```bash\n",
    "   if [[ -n \"${PIP_INSTALLS_FILE:-}\" && -f \"$PIP_INSTALLS_FILE\" ]]; then\n",
    "   ```\n",
    "\n",
    "   This ensures:\n",
    "\n",
    "   * PIP_INSTALLS_FILE is set and non-empty, **and**\n",
    "   * The referenced file actually exists.\n",
    "\n",
    "   If either condition fails, this block simply does nothing (no installs, no errors).\n",
    "\n",
    "3. **Install packages with pip3 install -r**\n",
    "\n",
    "   When a valid file is provided:\n",
    "\n",
    "   * A message is written to the summary log:\n",
    "\n",
    "     * \"Installing Python packages from file: $PIP_INSTALLS_FILE\"\n",
    "     * The exact pip command line (pip3 install -r $PIP_INSTALLS_FILE) is also logged, so later you can see precisely what was attempted.\n",
    "   * Then the command is executed:\n",
    "\n",
    "     ```bash\n",
    "     pip3 install -r \"$PIP_INSTALLS_FILE\"\n",
    "     ```\n",
    "\n",
    "     This treats the file like a standard requirements.txt:\n",
    "\n",
    "     * One package spec per line (with versions, extras, etc. as needed).\n",
    "     * Comments and blank lines are handled by pip itself.\n",
    "\n",
    "Why this pattern is useful:\n",
    "\n",
    "* It keeps your **Python dependency definition out of the wrapper script** and in a reusable, version-controlled requirements file.\n",
    "* It lets you adapt the environment per app version or per job by changing PIP_INSTALLS_FILE (or its contents) without changing the shell script.\n",
    "* Logging both the file path and the exact pip command into SUMMARY_SHORT makes it much easier to debug dependency issues later (“which packages did this job actually install?”).\n",
    "</details> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17. Installing Python packages from a requirements file (PIP_INSTALLS_FILE)\n",
    "\n",
    "This block provides a **file-based mechanism** for installing Python dependencies at runtime—similar in spirit to `MODULE_LOADS_FILE`, but specifically for pip packages.\n",
    "\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "\n",
    "**1. Logs the section and prints the Python version**\n",
    "\n",
    "The script writes a header into `SUMMARY_SHORT` and prints the active Python version:\n",
    "\n",
    "```bash\n",
    "echo \"---- Python / pip setup / from FILE ----\" >> \"$SUMMARY_SHORT\"\n",
    "python3 -V || true\n",
    "```\n",
    "\n",
    "* This helps diagnose environment or module-loading problems.\n",
    "* `|| true` ensures the job does *not* fail simply because `python3 -V` is missing—actual failure only occurs during the pip install.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Checks for a valid requirements file**\n",
    "\n",
    "```bash\n",
    "if [[ -n \"${PIP_INSTALLS_FILE:-}\" && -f \"$PIP_INSTALLS_FILE\" ]]; then\n",
    "```\n",
    "\n",
    "This ensures:\n",
    "\n",
    "1. `PIP_INSTALLS_FILE` is non-empty\n",
    "2. The referenced file exists on the execution system\n",
    "\n",
    "If either condition fails, the block logs a message and safely skips installation.\n",
    "No error is thrown just because the user omitted this option.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Installs packages with `pip3 install -r` (with full error handling)**\n",
    "\n",
    "If the requirements file exists:\n",
    "\n",
    "```bash\n",
    "echo \"Installing Python packages from file: $PIP_INSTALLS_FILE\" >> \"$SUMMARY_SHORT\"\n",
    "echo \"pip3 install -r $PIP_INSTALLS_FILE\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "if ! pip3 install -r \"$PIP_INSTALLS_FILE\"; then\n",
    "    rc=$?\n",
    "    echo \"ERROR: pip3 install failed for requirements file '$PIP_INSTALLS_FILE' (exit code $rc)\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"ERROR: pip3 install failed for requirements file '$PIP_INSTALLS_FILE' (exit code $rc)\" >&2\n",
    "    exit \"$rc\"\n",
    "fi\n",
    "```\n",
    "\n",
    "**Key behaviors:**\n",
    "\n",
    "* Logs both the **file path** and the **exact pip command** for reproducibility.\n",
    "* If pip install fails:\n",
    "\n",
    "  * Writes a clear ERROR line into `SUMMARY_SHORT`\n",
    "  * Writes the same message to stderr (so it appears cleanly in Tapis logs)\n",
    "  * Exits with a non-zero return code so the job is correctly marked FAILED.\n",
    "\n",
    "This mirrors the same error-handling model used in the list-based installer.\n",
    "\n",
    "---\n",
    "\n",
    "**Why this pattern is useful**\n",
    "\n",
    "* Keeps Python dependency definitions **out of the wrapper script** and in a normal `requirements.txt` file.\n",
    "* Allows job- or version-specific overrides without modifying the underlying app.\n",
    "* Fully Tapis-aware: failures propagate correctly and are easy for users to understand.\n",
    "* Logs exactly what was attempted, simplifying debugging (“what environment did this job actually run in?”).\n",
    "\n",
    "---\n",
    "\n",
    "**How it complements `PIP_INSTALLS_LIST`**\n",
    "\n",
    "| Feature        | `PIP_INSTALLS_FILE`                     | `PIP_INSTALLS_LIST`                |\n",
    "| -------------- | --------------------------------------- | ---------------------------------- |\n",
    "| Best for       | Stable, version-controlled environments | Quick per-job tweaks               |\n",
    "| Input type     | File (requirements.txt style)           | Comma-separated string             |\n",
    "| Error handling | Fail-fast with clear message            | Fail-fast with clear message       |\n",
    "| Ideal use case | Reproducible runtime environments       | Lightweight additions or overrides |\n",
    "\n",
    "Together, they provide a **robust, flexible environment management pattern** for Python inside Tapis/DesignSafe apps.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_option_PIP_FILE = textwrap.dedent(\"\"\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"= INSTALLING PYTHON PACKAGES FROM A USER-PROVIDED REQUIREMENTS FILE =\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"---- Python / pip setup / from FILE ----\" >> \"$SUMMARY_SHORT\"\n",
    "    python3 -V || true\n",
    "\n",
    "    if [[ -n \"${PIP_INSTALLS_FILE:-}\" && -f \"$PIP_INSTALLS_FILE\" ]]; then\n",
    "      echo \"Installing Python packages from file: $PIP_INSTALLS_FILE\" >> \"$SUMMARY_SHORT\"\n",
    "      echo \"pip3 install -r $PIP_INSTALLS_FILE\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "      if ! pip3 install -r \"$PIP_INSTALLS_FILE\"; then\n",
    "        rc=$?\n",
    "        echo \"ERROR: pip3 install failed for requirements file '$PIP_INSTALLS_FILE' (exit code $rc)\" >> \"$SUMMARY_SHORT\"\n",
    "        echo \"ERROR: pip3 install failed for requirements file '$PIP_INSTALLS_FILE' (exit code $rc)\" >&2\n",
    "        exit \"$rc\"\n",
    "      fi\n",
    "\n",
    "    else\n",
    "      echo \"PIP_INSTALLS_FILE not provided or file does not exist; skipping pip installs.\" >> \"$SUMMARY_SHORT\"\n",
    "    fi\n",
    "\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# absPath = os.path.abspath('../../../shared/Examples/OpenSees')\n",
    "# MyDataPath = os.path.expanduser('~/MyData/')\n",
    "# MyPath = absPath.replace(MyDataPath,'')\n",
    "\n",
    "# print('absPath',absPath)\n",
    "# print('MyDataPath',MyDataPath)\n",
    "# print('MyPath',MyPath)\n",
    "\n",
    "\n",
    "# # print(os.path.abspath('../../../shared/Examples/OpenSees'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #### 13. Installing Python packages from a comma-separated list (PIP_INSTALLS_LIST)\n",
    "\n",
    "This block is the **list-based counterpart** to PIP_INSTALLS_FILE. Instead of pointing to a requirements file, you can provide packages directly via the PIP_INSTALLS_LIST environment variable.\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "What it does:\n",
    "\n",
    "1. **Log the section and show the Python version**\n",
    "\n",
    "   * Writes a header (\"---- Python / pip setup / from LIST ----\") into SUMMARY_SHORT.\n",
    "   * Runs python3 -V || true so the active Python version is printed to stdout for debugging, without failing the job if python3 is missing.\n",
    "\n",
    "2. **Check whether a list of packages was provided**\n",
    "\n",
    "   ```bash\n",
    "   if [[ -n \"${PIP_INSTALLS_LIST:-}\" ]]; then\n",
    "   ```\n",
    "\n",
    "   * If PIP_INSTALLS_LIST is empty or unset, nothing happens.\n",
    "   * If it’s set (e.g., numpy, scipy==1.13,  pandas), the block proceeds.\n",
    "\n",
    "3. **Parse the comma-separated list**\n",
    "\n",
    "   ```bash\n",
    "   IFS=',' read -ra PKG_LIST <<< \"$PIP_INSTALLS_LIST\"\n",
    "   for pkg in \"${PKG_LIST[@]}\"; do\n",
    "     pkg=\"$(echo \"$pkg\" | xargs)\"\n",
    "     [[ -z \"$pkg\" ]] && continue\n",
    "   ```\n",
    "\n",
    "   * Splits PIP_INSTALLS_LIST on commas into PKG_LIST.\n",
    "   * Trims leading and trailing whitespace from each entry using xargs, so both numpy and \" numpy \" work.\n",
    "   * Skips empty entries, so accidental extra commas don’t cause errors.\n",
    "\n",
    "4. **Install each package with pip3 install**\n",
    "\n",
    "   For each non-empty pkg:\n",
    "\n",
    "   * Logs the exact command to SUMMARY_SHORT:\n",
    "\n",
    "     ```bash\n",
    "     echo \"pip3 install $pkg (from PIP_INSTALLS_LIST)\" >> \"$SUMMARY_SHORT\"\n",
    "     ```\n",
    "   * Executes:\n",
    "\n",
    "     ```bash\n",
    "     pip3 install \"$pkg\"\n",
    "     ```\n",
    "\n",
    "   This lets you add or override Python packages at runtime with a single environment variable, without editing a file.\n",
    "\n",
    "---\n",
    "\n",
    "**How it complements PIP_INSTALLS_FILE:**\n",
    "\n",
    "* PIP_INSTALLS_FILE is best for **stable, version-controlled** sets of dependencies (a requirements-style file).\n",
    "* PIP_INSTALLS_LIST is best for:\n",
    "\n",
    "  * Quick per-job tweaks (e.g., trying one extra package),\n",
    "  * Programmatic injection from the job JSON,\n",
    "  * Simple environments where a full requirements file feels overkill.\n",
    "\n",
    "Together, they mirror the same pattern you use for modules: a **file-based recipe for the baseline**, and a **list-based knob** for convenient overrides or additions.\n",
    "</details> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. Installing Python packages from a comma-separated list (PIP_INSTALLS_LIST)\n",
    "\n",
    "This block is the **list-based counterpart** to `PIP_INSTALLS_FILE`.\n",
    "Instead of pointing to a requirements file, you can provide Python packages directly through the `PIP_INSTALLS_LIST` environment variable.\n",
    "\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "\n",
    "**1. Log the section and report the active Python version**\n",
    "\n",
    "The script writes a header into `SUMMARY_SHORT` and prints the Python version for debugging:\n",
    "\n",
    "```bash\n",
    "echo \"---- Python / pip setup / from LIST ----\" >> \"$SUMMARY_SHORT\"\n",
    "python3 -V || true\n",
    "```\n",
    "\n",
    "`python3 -V || true` guarantees that missing Python does **not** break the job at this stage — the block only fails during an actual pip install error.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Check whether a package list was provided**\n",
    "\n",
    "```bash\n",
    "if [[ -n \"${PIP_INSTALLS_LIST:-}\" ]]; then\n",
    "```\n",
    "\n",
    "* If `PIP_INSTALLS_LIST` is empty or unset, the block logs that it is skipping installation.\n",
    "* If set (e.g., `numpy, scipy==1.13, pandas`), the block continues.\n",
    "\n",
    "This allows convenient per-job overrides without touching the app definition.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Split the comma-separated package list**\n",
    "\n",
    "```bash\n",
    "IFS=',' read -ra PKG_LIST <<< \"$PIP_INSTALLS_LIST\"\n",
    "for pkg in \"${PKG_LIST[@]}\"; do\n",
    "    pkg=\"$(echo \"$pkg\" | xargs)\"\n",
    "    [[ -z \"$pkg\" ]] && continue\n",
    "```\n",
    "\n",
    "* Splits the list into an array `PKG_LIST`.\n",
    "* Uses `xargs` to trim whitespace, so both `numpy` and `\" numpy \"` work.\n",
    "* Ignores empty entries so `\"numpy,,scipy\"` does not cause errors.\n",
    "\n",
    "This makes the interface resilient to user formatting.\n",
    "\n",
    "---\n",
    "\n",
    "**4. Install each package and fail cleanly on errors**\n",
    "\n",
    "For every valid package:\n",
    "\n",
    "```bash\n",
    "echo \"pip3 install $pkg (from PIP_INSTALLS_LIST)\" >> \"$SUMMARY_SHORT\"\n",
    "if ! pip3 install \"$pkg\"; then\n",
    "    rc=$?\n",
    "    echo \"ERROR: pip3 install failed for package '$pkg' (exit code $rc)\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"ERROR: pip3 install failed for package '$pkg' (exit code $rc)\" >&2\n",
    "    exit \"$rc\"\n",
    "fi\n",
    "```\n",
    "\n",
    "**Key behaviors:**\n",
    "\n",
    "* Logs the pip command for reproducibility.\n",
    "* If `pip3 install` fails:\n",
    "\n",
    "  * Writes a clear error message to `SUMMARY_SHORT`\n",
    "  * Writes the same message to stderr (visible in portal / `tapis jobs logs`)\n",
    "  * Exits with a non-zero return code so Tapis correctly marks the job as FAILED.\n",
    "\n",
    "This is the correct, Tapis-friendly pattern for surfacing human-readable errors.\n",
    "\n",
    "---\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "This block now behaves like a “proper installation step” in HPC workflows:\n",
    "\n",
    "* **Transparent:** every attempted install shows up in the log.\n",
    "* **Fail-fast:** jobs don’t continue in a broken environment.\n",
    "* **Tapis-aware:** the failure is clearly communicated to both humans and the Tapis job system.\n",
    "\n",
    "---\n",
    "\n",
    "**How this complements PIP_INSTALLS_FILE**\n",
    "\n",
    "| Feature        | `PIP_INSTALLS_FILE`                     | `PIP_INSTALLS_LIST`                              |\n",
    "| -------------- | --------------------------------------- | ------------------------------------------------ |\n",
    "| Best for       | Stable, version-controlled environments | Quick per-job tweaks and overrides               |\n",
    "| Input type     | Requirements-style text file            | Comma-separated string                           |\n",
    "| Good for       | Reproducibility                         | Experimentation, dynamic injection from job JSON |\n",
    "| Error handling | Fail-fast on requirements file errors   | Fail-fast on individual package errors           |\n",
    "\n",
    "Using both options gives you a flexible but robust installation strategy:\n",
    "\n",
    "* A **file-based baseline**,\n",
    "* Plus a **list-based runtime knob** for additional packages.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_option_PIP_LIST = textwrap.dedent(\"\"\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"= INSTALLING PYTHON PACKAGES FROM A USER-PROVIDED COMMA-SEPARATED LIST =\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"---- Python / pip setup / from LIST ----\" >> \"$SUMMARY_SHORT\"\n",
    "    python3 -V || true\n",
    "\n",
    "    if [[ -n \"${PIP_INSTALLS_LIST:-}\" ]]; then\n",
    "      echo \"Installing Python packages from PIP_INSTALLS_LIST list: $PIP_INSTALLS_LIST\" >> \"$SUMMARY_SHORT\"\n",
    "      IFS=',' read -ra PKG_LIST <<< \"$PIP_INSTALLS_LIST\"\n",
    "      for pkg in \"${PKG_LIST[@]}\"; do\n",
    "        pkg=\"$(echo \"$pkg\" | xargs)\"   # trim whitespace\n",
    "        [[ -z \"$pkg\" ]] && continue\n",
    "        echo \"pip3 install $pkg (from PIP_INSTALLS_LIST)\" >> \"$SUMMARY_SHORT\"\n",
    "        if ! pip3 install \"$pkg\"; then\n",
    "          rc=$?\n",
    "          echo \"ERROR: pip3 install failed for package '$pkg' (exit code $rc)\" >> \"$SUMMARY_SHORT\"\n",
    "          echo \"ERROR: pip3 install failed for package '$pkg' (exit code $rc)\" >&2\n",
    "          exit \"$rc\"\n",
    "        fi\n",
    "      done\n",
    "    else\n",
    "      echo \"PIP_INSTALLS_LIST is empty; skipping pip installs.\" >> \"$SUMMARY_SHORT\"\n",
    "    fi\n",
    "\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19. Choosing how to launch the app (sequential vs MPI)\n",
    "\n",
    "This block decides **whether to wrap the binary in an MPI launcher** or run it directly, and records that choice in the summary log.\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "**Key inputs:**\n",
    "\n",
    "* BINARYNAME – which executable we’re running (OpenSees, OpenSeesMP, etc.).\n",
    "* UseMPI – a user-facing flag (string) that says whether MPI should be used. It’s interpreted in a flexible, “human-ish” way.\n",
    "\n",
    "**What it does:**\n",
    "\n",
    "1. **Log the section and the requested MPI flag**\n",
    "\n",
    "   It writes a header and the current value of UseMPI to SUMMARY_SHORT, so later you can see what the job *thought* it should do regarding MPI.\n",
    "\n",
    "2. **Decide the launcher and populate LAUNCH**\n",
    "\n",
    "   The logic fills an array LAUNCH, which will be prepended when actually running the job:\n",
    "\n",
    "   * **Case 1: BINARYNAME == \"OpenSees\"**\n",
    "\n",
    "     ```bash\n",
    "     LAUNCH=()\n",
    "     ```\n",
    "\n",
    "     * No launcher is used: this is a **purely sequential** run.\n",
    "     * Logged as Launcher: none (OpenSees sequential).\n",
    "\n",
    "   * **Case 2: UseMPI is “false-like”**\n",
    "\n",
    "     ```bash\n",
    "     elif [[ ! \"${UseMPI:-}\" =~ ^([Tt][Rr][Uu][Ee]|1|[Yy][Ee]?[Ss]?)$ ]]; then\n",
    "       LAUNCH=()\n",
    "     ```\n",
    "\n",
    "     * If UseMPI is anything *other than* true/True/TRUE/yes/Yes/1 (or similar), then we again run **without** an MPI launcher.\n",
    "     * Logged as Launcher: none (UseMPI false-like).\n",
    "\n",
    "   * **Case 3: MPI is requested**\n",
    "\n",
    "     ```bash\n",
    "     else\n",
    "       LAUNCH=(ibrun)\n",
    "     ```\n",
    "\n",
    "     * If UseMPI matches a “true-like” string, the script sets LAUNCH=(ibrun).\n",
    "     * This means the final command will be ibrun <binary> <args> on Stampede3.\n",
    "     * Logged as Launcher: ibrun (UseMPI true-like).\n",
    "\n",
    "**Why this pattern:**\n",
    "\n",
    "* Keeps the **launcher choice centralized** and explicit, instead of scattering ibrun versus direct runs in multiple places.\n",
    "* Makes UseMPI flexible and user-friendly (accepting true, True, YES, 1, etc.).\n",
    "* Ensures that plain OpenSees (Tcl, single-process) defaults to **sequential**, while MPI-capable binaries can opt into parallelism cleanly via UseMPI.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_run_CHOOSE_LAUNCHER = textwrap.dedent(\"\"\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"=========== CHOOSING THE LAUNCHER (SEQUENTIAL VS MPI) =============\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \" ---- choose launcher ---- \" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"UseMPI ${UseMPI}\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "    LAUNCH=()\n",
    "    if [[ \"$BINARYNAME\" == \"OpenSees\" ]]; then\n",
    "      LAUNCH=()        # direct run for sequential\n",
    "      echo \"Launcher: none (OpenSees sequential)\" >> \"$SUMMARY_SHORT\"\n",
    "    elif [[ ! \"${UseMPI:-}\" =~ ^([Tt][Rr][Uu][Ee]|1|[Yy][Ee]?[Ss]?)$ ]]; then\n",
    "      LAUNCH=()\n",
    "      echo \"Launcher: none (UseMPI false-like)\" >> \"$SUMMARY_SHORT\"\n",
    "    else\n",
    "      LAUNCH=(ibrun)\n",
    "      echo \"Launcher: ibrun (UseMPI true-like)\" >> \"$SUMMARY_SHORT\"\n",
    "    fi\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20. Running the job binary (with timers and error handling)\n",
    "\n",
    "This block is the **core execution step**: it runs the main binary (with or without an MPI launcher), records timing information, and handles errors in a consistent way.\n",
    "\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "\n",
    "This block:\n",
    "**A. Start the “binary run” timer**\n",
    "\n",
    "* Captures:\n",
    "\n",
    "  * RUN_START_EPOCH – epoch time when the binary starts.\n",
    "  * RUN_START_HUMAN – human-readable start time.\n",
    "* Logs the start time to SUMMARY_SHORT.\n",
    "\n",
    "This pairs with the __echoTimers_START__ / bash_script_echoTimers_AFTER blocks so you can see how long the binary itself ran.\n",
    "\n",
    "**B. Optional Python version check**\n",
    "\n",
    "* If BINARYNAME == \"python3\", it runs python3 -V || true:\n",
    "\n",
    "  * Prints the Python version to stdout (helpful when debugging OpenSeesPy or other Python workflows).\n",
    "  * || true avoids killing the job if that command fails.\n",
    "\n",
    "**C. Actually run the application**\n",
    "\n",
    "The script then:\n",
    "\n",
    "* Prints a little visual marker to stdout (************************* run!!!) and a separator in SUMMARY_SHORT.\n",
    "* Chooses **how** to run based on LAUNCH (which was set earlier by bash_script_run_CHOOSE_LAUNCHER):\n",
    "\n",
    "**Case I – With launcher (MPI / ibrun, etc.)**\n",
    "\n",
    "* If LAUNCH has elements:\n",
    "\n",
    "  * Logs a line like\n",
    "    Running: ibrun OpenSeesMP input.tcl <args>\n",
    "    to SUMMARY_SHORT.\n",
    "  * Executes:\n",
    "    \"${LAUNCH[@]}\" \"$BINARYNAME\" \"$INPUTSCRIPT\" \"$@\"\n",
    "  * If that command fails (nonzero status):\n",
    "\n",
    "    * Captures the return code in rc.\n",
    "    * Logs Program exited with error status: $rc to the summary.\n",
    "    * Calls __echoTimers_START__ to record **on-error timing** (run + total).\n",
    "    * Exits the wrapper with the same rc.\n",
    "\n",
    "**Case II – No launcher (sequential)**\n",
    "\n",
    "* If LAUNCH is empty:\n",
    "\n",
    "  * Logs Running: $BINARYNAME $INPUTSCRIPT $* to SUMMARY_SHORT.\n",
    "  * Runs the binary directly:\n",
    "    \"$BINARYNAME\" \"$INPUTSCRIPT\" \"$@\"\n",
    "  * On failure:\n",
    "\n",
    "    * Same behavior as above: capture rc, log it, call __echoTimers_START__, and exit with rc.\n",
    "\n",
    "This gives you the **same error-handling path** whether you’re running sequentially or under ibrun.\n",
    "\n",
    "**D. Mark successful completion**\n",
    "\n",
    "If the binary exits with status 0:\n",
    "\n",
    "* Writes a big banner to SUMMARY_SHORT:\n",
    "\n",
    "  * Separator line\n",
    "  * Run completed with NO ERROR!!!!\n",
    "  * Separator line\n",
    "\n",
    "At this point, the end-of-run timer block (bash_script_echoTimers_AFTER + bash_script_echoTimers_END) will typically run to record the normal, successful runtime for both the binary and the whole script.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_run_RUN_JOB = textwrap.dedent(\"\"\"\n",
    "    echo \"=start==============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================== RUNNING THE JOB BINARY ======================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    # ---- TIMER: binary run only ----\n",
    "    RUN_START_EPOCH=$(date +%s)\n",
    "    RUN_START_HUMAN=\"$(date)\"\n",
    "    echo \"Binary run start time: ${RUN_START_HUMAN} (epoch ${RUN_START_EPOCH})\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "    if [[ \"$BINARYNAME\" == \"python3\" ]]; then\n",
    "        python3 -V || true\n",
    "    fi\n",
    "\n",
    "    if [[ \"$BINARYNAME\" == \"python\" ]]; then\n",
    "        python -V || true\n",
    "    fi    \n",
    "\n",
    "\n",
    "    echo '************************* run!!!'\n",
    "    echo \"==============\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "    \n",
    "   \n",
    "    if [[ ${#LAUNCH[@]} -gt 0 ]]; then\n",
    "      echo \"Running: ${LAUNCH[*]} $BINARYNAME $INPUTSCRIPT $*\" >> \"$SUMMARY_SHORT\"\n",
    "      \"${LAUNCH[@]}\" \"$BINARYNAME\" \"$INPUTSCRIPT\" \"$@\"\n",
    "      rc=$?\n",
    "    else\n",
    "      echo \"Running: $BINARYNAME $INPUTSCRIPT $*\" >> \"$SUMMARY_SHORT\"\n",
    "      \"$BINARYNAME\" \"$INPUTSCRIPT\" \"$@\"\n",
    "      rc=$?\n",
    "    fi\n",
    "    \n",
    "    if [[ $rc -ne 0 ]]; then\n",
    "      echo \"Program exited with error status: $rc\" >> \"$SUMMARY_SHORT\"\n",
    "    \n",
    "      __echoTimers_START__\n",
    "\n",
    "      echo \"ERROR: Application run failed with status $rc\" >&2\n",
    "      echo \"HINT: Possible cause: Failed to import openseespy or missing modules.\" >&2\n",
    "      exit \"$rc\"\n",
    "    fi\n",
    "\n",
    "    echo \"###############################################################################\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"Run completed with NO ERROR!!!!\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"###############################################################################\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21. OpenSeesPy: copy TACC-compiled OpenSeesPy.so into the run directory\n",
    "\n",
    "Because the **PyPI wheel for OpenSeesPy** is not guaranteed to match the **exact Python build and system libraries on TACC**, this block provides a safer alternative:\n",
    "\n",
    "> If requested, use the **TACC-compiled OpenSeesPy shared library** instead of relying on whatever pip install openseespy would pull in.\n",
    "\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "Concretely, this block:\n",
    "\n",
    "1. **Checks whether the user actually requested the TACC OpenSeesPy**\n",
    "\n",
    "   It looks at GET_TACC_OPENSEESPY and treats “true-like” strings as *on*:\n",
    "\n",
    "   * Accepted values: true, True, TRUE, yes, Yes, 1, etc.\n",
    "   * If not true-like, the entire block is skipped.\n",
    "\n",
    "   This makes it an **opt-in switch** from the Tapis job JSON or environment.\n",
    "\n",
    "2. **Loads the Python + OpenSees environment expected by the TACC build**\n",
    "\n",
    "   Inside the GET_TACC_OPENSEESPY true branch, it defensively does:\n",
    "\n",
    "   * module load python/3.12.11 || true\n",
    "   * module load hdf5/1.14.4 || true\n",
    "   * module load opensees || true\n",
    "\n",
    "   These are the modules that match the **environment used to compile** the TACC OpenSeesPy library. Loading them ensures:\n",
    "\n",
    "   * ABI and library compatibility for OpenSeesPy.so,\n",
    "   * Consistency with the TACC-supported toolchain.\n",
    "\n",
    "   The || true prevents a hard failure if one of these loads doesn’t succeed, but the summary log still notes that this path was taken.\n",
    "\n",
    "3. **Validate and use TACC_OPENSEES_BIN as the source location**\n",
    "\n",
    "   The script then checks:\n",
    "\n",
    "   * If TACC_OPENSEES_BIN is **unset or empty**:\n",
    "\n",
    "     * It logs a warning to SUMMARY_SHORT that the path is missing and skips the copy.\n",
    "   * Else if ${TACC_OPENSEES_BIN}/OpenSeesPy.so **doesn’t exist**:\n",
    "\n",
    "     * It logs a warning that the file wasn’t found and skips the copy.\n",
    "\n",
    "   This protects against misconfigured environments or typos in the path.\n",
    "\n",
    "4. **Copy the TACC OpenSeesPy into the execution directory as opensees.so**\n",
    "\n",
    "   If everything is valid:\n",
    "\n",
    "   * It echoes to stdout:\n",
    "     Copying TACC OpenSeesPy -> ./opensees.so\n",
    "   * Performs:\n",
    "\n",
    "     ```bash\n",
    "     cp \"${TACC_OPENSEES_BIN}/OpenSeesPy.so\" ./opensees.so\n",
    "     ```\n",
    "   * Logs to SUMMARY_SHORT exactly what was copied and where:\n",
    "\n",
    "     * Source: ${TACC_OPENSEES_BIN}/OpenSeesPy.so\n",
    "     * Destination: $(pwd)/opensees.so\n",
    "\n",
    "   This puts a **known-good, TACC-compiled** OpenSeesPy shared library directly in the working directory, where Python will pick it up (e.g., via local opensees.so import behavior) without relying on an external wheel.\n",
    "\n",
    "5. **Document the modules that were loaded for this path**\n",
    "\n",
    "   Finally, it appends a note to SUMMARY_SHORT:\n",
    "\n",
    "   * Loaded default TACC OpenSeesPy modules: python/3.12.11, hdf5/1.14.4, opensees\n",
    "\n",
    "   So when you inspect the job summary, you can see that:\n",
    "\n",
    "   * The TACC OpenSeesPy path was used,\n",
    "   * Which modules/environment were assumed for it.\n",
    "\n",
    "---\n",
    "\n",
    "When paired with a later “cleanup” block that removes ./opensees.so after the run, this pattern lets you:\n",
    "\n",
    "* Inject a **cluster-native** OpenSeesPy build for the duration of the job,\n",
    "* Avoid subtle wheel/ABI mismatches from pip install,\n",
    "* Keep the execution directory clean once the run is done.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_option_COPY_OPENSEESPY = textwrap.dedent(\"\"\"\n",
    "    echo \"=start==============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"=============== COPY TACC-COMPILED OPENSEESPY =====================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \" ---- OpenSeesPy: copy TACC-compiled opensees.so if requested ----\" >> \"$SUMMARY_SHORT\"\n",
    "    if [[ \"${GET_TACC_OPENSEESPY:-}\" =~ ^([Tt][Rr][Uu][Ee]|1|[Yy][Ee]?[Ss]?)$ ]]; then\n",
    "        module load python/3.12.11 || true\n",
    "        module load hdf5/1.14.4 || true\n",
    "        module load opensees || true\n",
    "        if [[ -z \"${TACC_OPENSEES_BIN:-}\" ]]; then\n",
    "          echo \"WARNING: GET_TACC_OPENSEESPY=True but TACC_OPENSEES_BIN is not set; skipping copy of OpenSeesPy.\" >> \"$SUMMARY_SHORT\"\n",
    "        elif [[ ! -f \"${TACC_OPENSEES_BIN}/OpenSeesPy.so\" ]]; then\n",
    "          echo \"WARNING: ${TACC_OPENSEES_BIN}/OpenSeesPy.so not found; skipping copy of OpenSeesPy.\" >> \"$SUMMARY_SHORT\"\n",
    "        else\n",
    "          echo \"Copying TACC OpenSeesPy -> ./opensees.so\"\n",
    "          cp \"${TACC_OPENSEES_BIN}/OpenSeesPy.so\" ./opensees.so\n",
    "          echo \"Copied TACC OpenSeesPy: \" >> \"$SUMMARY_SHORT\"\n",
    "          echo \"    ${TACC_OPENSEES_BIN}/OpenSeesPy.so -> $(pwd)/opensees.so\" >> \"$SUMMARY_SHORT\"\n",
    "        fi\n",
    "        echo \"Loaded default TACC OpenSeesPy modules: python/3.12.11, hdf5/1.14.4, opensees\" >> \"$SUMMARY_SHORT\"\n",
    "    fi\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22. Optional Cleanup: remove temporary TACC OpenSeesPy library after the run\n",
    "\n",
    "This block **cleans up** the OpenSeesPy shared library that may have been copied into the execution directory by the GET_TACC_OPENSEESPY option.\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "**What it does:**\n",
    "\n",
    "1. **Log that a cleanup phase is running**\n",
    "\n",
    "   It writes a header and a short label (\"remove OpenSeesPy file (Optional)\") into SUMMARY_SHORT so it’s clear that a post-run OpenSeesPy cleanup step was attempted.\n",
    "\n",
    "2. **Check whether TACC OpenSeesPy was requested**\n",
    "\n",
    "   Just like the copy block, it uses:\n",
    "\n",
    "   ```bash\n",
    "   if [[ \"${GET_TACC_OPENSEESPY:-}\" =~ ^([Tt][Rr][Uu][Ee]|1|[Yy][Ee]?[Ss]?)$ ]]; then\n",
    "   ```\n",
    "\n",
    "   This ensures that **cleanup only runs if the job opted into using the TACC OpenSeesPy build** (i.e., the same flag that gated the copy step). If the user never requested GET_TACC_OPENSEESPY, this block quietly does nothing.\n",
    "\n",
    "3. **Remove the local opensees.so file**\n",
    "\n",
    "   Inside the true branch:\n",
    "\n",
    "   * It calls:\n",
    "\n",
    "     ```bash\n",
    "     rm -f ./opensees.so || true\n",
    "     ```\n",
    "\n",
    "     * rm -f removes the file if it exists and does nothing (no error) if it doesn’t.\n",
    "     * || true prevents any unexpected rm issue from killing the job.\n",
    "   * It logs to SUMMARY_SHORT that the file was removed.\n",
    "\n",
    "**Why this cleanup matters:**\n",
    "\n",
    "* The copy step deliberately places a **cluster-specific** OpenSeesPy.so into the current directory as opensees.so so the job can use a known-compatible library.\n",
    "* Leaving that file behind could:\n",
    "\n",
    "  * Confuse future runs (if they expect a different version),\n",
    "  * Be mistakenly packaged or moved as user output,\n",
    "  * Make it ambiguous whether the job used a TACC-native build or a different OpenSeesPy installation.\n",
    "\n",
    "By removing ./opensees.so at the end **only when GET_TACC_OPENSEESPY was enabled**, you:\n",
    "\n",
    "* Keep the execution directory clean,\n",
    "* Make the TACC-compiled library clearly **ephemeral and job-scoped**,\n",
    "* Avoid interfering with any other environment that might exist outside this job.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_option_DELETE_OPENSEESPY = textwrap.dedent(\"\"\"\n",
    "    echo \"=start==============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"=============== REMOVE TACC-COMPILED OPENSEESPY ===================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"remove OpenSeesPy file (Optional)\" >> \"$SUMMARY_SHORT\"\n",
    "    if [[ \"${GET_TACC_OPENSEESPY:-}\" =~ ^([Tt][Rr][Uu][Ee]|1|[Yy][Ee]?[Ss]?)$ ]]; then\n",
    "        rm -f ./opensees.so || true\n",
    "        echo \"Removed OpenSeesPy file ./opensees.so\" >> \"$SUMMARY_SHORT\"\n",
    "    fi\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 23. Optional: repack the output directory into a single ZIP (ZIP_OUTPUT_SWITCH)\n",
    "\n",
    "This block optionally **converts the job’s output directory into one ZIP archive** and updates ArchiveName so that the later “move output” phase will move either:\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "* the original directory (no zipping), or\n",
    "* the ZIP file (if zipping is enabled).\n",
    "\n",
    "##### How it works\n",
    "\n",
    "Before this block runs, you set:\n",
    "\n",
    "```bash\n",
    "ArchiveName=\"${inputDirectory}\"\n",
    "```\n",
    "\n",
    "So by default, ArchiveName points to the **output folder** itself.\n",
    "\n",
    "This block then:\n",
    "\n",
    "1. **Logs configuration**\n",
    "\n",
    "   It writes a header and echoes ZIP_OUTPUT_SWITCH into SUMMARY_SHORT, so you can see whether this option was turned on for the job.\n",
    "\n",
    "2. **Checks whether zipping is requested**\n",
    "\n",
    "   If ZIP_OUTPUT_SWITCH matches a true-like value (true, yes, 1, etc.), the script:\n",
    "\n",
    "   * Sets\n",
    "\n",
    "     ```bash\n",
    "     ArchiveName=\"inputDirectory.zip\"\n",
    "     ```\n",
    "\n",
    "     overriding the earlier value. From this point on, any later “move output” logic should operate on **inputDirectory.zip** instead of the directory.\n",
    "\n",
    "3. **Creates the ZIP archive**\n",
    "\n",
    "   * Runs:\n",
    "\n",
    "     ```bash\n",
    "     zip -r -q \"${ArchiveName}\" \"./${inputDirectory}\"\n",
    "     ```\n",
    "\n",
    "     which recursively zips ./${inputDirectory} into inputDirectory.zip in the current working directory.\n",
    "   * Logs to SUMMARY_SHORT that the archive was created and from which path.\n",
    "\n",
    "   This reduces the job’s output to **one big file**, which is often much more robust with Tapis archive/transfer limits and typically faster to move.\n",
    "\n",
    "4. **Deletes the original directory**\n",
    "\n",
    "   * Removes the original ${inputDirectory} tree with rm -rf.\n",
    "   * Logs the removal in the summary.\n",
    "\n",
    "   After this, the execution directory contains the ZIP instead of the exploded folder, and ArchiveName now correctly points to the ZIP. The **archive/move phase that follows doesn’t need to care which path was taken** — it simply moves ArchiveName, whether that’s a folder (no zip) or a single ZIP file (zip enabled).\n",
    "\n",
    "##### Why this is helpful\n",
    "\n",
    "* Avoids hitting limits on **number of files** in Tapis archiving.\n",
    "* Makes the archive/move phase **shorter and simpler** (one artifact).\n",
    "* Keeps the interface to later steps clean: they just look at ArchiveName and don’t need branching logic for “folder vs zip.”\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_option_ZIP_OUTPUT = textwrap.dedent(\"\"\"\n",
    "    echo \"=start==============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"=============== REPACK THE OUTPUT DIRECTORY TO ZIP ================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \" ---- optional re-pack an output folder ----\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"ZIP_OUTPUT_SWITCH: ${ZIP_OUTPUT_SWITCH:-}\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "    if [[ \"${ZIP_OUTPUT_SWITCH:-}\" =~ ^([Tt][Rr][Uu][Ee]|1|[Yy][Ee]?[Ss]?)$ ]]; then\n",
    "      ArchiveName=\"inputDirectory.zip\"\n",
    "      \n",
    "      zip -r -q \"${ArchiveName}\" \"./${inputDirectory}\"\n",
    "      echo \"Zipped output: ${ArchiveName} from $(pwd)\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "      rm -rf \"${inputDirectory}\"\n",
    "      echo \"removed\"\n",
    "      echo \"Removed original inputDirectory: ${inputDirectory}\" >> \"$SUMMARY_SHORT\"\n",
    "    fi\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 24. Optional: move main output to a faster storage destination (PATH_MOVE_OUTPUT)\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "This block is the **final handoff step** for job results. Instead of leaving large output directly in the execution directory for Tapis to archive (which can be slow), it optionally **moves the main output to a user-chosen location** on the system (e.g., $SCRATCH or $WORK) and copies over top-level helper files.\n",
    "\n",
    "Because earlier logic sets:\n",
    "\n",
    "* ArchiveName=\"${inputDirectory}\" by default, and\n",
    "* ArchiveName=\"inputDirectory.zip\" if ZIP_OUTPUT_SWITCH is enabled,\n",
    "\n",
    "this block will move **either the output folder or the ZIP file**, depending on how the job was configured.\n",
    "\n",
    "##### 1. Check whether a destination was requested\n",
    "\n",
    "The block reads PATH_MOVE_OUTPUT:\n",
    "\n",
    "* If PATH_MOVE_OUTPUT is unset or empty → **no move is performed**, everything stays in the execution directory.\n",
    "* If it is set → we treat it as the **base directory** where outputs should be moved.\n",
    "\n",
    "Typical choices (user guidance):\n",
    "\n",
    "* **$SCRATCH** – Best for **short-term, high-volume data**. Large, fast, but not backed up; good for heavy, transient outputs.\n",
    "* **$WORK** – Best for **large project storage** that needs to persist across jobs and sessions.\n",
    "* **$HOME** – *Not recommended* for big outputs:\n",
    "\n",
    "  * Intended for permanent small files: configs, scripts, dotfiles, etc.\n",
    "  * Typically has **limited capacity** and is not meant for bulk simulation results.\n",
    "\n",
    "You expose this as an option in the app so users can choose the storage tier that matches their use case.\n",
    "\n",
    "##### 2. Construct a job-specific destination path\n",
    "\n",
    "If PATH_MOVE_OUTPUT is set:\n",
    "\n",
    "1. dest=\"${PATH_MOVE_OUTPUT}\"\n",
    "   Start from the user-provided base path.\n",
    "\n",
    "2. Append the job identifier:\n",
    "\n",
    "   ```bash\n",
    "   dest=\"${dest}/_${JobUUID}\"\n",
    "   ```\n",
    "\n",
    "   * This creates a **unique subdirectory per job**, named with the JobUUID (prefixed by _), which:\n",
    "\n",
    "     * Prevents collisions between runs,\n",
    "     * Makes it easy to find outputs for a specific Tapis job later.\n",
    "\n",
    "3. Create the directory:\n",
    "\n",
    "   ```bash\n",
    "   mkdir -p -- \"$dest\"\n",
    "   ```\n",
    "\n",
    "   * Ensures the full directory path exists before moving/copying.\n",
    "\n",
    "##### 3. Move the main output artifact (ArchiveName)\n",
    "\n",
    "```bash\n",
    "mv -v -- \"$ArchiveName\" \"$dest/\"\n",
    "echo \"Moved main output: ${ArchiveName} -> ${dest}/\" >> \"$SUMMARY_SHORT\"\n",
    "```\n",
    "\n",
    "* Moves the **primary result** (either the folder or the ZIP, depending on earlier steps) into the job-specific directory under PATH_MOVE_OUTPUT.\n",
    "* Uses -v so the move is visible in stdout, and logs the move to SUMMARY_SHORT.\n",
    "\n",
    "This is the key step that makes **Tapis archiving fast**: by moving the heavy data to a different filesystem (e.g., $SCRATCH), the execution directory stays small and light, so Tapis has much less to copy.\n",
    "\n",
    "##### 4. Copy additional top-level files for convenience\n",
    "\n",
    "```bash\n",
    "find . -maxdepth 1 -type f -exec cp -t \"$dest/\" {} +\n",
    "echo \"Copied additional top-level files from $(pwd) -> ${dest}/\" >> \"$SUMMARY_SHORT\"\n",
    "```\n",
    "\n",
    "* Finds all **top-level regular files** in the current directory (e.g., logs, small config files, summary logs).\n",
    "* Copies them into the same destination directory, **without removing** them from the execution directory.\n",
    "* This gives you a **consolidated result folder** containing:\n",
    "\n",
    "  * The main output (folder or ZIP),\n",
    "  * Top-level logs and other important small files.\n",
    "\n",
    "Meanwhile, the execution directory retains minimal, lightweight content so that:\n",
    "\n",
    "* Tapis’s default archive remains small and fast,\n",
    "* The “real” payload is safely stored in your chosen system path ($SCRATCH, $WORK, etc.).\n",
    "\n",
    "This pattern lets the app treat **PATH_MOVE_OUTPUT + ArchiveName** as the main hook for high-volume outputs, while still giving Tapis a quick, small archive to handle.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_option_MOVE_OUTPUT = textwrap.dedent(\"\"\"\n",
    "    echo \"=start==============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================== MOVE MAIN OUTPUT TO FASTER STORAGE DESTINATION ===========\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \" --- move the result to destinations (if requested) ---\" >> \"$SUMMARY_SHORT\"\n",
    "    dest=\"\"\n",
    "    if [[ -n \"${PATH_MOVE_OUTPUT:-}\" ]]; then\n",
    "      dest=\"${PATH_MOVE_OUTPUT}\"\n",
    "      \n",
    "      echo \" ---- move $ArchiveName ---- \"\n",
    "      echo \"add JobUUID to destination path\"\n",
    "      dest=\"${dest}/_${JobUUID}\"\n",
    "      mkdir -p -- \"$dest\"\n",
    "      mv -v -- \"$ArchiveName\" \"$dest/\"\n",
    "      echo \"Moved main output: ${ArchiveName} -> ${dest}/\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "      find . -maxdepth 1 -type f -exec cp -t \"$dest/\" {} +\n",
    "      echo \"Copied additional top-level files from $(pwd) -> ${dest}/\" >> \"$SUMMARY_SHORT\"\n",
    "    fi\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 25. Optional: Pre-Job Hook -- User-Defined script run BEFORE main binary (PRE_JOB_SCRIPT)\n",
    "This block implements an **optional user-defined “pre-job” hook** that runs *before* the main OpenSees/OpenSeesPy execution begins. It allows users to insert their own setup logic — such as preparing input files, generating parameters, running a Python pre-processor, or checking environment conditions — directly inside the job’s execution directory.\n",
    "\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "\n",
    "This block:\n",
    "\n",
    "1. **Announces the hook in the job summary log**\n",
    "   A header entry is written to SLURM-job-summary.log to indicate that the pre-job hook is being evaluated.\n",
    "\n",
    "2. **Checks whether the user provided the environment variable**\n",
    "\n",
    "   ```bash\n",
    "   PRE_JOB_SCRIPT\n",
    "   ```\n",
    "\n",
    "   If the variable is **empty or unset**, the app simply logs:\n",
    "\n",
    "   ```\n",
    "   No PRE_JOB_SCRIPT provided; skipping pre-job hook.\n",
    "   ```\n",
    "\n",
    "3. **Resolves the script’s location**\n",
    "\n",
    "   * If the user provides:\n",
    "\n",
    "     * a **full absolute path** → used as-is\n",
    "     * a **filename only** → the wrapper assumes the file is inside the job’s input directory (./)\n",
    "\n",
    "4. **Executes the script appropriately**\n",
    "   The logic distinguishes between:\n",
    "\n",
    "   * **Executable scripts** (chmod +x <file>) → run directly\n",
    "   * **Non-executable files** → run using bash <file>\n",
    "   * **Missing or invalid paths** → log a warning\n",
    "\n",
    "5. **Error handling**\n",
    "   If the script fails, the wrapper:\n",
    "\n",
    "   * Logs a warning with the exit code\n",
    "   * *Does not stop the job by default*\n",
    "     (the policy is intentionally lenient so users can choose whether a hook failure should stop the entire job)\n",
    "\n",
    "   The wrapper includes a commented line showing where a stricter \"fail-fast\" policy could be activated.\n",
    "\n",
    "##### **Why this feature matters**\n",
    "\n",
    "This hook gives users considerable flexibility **without modifying the core app**, enabling tasks such as:\n",
    "\n",
    "* Creating randomized parameter sets\n",
    "* Unzipping or reorganizing input files\n",
    "* Generating model files on the fly\n",
    "* Preparing database connections\n",
    "* Logging metadata to custom files\n",
    "* Running small diagnostic checks before the HPC job starts\n",
    "\n",
    "The hook is safe, optional, and entirely user-controlled.\n",
    "\n",
    "##### **How to use it**\n",
    "\n",
    "Users simply include in their Tapis job submission:\n",
    "\n",
    "```json\n",
    "\"envVariables\": {\n",
    "    \"PRE_JOB_SCRIPT\": \"prepare_inputs.sh\"\n",
    "}\n",
    "```\n",
    "\n",
    "…and place prepare_inputs.sh inside the **Input Directory**, or supply a full absolute path.\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_option_PRE_JOB_SCRIPT = textwrap.dedent(\"\"\"\n",
    "    echo \"=start==============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"======================== PRE-JOB HOOK =============================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"OPTIONAL: pre-job hook\" >> \"$SUMMARY_SHORT\"\n",
    "    if [[ -n \"${PRE_JOB_SCRIPT:-}\" ]]; then\n",
    "      echo \"PRE_JOB_SCRIPT specified: ${PRE_JOB_SCRIPT}\" >> \"$SUMMARY_SHORT\"\n",
    "    \n",
    "      # If user passed just a filename, assume it is in the current directory (inputDirectory)\n",
    "      _pre=\"${PRE_JOB_SCRIPT}\"\n",
    "      if [[ ! \"$_pre\" = /* ]]; then\n",
    "        _pre=\"./${_pre}\"\n",
    "      fi\n",
    "    \n",
    "      if [[ -x \"$_pre\" ]]; then\n",
    "        echo \"Running pre-job script (executable): $_pre\" >> \"$SUMMARY_SHORT\"\n",
    "        if ! \"$_pre\"; then\n",
    "          rc=$?\n",
    "          echo \"WARNING: pre-job script exited with status $rc\" >> \"$SUMMARY_SHORT\"\n",
    "          # Decide policy: fail hard or continue\n",
    "          # exit \"$rc\"\n",
    "        fi\n",
    "      elif [[ -f \"$_pre\" ]]; then\n",
    "        echo \"Running pre-job script via bash: $_pre\" >> \"$SUMMARY_SHORT\"\n",
    "        if ! bash \"$_pre\"; then\n",
    "          rc=$?\n",
    "          echo \"WARNING: pre-job script (bash) exited with status $rc\" >> \"$SUMMARY_SHORT\"\n",
    "          # exit \"$rc\"\n",
    "        fi\n",
    "      else\n",
    "        echo \"WARNING: PRE_JOB_SCRIPT not found: $_pre\" >> \"$SUMMARY_SHORT\"\n",
    "      fi\n",
    "    else\n",
    "      echo \"No PRE_JOB_SCRIPT provided; skipping pre-job hook.\" >> \"$SUMMARY_SHORT\"\n",
    "    fi\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 26. Optional: Post-Job Hook -- User-Defined script run AFTER main binary (POST_JOB_SCRIPT)\n",
    "This block implements an **optional user-defined “post-job” hook** that runs *after* the main executable finishes, but *before* the script leaves the job directory and before final timers/output handling are logged. It allows users to attach custom post-processing steps directly to the job workflow.\n",
    "\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "This block:\n",
    "\n",
    "1. **Announces the hook in the job summary log**\n",
    "   It writes a section header to SLURM-job-summary.log:\n",
    "\n",
    "   ```text\n",
    "   OPTIONAL: post-job hook\n",
    "   ```\n",
    "\n",
    "   so users can clearly see whether a post-job script was requested and how it behaved.\n",
    "\n",
    "2. **Checks whether the user provided POST_JOB_SCRIPT**\n",
    "   If the environment variable is unset or empty, the app logs:\n",
    "\n",
    "   ```text\n",
    "   No POST_JOB_SCRIPT provided; skipping post-job hook.\n",
    "   ```\n",
    "\n",
    "   and proceeds without running anything extra.\n",
    "\n",
    "3. **Resolves the script path**\n",
    "   Similar to the pre-hook:\n",
    "\n",
    "   * If POST_JOB_SCRIPT is an **absolute path**, it is used directly.\n",
    "   * If it is just a **filename**, the wrapper assumes it lives in the current working directory (usually the inputDirectory):\n",
    "\n",
    "     ```bash\n",
    "     _post=\"./${POST_JOB_SCRIPT}\"\n",
    "     ```\n",
    "\n",
    "4. **Executes the script in a flexible way**\n",
    "   The handler distinguishes between:\n",
    "\n",
    "   * **Executable files** (chmod +x post_hook.sh) → run directly:\n",
    "\n",
    "     ```bash\n",
    "     \"$_post\"\n",
    "     ```\n",
    "\n",
    "   * **Non-executable files** → run via:\n",
    "\n",
    "     ```bash\n",
    "     bash \"$_post\"\n",
    "     ```\n",
    "\n",
    "   * **Missing/invalid paths** → a warning is written to the summary log.\n",
    "\n",
    "5. **Error handling**\n",
    "   If the post-job script fails (non-zero exit code), the wrapper:\n",
    "\n",
    "   * Logs a warning containing the exit status\n",
    "   * By default, **does not abort the job** at this late stage\n",
    "\n",
    "   The code includes a commented exit \"$rc\" line to show where a stricter “fail on post-hook error” policy could be enabled if desired.\n",
    "\n",
    "##### **Why this feature matters**\n",
    "\n",
    "The post-job hook provides a convenient place to run **custom post-processing** *inside the same job*, without editing the main Tapis app or wrapper script. Typical use cases include:\n",
    "\n",
    "* Aggregating or compressing output files\n",
    "* Creating summary figures or CSV tables\n",
    "* Running validation checks on the results\n",
    "* Writing additional custom logs or metadata\n",
    "* Pushing results into user-specific directory structures (within the execution system)\n",
    "* Cleaning up intermediate scratch data while keeping key outputs\n",
    "\n",
    "Because the hook runs after the main program finishes, it’s a natural place to attach “last step” logic.\n",
    "\n",
    "##### **How to use it**\n",
    "\n",
    "Users can specify the hook via an environment variable in their Tapis job:\n",
    "\n",
    "```json\n",
    "\"envVariables\": {\n",
    "  \"POST_JOB_SCRIPT\": \"postprocess_results.sh\"\n",
    "}\n",
    "```\n",
    "\n",
    "and place postprocess_results.sh in the **Input Directory** (or specify an absolute path).\n",
    "\n",
    "The wrapper will then:\n",
    "\n",
    "* resolve the path,\n",
    "* execute it either as an executable or via bash,\n",
    "* and log any warnings if the script exits with a non-zero status.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_option_POST_JOB_SCRIPT = textwrap.dedent(\"\"\"\n",
    "    echo \"=start==============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"======================== POST-JOB HOOK ============================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"OPTIONAL: post-job hook\" >> \"$SUMMARY_SHORT\"\n",
    "    if [[ -n \"${POST_JOB_SCRIPT:-}\" ]]; then\n",
    "      echo \"POST_JOB_SCRIPT specified: ${POST_JOB_SCRIPT}\" >> \"$SUMMARY_SHORT\"\n",
    "    \n",
    "      _post=\"${POST_JOB_SCRIPT}\"\n",
    "      if [[ ! \"$_post\" = /* ]]; then\n",
    "        _post=\"./${_post}\"\n",
    "      fi\n",
    "    \n",
    "      if [[ -x \"$_post\" ]]; then\n",
    "        echo \"Running post-job script (executable): $_post\" >> \"$SUMMARY_SHORT\"\n",
    "        if ! \"$_post\"; then\n",
    "          rc=$?\n",
    "          echo \"WARNING: post-job script exited with status $rc\" >> \"$SUMMARY_SHORT\"\n",
    "          # Decide policy: fail or continue; usually continue:\n",
    "          # exit \"$rc\"\n",
    "        fi\n",
    "      elif [[ -f \"$_post\" ]]; then\n",
    "        echo \"Running post-job script via bash: $_post\" >> \"$SUMMARY_SHORT\"\n",
    "        if ! bash \"$_post\"; then\n",
    "          rc=$?\n",
    "          echo \"WARNING: post-job script (bash) exited with status $rc\" >> \"$SUMMARY_SHORT\"\n",
    "          # exit \"$rc\"\n",
    "        fi\n",
    "      else\n",
    "        echo \"WARNING: POST_JOB_SCRIPT not found: $_post\" >> \"$SUMMARY_SHORT\"\n",
    "      fi\n",
    "    else\n",
    "      echo \"No POST_JOB_SCRIPT provided; skipping post-job hook.\" >> \"$SUMMARY_SHORT\"\n",
    "    fi\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 27. Change Directory (cd) INTO Input Directory\n",
    "Change to Input Directory (with Logging)\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "\n",
    "This script block switches the working directory to the job’s designated input directory and records that action in the short summary log. \n",
    "\n",
    "It appends a clearly marked header and footer to *SUMMARY_SHORT*, making it easy to see when the script attempts to *cd* into *$inputDirectory*. \n",
    "\n",
    "The 'cd -- \"$inputDirectory\"' command safely handles paths that may contain spaces or begin with a dash, and the subsequent *pwd* call confirms the new working directory, writing the resolved path back to *SUMMARY_SHORT* for traceability and debugging.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_cd_InputDirectory_IN = textwrap.dedent(\"\"\"\n",
    "    echo \"=start==============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"==================== CD INTO INPUT DIRECTORY ======================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    cd -- \"$inputDirectory\" \n",
    "    echo \"Changed directory to: $(pwd)\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 28. Change Directory (cd) OUT OF Input Directory\n",
    "Change Back to Parent Directory (with Logging)\n",
    "<details>\n",
    "<summary><strong>What this block does</strong></summary>\n",
    "\n",
    "This script block moves the working directory up one level in the directory hierarchy and logs the change to *SUMMARY_SHORT*. \n",
    "\n",
    "It first appends a visual separator line to make the action easy to spot in the summary log, then runs 'cd ..' to go to the parent directory.\n",
    "\n",
    "Finally, it records the new working directory using *pwd*, writing the resolved path to *SUMMARY_SHORT* so it’s clear where subsequent commands will execute.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_cd_InputDirectory_OUT = textwrap.dedent(\"\"\"\n",
    "    echo \"=start==============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"=================== CD BACK FROM INPUT DIRECTORY ==================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"===================================================================\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"cd back one folder\"\n",
    "    cd ..\n",
    "    echo \"changed directory back to: $(pwd)\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"=end===============================================================\" >> \"$SUMMARY_SHORT\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble Main Wrapper File: **tapisjob_app.sh**\n",
    "\n",
    "This `tapisjob_app.sh` skeleton is the **master wrapper script** that the notebook assembles and then **packs into the app ZIP**. All the ***placeholders*** in it get replaced with the app-specific blocks you defined earlier (initialize, logging, module/pip setup, OpenSeesPy handling, timers, etc.).\n",
    "\n",
    "**tapisjob_app.sh is the orchestrator**. The notebook builds it from your modular chunks, then zips it before uploading, together with the rest of the app files, to the TACC system. Every job launched by this app runs through this script, which standardizes logging, environment setup, execution, and output handling for OpenSees/OpenSeesPy workflows on DesignSafe/TACC.\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary><b><large>Details of tapisjob_app.sh (generated job wrapper)</large></b></summary>\n",
    "\n",
    "This file is the **main SLURM/Tapis job driver** that the app runs for each submission. It is **auto-generated** in the notebook by stitching together modular code blocks (the `__run_*__`, `__option_*__`, and `__echoSummary_*__` placeholders). Once assembled, this script is included in the app’s runtime ZIP and uploaded to the TACC system.\n",
    "\n",
    "At runtime, `tapisjob_app.sh` is responsible for:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Initialization and argument validation\n",
    "\n",
    "* Enforces required arguments: binary name, input script, and the `UseMPI` flag.\n",
    "* Captures `inputDirectory`, `JobUUID`, and the starting directory.\n",
    "* Starts global timers for the entire script and enables safe shell behavior:\n",
    "\n",
    "  ```bash\n",
    "  set -euo pipefail\n",
    "  set -x\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Job summary + environment logging\n",
    "\n",
    "* Initializes the compact summary log (`SUMMARY_SHORT`) and the full environment log.\n",
    "* Records app metadata, key paths (`$HOME`, `$WORK`, `$SCRATCH`), user configuration, and environment variables that control:\n",
    "\n",
    "  * module loading,\n",
    "  * pip installs,\n",
    "  * file copy-in,\n",
    "  * unzipping,\n",
    "  * output movement and zipping.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Move into the input directory & optional pre-run preparation\n",
    "\n",
    "```bash\n",
    "cd -- \"$inputDirectory\"\n",
    "```\n",
    "\n",
    "From inside the job’s working folder, the script may:\n",
    "\n",
    "* **Copy in** extra files or directories specified via `PATH_COPY_IN_LIST`.\n",
    "* **Unzip** any input archives (`UNZIP_FILES_LIST`) so the run sees expanded input data.\n",
    "\n",
    "If copy-in is enabled, the script also initializes a **copy-in manifest**, which records exactly which files or directories were staged into the working directory. This manifest is later used for optional cleanup.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Environment setup (modules + pip)\n",
    "\n",
    "The script performs layered environment configuration:\n",
    "\n",
    "* Ensures the `module` command is available.\n",
    "* Optionally loads modules from:\n",
    "\n",
    "  * a **module file** (`MODULE_LOADS_FILE`), and/or\n",
    "  * a **comma-separated list** (`MODULE_LOADS_LIST`).\n",
    "* Optionally stages the **TACC-compiled OpenSeesPy** shared library (`GET_TACC_OPENSEESPY`).\n",
    "* Optionally installs Python packages from:\n",
    "\n",
    "  * a **requirements-style file** (`PIP_INSTALLS_FILE`), and/or\n",
    "  * a **comma-separated list** (`PIP_INSTALLS_LIST`).\n",
    "\n",
    "After this phase, the job has a reproducible, fully documented runtime environment.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Launcher selection and main run\n",
    "\n",
    "* Chooses how to launch the binary:\n",
    "\n",
    "  * direct execution (sequential), or\n",
    "  * `ibrun` (MPI) if `UseMPI` is true-like.\n",
    "* Starts a **binary-run timer**, executes the application, and:\n",
    "\n",
    "  * On error: records run/total timings, logs the error code, and exits with that code.\n",
    "  * On success: logs a “NO ERROR” message and continues.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Post-run cleanup inside the input directory (runtime artifacts)\n",
    "\n",
    "* If TACC OpenSeesPy was staged in (`GET_TACC_OPENSEESPY`), the temporary `opensees.so` is removed after the run to avoid polluting the directory.\n",
    "* Other short-lived runtime artifacts created solely for execution (temporary launch helpers, scratch symlinks, etc.) are cleaned up here if applicable.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Optional cleanup of copy-in files (end-of-job hygiene)\n",
    "\n",
    "If the user enables:\n",
    "\n",
    "```bash\n",
    "DELETE_COPIED_IN_ON_EXIT=1\n",
    "```\n",
    "\n",
    "the script performs a **controlled cleanup of files and directories that were copied in before the run**:\n",
    "\n",
    "* A cleanup function is registered via a Bash `EXIT` trap, ensuring it runs:\n",
    "\n",
    "  * on normal completion,\n",
    "  * on application failure,\n",
    "  * or on unexpected script termination.\n",
    "* The cleanup logic:\n",
    "\n",
    "  * reads the copy-in manifest created during the pre-run copy phase,\n",
    "  * deletes **only** the paths that were explicitly copied into the working directory,\n",
    "  * refuses to delete absolute paths, parent traversals (`..`), or anything outside the job directory.\n",
    "* Each deletion is logged to `SUMMARY_SHORT` for transparency and traceability.\n",
    "\n",
    "This keeps job directories clean while ensuring deletion is **explicit, auditable, and opt-in**.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Return to the parent directory and archive preparation\n",
    "\n",
    "```bash\n",
    "cd ..\n",
    "ArchiveName=\"${inputDirectory}\"\n",
    "```\n",
    "\n",
    "Back in the parent directory, the script treats `ArchiveName` as the **main output artifact**:\n",
    "\n",
    "* By default, this is the original output folder.\n",
    "* If `ZIP_OUTPUT_SWITCH` is enabled:\n",
    "\n",
    "  * the folder is repacked into `inputDirectory.zip`,\n",
    "  * the original directory is removed,\n",
    "  * `ArchiveName` is updated to reference the ZIP instead.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Optional output move (fast archive strategy)\n",
    "\n",
    "* If `PATH_MOVE_OUTPUT` is set:\n",
    "\n",
    "  * a job-specific subdirectory (using `JobUUID`) is created under the chosen base path (e.g., `$SCRATCH` or `$WORK`),\n",
    "  * the main output artifact (`ArchiveName`) is moved there,\n",
    "  * top-level logs and summaries are copied alongside it.\n",
    "\n",
    "This minimizes the size of the execution directory and makes Tapis archiving significantly faster.\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Final timing footer and completion\n",
    "\n",
    "* Writes the total script end time and full runtime (setup + run + post-processing) into `SUMMARY_SHORT`.\n",
    "* Prints a final `DONE!` marker to clearly indicate wrapper completion.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_tapisJob_app_base = textwrap.dedent(\"\"\"\\\n",
    "\n",
    "    __run_INITIALIZE__\n",
    "    \n",
    "    __echoSummary_START__\n",
    "    \n",
    "    __echoSummary_VERBOSE__\n",
    "\n",
    "    __cd_InputDirectory_IN__\n",
    "\n",
    "    __option_COPY_FILES__\n",
    "\n",
    "    __option_UNZIP__\n",
    "\n",
    "    __option_MODULE_ENV_SETUP__\n",
    "\n",
    "    __option_MODULE_LOAD_FILE__\n",
    "\n",
    "    __option_MODULE_LOAD_LIST__\n",
    "\n",
    "    __option_COPY_OPENSEESPY__\n",
    "\n",
    "    __option_OPS_MODULES_LOAD__\n",
    "\n",
    "    __option_PyLauncher_MODULES_LOAD__\n",
    "\n",
    "    __option_PYTHON_ALIAS__\n",
    "    \n",
    "    __option_PIP_FILE__\n",
    "\n",
    "    __option_PIP_LIST__\n",
    "    \n",
    "    echo \"###############################################################################\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"DONE with installations\" >> \"$SUMMARY_SHORT\"\n",
    "    echo \"\" >> \"$SUMMARY_SHORT\"\n",
    "\n",
    "    __option_PRE_JOB_SCRIPT__\n",
    "\n",
    "    __run_CHOOSE_LAUNCHER__\n",
    "\n",
    "    __run_RUN_JOB__\n",
    "\n",
    "    __echoTimers_AFTER__\n",
    "\n",
    "    __option_DELETE_OPENSEESPY__\n",
    "\n",
    "    __option_POST_JOB_SCRIPT__\n",
    "\n",
    "    __cd_InputDirectory_OUT__\n",
    "\n",
    "    ArchiveName=\"${inputDirectory}\"\n",
    "\n",
    "    __option_ZIP_OUTPUT__\n",
    "    \n",
    "    __option_MOVE_OUTPUT__\n",
    "\n",
    "    __echoTimers_END__\n",
    "\n",
    "    echo \"DONE!\"\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace batch_script patches into the Main Wrapper File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A. Replace batch_script patches -- All Apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__run_INITIALIZE__\", bash_script_run_INITIALIZE)\n",
    "\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__app_Author_Info__\", app_Author_Info)\n",
    "\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__cd_InputDirectory_IN__\", bash_script_cd_InputDirectory_IN)\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__cd_InputDirectory_OUT__\", bash_script_cd_InputDirectory_OUT)\n",
    "\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__run_CHOOSE_LAUNCHER__\", bash_script_run_CHOOSE_LAUNCHER)\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__run_RUN_JOB__\", bash_script_run_RUN_JOB)\n",
    "\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__echoSummary_START__\", bash_script_echoSummary_START)\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__echoTimers_START__\", bash_script_echoTimers_START)\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__echoTimers_AFTER__\", bash_script_echoTimers_AFTER)\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__echoTimers_END__\", bash_script_echoTimers_END)\n",
    "\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__option_MODULE_ENV_SETUP__\", bash_script_option_MODULE_ENV_SETUP)\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__option_MODULE_LOAD_LIST__\", bash_script_option_MODULE_LOAD_LIST)\n",
    "\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__option_OPS_MODULES_LOAD__\", bash_script_option_OPS_MODULES_LOAD)\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__option_PyLauncher_MODULES_LOAD__\", bash_script_option_PYLAUNCHER_MODULES_LOAD)\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__option_PIP_LIST__\", bash_script_option_PIP_LIST)\n",
    "\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__option_COPY_OPENSEESPY__\", bash_script_option_COPY_OPENSEESPY)\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__option_DELETE_OPENSEESPY__\", bash_script_option_DELETE_OPENSEESPY)\n",
    "\n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__option_PYTHON_ALIAS__\", bash_script_option_PYTHON_ALIAS)\n",
    "\n",
    "\n",
    "    \n",
    "bash_script_tapisJob_app_base = bash_script_tapisJob_app_base.replace(\"__option_PIP_FILE__\", bash_script_option_PIP_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B. Replace batch_script patches -- Agnostic App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_makeApp:\n",
    "    bash_script_tapisJob_app = bash_script_tapisJob_app_base\n",
    "    bash_script_tapisJob_app = bash_script_tapisJob_app.replace(\"__echoSummary_ARGS__\", bash_script_echoSummary_ARGS)\n",
    "    bash_script_tapisJob_app = bash_script_tapisJob_app.replace(\"__echoSummary_ENV_VARS__\", bash_script_echoSummary_ENV_VARS)\n",
    "    bash_script_tapisJob_app = bash_script_tapisJob_app.replace(\"__echoSummary_MPI__\", bash_script_echoSummary_MPI)\n",
    "    \n",
    "    bash_script_tapisJob_app = bash_script_tapisJob_app.replace(\"__echoSummary_VERBOSE__\", bash_script_echoSummary_VERBOSE)\n",
    "    \n",
    "    bash_script_tapisJob_app = bash_script_tapisJob_app.replace(\"__option_COPY_FILES__\", bash_script_option_COPY_FILES)\n",
    "    bash_script_tapisJob_app = bash_script_tapisJob_app.replace(\"__option_UNZIP__\", bash_script_option_UNZIP)\n",
    "    bash_script_tapisJob_app = bash_script_tapisJob_app.replace(\"__option_MODULE_LOAD_FILE__\", bash_script_option_MODULE_LOAD_FILE)\n",
    "    \n",
    "\n",
    "    bash_script_tapisJob_app = bash_script_tapisJob_app.replace(\"__option_PRE_JOB_SCRIPT__\", bash_script_option_PRE_JOB_SCRIPT)\n",
    "    bash_script_tapisJob_app = bash_script_tapisJob_app.replace(\"__option_POST_JOB_SCRIPT__\", bash_script_option_POST_JOB_SCRIPT)\n",
    "    \n",
    "    bash_script_tapisJob_app = bash_script_tapisJob_app.replace(\"__option_ZIP_OUTPUT__\", bash_script_option_ZIP_OUTPUT)\n",
    "    bash_script_tapisJob_app = bash_script_tapisJob_app.replace(\"__option_MOVE_OUTPUT__\", bash_script_option_MOVE_OUTPUT)\n",
    "\n",
    "    bash_script_tapisJob_app = bash_script_tapisJob_app.replace(\"__app_id__\", app_id)\n",
    "    bash_script_tapisJob_app = bash_script_tapisJob_app.replace(\"__app_version__\", app_version)\n",
    "    bash_script_tapisJob_app = bash_script_tapisJob_app.replace(\"__app_description__\", app_description)\n",
    "    bash_script_tapisJob_app = bash_script_tapisJob_app.replace(\"__app_helpUrl__\", app_helpUrl)\n",
    "\n",
    "    \n",
    "    thisFilename_sh = \"tapisjob_app.sh\"\n",
    "\n",
    "    with open(f\"{appPath_Local}/{thisFilename_sh}\", \"w\") as f:\n",
    "        f.write(bash_script_tapisJob_app)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15ceac65816470eaf8f9cac48fb1549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if do_makeApp:\n",
    "    OpsUtils.show_text_file_in_accordion(appPath_Local, [thisFilename_sh], background='#d4fbff', showLineNumbers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C. Replace batch_script patches -- OpenSeesPy App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_makeApp_OpsPy:\n",
    "    bash_script_tapisJob_app_OpsPy = bash_script_tapisJob_app_base\n",
    "    bash_script_tapisJob_app_OpsPy = bash_script_tapisJob_app_OpsPy.replace(\"__echoSummary_ARGS__\", '')\n",
    "    bash_script_tapisJob_app_OpsPy = bash_script_tapisJob_app_OpsPy.replace(\"__echoSummary_ENV_VARS__\", '')\n",
    "    bash_script_tapisJob_app_OpsPy = bash_script_tapisJob_app_OpsPy.replace(\"__echoSummary_MPI__\", '')\n",
    "    \n",
    "    bash_script_tapisJob_app_OpsPy = bash_script_tapisJob_app_OpsPy.replace(\"__echoSummary_VERBOSE__\", '')\n",
    "    \n",
    "    bash_script_tapisJob_app_OpsPy = bash_script_tapisJob_app_OpsPy.replace(\"__option_COPY_FILES__\", '')\n",
    "    bash_script_tapisJob_app_OpsPy = bash_script_tapisJob_app_OpsPy.replace(\"__option_UNZIP__\", '')\n",
    "    bash_script_tapisJob_app_OpsPy = bash_script_tapisJob_app_OpsPy.replace(\"__option_MODULE_LOAD_FILE__\", '')\n",
    "\n",
    "    bash_script_tapisJob_app_OpsPy = bash_script_tapisJob_app_OpsPy.replace(\"__option_PRE_JOB_SCRIPT__\", '')\n",
    "    bash_script_tapisJob_app_OpsPy = bash_script_tapisJob_app_OpsPy.replace(\"__option_POST_JOB_SCRIPT__\", '')    \n",
    "    \n",
    "    bash_script_tapisJob_app_OpsPy = bash_script_tapisJob_app_OpsPy.replace(\"__option_ZIP_OUTPUT__\", '')\n",
    "    bash_script_tapisJob_app_OpsPy = bash_script_tapisJob_app_OpsPy.replace(\"__option_MOVE_OUTPUT__\", '')\n",
    "\n",
    "    bash_script_tapisJob_app_OpsPy = bash_script_tapisJob_app_OpsPy.replace(\"__app_id__\", app_id_OpsPy)\n",
    "    bash_script_tapisJob_app_OpsPy = bash_script_tapisJob_app_OpsPy.replace(\"__app_version__\", app_version_OpsPy)\n",
    "    bash_script_tapisJob_app_OpsPy = bash_script_tapisJob_app_OpsPy.replace(\"__app_description__\", app_description_OpsPy)\n",
    "    bash_script_tapisJob_app_OpsPy = bash_script_tapisJob_app_OpsPy.replace(\"__app_helpUrl__\", app_helpUrl_OpsPy)\n",
    "    \n",
    "    thisFilename_sh_OpsPy = \"tapisjob_app.sh\"\n",
    "\n",
    "    with open(f\"{appPath_Local_OpsPy}/{thisFilename_sh_OpsPy}\", \"w\") as f:\n",
    "        f.write(bash_script_tapisJob_app_OpsPy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3032d4bdaa4cefb6722bf312f5a16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if do_makeApp_OpsPy:\n",
    "    OpsUtils.show_text_file_in_accordion(appPath_Local, [thisFilename_sh_OpsPy], background='#d4fbff', showLineNumbers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Create **tapisjob_app.zip** – App Zip File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf60e68fb484743bce60342deee2138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OpsUtils.show_text_file_in_accordion(PathOpsUtils, 'zip_file.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zip_path /home/jupyter/MyData/myAuthoredTapisApps/designsafe-agnostic-app/1.3.11/designsafe-agnostic-app.zip\n"
     ]
    }
   ],
   "source": [
    "if do_makeApp:\n",
    "    zip_path = os.path.join(appPath_Local, container_filename)\n",
    "    OpsUtils.zip_file(zip_path,thisFilename_sh,bash_script_tapisJob_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zip_path /home/jupyter/MyData/myAuthoredTapisApps/designsafe-openseespy-s3/1.2.15/designsafe-openseespy-s3.zip\n"
     ]
    }
   ],
   "source": [
    "if do_makeApp_OpsPy:\n",
    "    zip_path_OpsPy = os.path.join(appPath_Local_OpsPy, container_filename_OpsPy)\n",
    "    OpsUtils.zip_file(zip_path_OpsPy,thisFilename_sh_OpsPy,bash_script_tapisJob_app_OpsPy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. File Check -- Visualize File Contents in Local (Development) Path\n",
    "Look at the files we have written and check for typos or formatting errors.\n",
    "\n",
    "**Validation and Line-Numbered Views**\n",
    "\n",
    "    The notebook shows the app-definition files with and without line numbers:\n",
    "    \n",
    "    * **Without line numbers**: ideal when you need to copy the JSON content into another tool or system without extra markup.\n",
    "    * **With line numbers**: ideal for debugging JSON validation errors (e.g., “invalid JSON at line 127, column 10”). You can quickly navigate to the offending line in the notebook view.\n",
    "    \n",
    "    This small UX choice dramatically simplifies the **app-validation cycle**: inspect, fix, re-validate, repeat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Files for Content -- No Line Numbers\n",
    "Good for copying content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e77a2bf2754b96b1eedd9d1bcd1b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Output(),), titles=('Local Files NO LINE NUMBERS',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showLineNumbers = False\n",
    "accordionTitle = f'Local Files NO LINE NUMBERS'\n",
    "if do_makeApp or do_makeApp_OpsPy:\n",
    "    here_out = widgets.Output()\n",
    "    here_accordion = widgets.Accordion(children=[here_out])\n",
    "    # here_accordion.selected_index = 0\n",
    "    here_accordion.set_title(0, accordionTitle)\n",
    "    display(here_accordion)\n",
    "    \n",
    "    with here_out:\n",
    "        if do_makeApp:\n",
    "            appfiles = os.listdir(appPath_Local); # same as before\n",
    "            print('app_id:',app_id)\n",
    "            print('appPath_Local:',appPath_Local)\n",
    "            print('appfiles:',appfiles)\n",
    "            OpsUtils.show_text_file_in_accordion(appPath_Local, appfiles, background='lightyellow', showLineNumbers=showLineNumbers)\n",
    "            if len(appfiles)==0:\n",
    "                here_accordion.set_title(0, 'ERROR!!!!! THERE ARE NO FILES!!!')\n",
    "        if do_makeApp_OpsPy:\n",
    "            appfiles_OpsPy = os.listdir(appPath_Local_OpsPy); # same as before\n",
    "            print('\\napp_id_opsPy:',app_id_OpsPy)\n",
    "            print('appPath_Local_OpsPy:',appPath_Local_OpsPy)\n",
    "            print('appfiles_OpsPy:',appfiles_OpsPy)\n",
    "            OpsUtils.show_text_file_in_accordion(appPath_Local_OpsPy, appfiles_OpsPy, background='lightyellow', showLineNumbers=showLineNumbers)\n",
    "            if len(appfiles_OpsPy)==0:\n",
    "                here_accordion.set_title(0,'ERROR!!!!!! THERE ARE NO FILES!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Files for Debugging -- SHOW Line Numbers\n",
    "Useful for Error-Source Identification in Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93c56fa94914ccbb0bbc21e213264fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Output(),), titles=('Local Files SHOW LINE NUMBERS',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showLineNumbers = True\n",
    "accordionTitle = f'Local Files SHOW LINE NUMBERS'\n",
    "if do_makeApp or do_makeApp_OpsPy:\n",
    "    here_out = widgets.Output()\n",
    "    here_accordion = widgets.Accordion(children=[here_out])\n",
    "    # here_accordion.selected_index = 0\n",
    "    here_accordion.set_title(0, accordionTitle)\n",
    "    display(here_accordion)\n",
    "    \n",
    "    with here_out:\n",
    "        if do_makeApp:\n",
    "            appfiles = os.listdir(appPath_Local); # same as before\n",
    "            print('app_id:',app_id)\n",
    "            print('appPath_Local:',appPath_Local)\n",
    "            print('appfiles:',appfiles)\n",
    "            OpsUtils.show_text_file_in_accordion(appPath_Local, appfiles, background='lightyellow', showLineNumbers=showLineNumbers)\n",
    "            if len(appfiles)==0:\n",
    "                here_accordion.set_title(0,'ERROR!!!!!! THERE ARE NO FILES!!!')\n",
    "        if do_makeApp_OpsPy:\n",
    "            appfiles_OpsPy = os.listdir(appPath_Local_OpsPy); # same as before\n",
    "            print('\\napp_id_opsPy:',app_id_OpsPy)\n",
    "            print('appPath_Local_OpsPy:',appPath_Local_OpsPy)\n",
    "            print('appfiles_OpsPy:',appfiles_OpsPy)\n",
    "            OpsUtils.show_text_file_in_accordion(appPath_Local_OpsPy, appfiles_OpsPy, background='lightyellow', showLineNumbers=showLineNumbers)\n",
    "            if len(appfiles_OpsPy)==0:\n",
    "                here_accordion.set_title(0,'ERROR!!!!!! THERE ARE NO FILES!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Validate App Files Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d73b1bce3f47d58c68a620916559de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OpsUtils.show_text_file_in_accordion(PathOpsUtils, 'validate_app_folder.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Validating app folder: /home/jupyter/MyData/myAuthoredTapisApps/designsafe-agnostic-app/1.3.11\n",
      "\n",
      "✅ All required files are present.\n",
      "\n",
      "📄 App ID: designsafe-agnostic-app\n",
      "📄 App Name: (missing)\n",
      "📄 Version: 1.3.11\n",
      "🔧 Parameters: []\n",
      "📦 Inputs: []\n",
      "📤 Outputs: []\n",
      "\n",
      "App Keys: ['id', 'version', 'description', 'owner', 'enabled', 'runtime', 'runtimeVersion', 'runtimeOptions', 'containerImage', 'jobType', 'maxJobs', 'maxJobsPerUser', 'strictFileInputs', 'jobAttributes', 'tags', 'notes']\n",
      "\n",
      "✅ Basic validation complete. App folder looks good!\n"
     ]
    }
   ],
   "source": [
    "if do_makeApp:\n",
    "    appfiles = os.listdir(appPath_Local)\n",
    "    if len(appfiles_OpsPy)==0:\n",
    "        print('ERROR!!!!! THERE ARE NO FILES!!!')\n",
    "    validation = OpsUtils.validate_app_folder(appPath_Local,appfiles)\n",
    "    if not validation:\n",
    "        print('Validation Failed: stopping here!!!!')\n",
    "        a = 3/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Validating app folder: /home/jupyter/MyData/myAuthoredTapisApps/designsafe-openseespy-s3/1.2.15\n",
      "\n",
      "✅ All required files are present.\n",
      "\n",
      "📄 App ID: designsafe-openseespy-s3\n",
      "📄 App Name: (missing)\n",
      "📄 Version: 1.2.15\n",
      "🔧 Parameters: []\n",
      "📦 Inputs: []\n",
      "📤 Outputs: []\n",
      "\n",
      "App Keys: ['id', 'version', 'description', 'owner', 'enabled', 'runtime', 'runtimeVersion', 'runtimeOptions', 'containerImage', 'jobType', 'maxJobs', 'maxJobsPerUser', 'strictFileInputs', 'jobAttributes', 'tags', 'notes']\n",
      "\n",
      "✅ Basic validation complete. App folder looks good!\n"
     ]
    }
   ],
   "source": [
    "if do_makeApp_OpsPy:\n",
    "    appfiles_OpsPy = os.listdir(appPath_Local_OpsPy)\n",
    "    if len(appfiles_OpsPy)==0:\n",
    "        print('ERROR!!!!! THERE ARE NO FILES!!!')\n",
    "    validation = OpsUtils.validate_app_folder(appPath_Local_OpsPy,appfiles_OpsPy)\n",
    "    if not validation:\n",
    "        print('Validation Failed: stopping here!!!!')\n",
    "        a = 3/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Deploy the App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Files to appPath_Tapis\n",
    "Although Tapis can create directories and upload files, filesystem operations through the API tend to be slow.\n",
    "\n",
    "If you have direct access to the target directory (e.g., via JupyterHub or SSH), it is usually faster to create folders and copy files using Python’s **os** and **shutil** utilities—though note that the destination filesystem itself may still be slow, regardless of the method used.\n",
    "\n",
    "* File-Transfer Options:\n",
    "    * **Using Tapis**: When using Tapis to transfer files, you must specify **URI-style paths** (e.g., tacc.work2://...).\n",
    "      * This method does not work from within DesignSafe's JupyterHub because there is not SSH protocol there. here is the error:<br>\n",
    "        ```ForbiddenError: message: FILES_CLIENT_SSH_PERM_DENIED OboTenant: designsafe OboUser: silvia Operation: mkdir System: cloud.data EffectiveUser: silvia Host: cloud.data.tacc.utexas.edu Path: /work2 Error: SFTP error (SSH_FX_PERMISSION_DENIED): Permission denied```\n",
    "    * **Using Python/Shell**: When using Python or shell commands, you instead provide **local filesystem paths** (e.g., ../Work/...).\n",
    "      * The method is fast and reliable because Work is mounted on JupyterHub in DesignSafe.\n",
    "\n",
    "The process described below defines arguments for **both** methods (appPath_Tapis and appPath_Tapis_local) so you can choose whether to perform uploads via Tapis or directly through Python, depending on what is most convenient for your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileUpload_method = 'Python'; # options: 'Python' or 'Tapis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the App Directory\n",
    "The apps in this folder are the ones that area actually uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileUpload_method Python\n",
      "appPath_Tapis_local /home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11\n",
      "\n",
      "Created: appPath_Tapis /work2/05072/silvia/stampede3/apps/designsafe-agnostic-app/1.3.11\n"
     ]
    }
   ],
   "source": [
    "if do_makeApp:\n",
    "    print('FileUpload_method',FileUpload_method)\n",
    "    if FileUpload_method == 'Tapis':\n",
    "        print('app_system_id',app_system_id)\n",
    "        print('appPath_Tapis',appPath_Tapis)\n",
    "        t.files.mkdir(systemId=app_system_id, path=appPath_Tapis)\n",
    "        print('\\nCreated appPath_Tapis',appPath_Tapis)\n",
    "    else:\n",
    "        print('appPath_Tapis_local',appPath_Tapis_local)\n",
    "        os.makedirs(appPath_Tapis_local, exist_ok=True)\n",
    "        print('\\nCreated: appPath_Tapis',appPath_Tapis)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileUpload_method Python\n",
      "appPath_Tapis_local_OpsPy /home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15\n",
      "\n",
      "Created: appPath_Tapis_local_OpsPy /home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15\n"
     ]
    }
   ],
   "source": [
    "if do_makeApp_OpsPy:\n",
    "    print('FileUpload_method',FileUpload_method)\n",
    "    if FileUpload_method == 'Tapis':\n",
    "        print('app_system_id_OpsPy',app_system_id_OpsPy)\n",
    "        print('appPath_Tapis_OpsPy',appPath_Tapis_OpsPy)\n",
    "        t.files.mkdir(systemId=app_system_id_OpsPy, path=appPath_Tapis_OpsPy)\n",
    "        print('\\nCreated: appPath_Tapis_OpsPy',appPath_Tapis_OpsPy)\n",
    "    else:\n",
    "        print('appPath_Tapis_local_OpsPy',appPath_Tapis_local_OpsPy)\n",
    "        os.makedirs(appPath_Tapis_local_OpsPy, exist_ok=True)\n",
    "        print('\\nCreated: appPath_Tapis_local_OpsPy',appPath_Tapis_local_OpsPy)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload/Copy Files to Deployment System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OS-copied /home/jupyter/MyData/myAuthoredTapisApps/designsafe-agnostic-app/1.3.11/ReadMe.MD to /home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11\n",
      "\n",
      "OS-copied /home/jupyter/MyData/myAuthoredTapisApps/designsafe-agnostic-app/1.3.11/app.json to /home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11\n",
      "\n",
      "OS-copied /home/jupyter/MyData/myAuthoredTapisApps/designsafe-agnostic-app/1.3.11/tapisjob_app.sh to /home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11\n",
      "\n",
      "OS-copied /home/jupyter/MyData/myAuthoredTapisApps/designsafe-agnostic-app/1.3.11/designsafe-agnostic-app.zip to /home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11\n"
     ]
    }
   ],
   "source": [
    "if do_makeApp:\n",
    "    appfiles = os.listdir(appPath_Local)\n",
    "    if len(appfiles)==0:\n",
    "        print('ERROR!!!!! THERE ARE NO FILES!!!')\n",
    "    for fname in appfiles:\n",
    "        fpath = f'{appPath_Local}/{fname}'\n",
    "        if FileUpload_method == 'Tapis':\n",
    "            dest_file_path=f'{appPath_Tapis}/{fname}'\n",
    "            t.upload(source_file_path=fpath,\n",
    "                     system_id=app_system_id,\n",
    "                     dest_file_path=dest_file_path)\n",
    "            print(f'\\nTapis-uploaded {fpath} to {dest_file_path} on {app_system_id}')\n",
    "        else:\n",
    "            shutil.copy(fpath, appPath_Tapis_local)\n",
    "            print(f'\\nOS-copied {fpath} to {appPath_Tapis_local}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OS-copied /home/jupyter/MyData/myAuthoredTapisApps/designsafe-openseespy-s3/1.2.15/ReadMe.MD to /home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15\n",
      "\n",
      "OS-copied /home/jupyter/MyData/myAuthoredTapisApps/designsafe-openseespy-s3/1.2.15/app.json to /home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15\n",
      "\n",
      "OS-copied /home/jupyter/MyData/myAuthoredTapisApps/designsafe-openseespy-s3/1.2.15/tapisjob_app.sh to /home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15\n",
      "\n",
      "OS-copied /home/jupyter/MyData/myAuthoredTapisApps/designsafe-openseespy-s3/1.2.15/designsafe-openseespy-s3.zip to /home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15\n"
     ]
    }
   ],
   "source": [
    "if do_makeApp_OpsPy:\n",
    "    appfiles_OpsPy = os.listdir(appPath_Local_OpsPy)\n",
    "    if len(appfiles_OpsPy)==0:\n",
    "        print('ERROR!!!!! THERE ARE NO FILES!!!')\n",
    "    for fname in appfiles_OpsPy:\n",
    "        fpath = f'{appPath_Local_OpsPy}/{fname}'\n",
    "        if FileUpload_method == 'Tapis':\n",
    "            dest_file_path=f'{appPath_Tapis_OpsPy}/{fname}'\n",
    "            t.upload(source_file_path=fpath,\n",
    "                     system_id=app_system_id_OpsPy,\n",
    "                     dest_file_path=f'{appPath_Tapis_OpsPy}/{fname}')\n",
    "            print(f'\\nTapis-uploaded {fpath} to {dest_file_path} on {app_system_id}')\n",
    "        else:\n",
    "            shutil.copy(fpath, appPath_Tapis_local_OpsPy)\n",
    "            print(f'\\nOS-copied {fpath} to {appPath_Tapis_local_OpsPy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Files on Deployment System To Verify Upload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d97bb0a35454e6884d264df33b1017d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Output(),), selected_index=0, titles=('Verify Upload -- app-id=designsafe-agnostic-app',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "if do_makeApp:\n",
    "    here_out = widgets.Output()\n",
    "    here_accordion = widgets.Accordion(children=[here_out])\n",
    "    here_accordion.selected_index = 0\n",
    "    here_accordion.set_title(0, f'Verify Upload -- app-id={app_id}')\n",
    "    display(here_accordion)\n",
    "    \n",
    "    with here_out:\n",
    "        print('app_system_id:',app_system_id)\n",
    "        print('appPath_Tapis:',appPath_Tapis)\n",
    "        print('')\n",
    "        print('appPath_Tapis_local:',appPath_Tapis_local)\n",
    "        if FileUpload_method == 'Tapis':\n",
    "            appfiles = t.files.listFiles(systemId=app_system_id, path=appPath_Tapis)\n",
    "            for thisF in appfiles:\n",
    "                print(thisF)\n",
    "                print('')            \n",
    "        else:\n",
    "            appfiles = os.listdir(appPath_Tapis_local)\n",
    "            OpsUtils.show_text_file_in_accordion(appPath_Tapis_local, appfiles, background='cream', showLineNumbers=False)\n",
    "        if len(appfiles)==0:\n",
    "            here_accordion.set_title(0,'ERROR!!!!!! THERE ARE NO FILES!!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06051c3e77eb44c59f49bbf8fb2ef872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Output(),), selected_index=0, titles=('Verify Upload -- app-id=designsafe-openseespy-s3',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if do_makeApp_OpsPy:\n",
    "    here_out = widgets.Output()\n",
    "    here_accordion = widgets.Accordion(children=[here_out])\n",
    "    here_accordion.selected_index = 0\n",
    "    here_accordion.set_title(0, f'Verify Upload -- app-id={app_id_OpsPy}')\n",
    "    display(here_accordion)\n",
    "    \n",
    "    with here_out:\n",
    "        print('app_system_id:',app_system_id_OpsPy)\n",
    "        print('appPath_Tapis:',appPath_Tapis_OpsPy)\n",
    "        print('')\n",
    "        print('appPath_Tapis_local:',appPath_Tapis_local_OpsPy)\n",
    "        if FileUpload_method == 'Tapis':\n",
    "            appfiles_OpsPy = t.files.listFiles(systemId=app_system_id_OpsPy, path=appPath_Tapis_OpsPy)\n",
    "            for thisF in appfile_OpsPys:\n",
    "                print(thisF)\n",
    "                print('')            \n",
    "        else:\n",
    "            appfiles_OpsPy = os.listdir(appPath_Tapis_local_OpsPy)\n",
    "            OpsUtils.show_text_file_in_accordion(appPath_Tapis_local_OpsPy, appfiles_OpsPy, background='cream', showLineNumbers=False)\n",
    "        if len(appfiles_OpsPy)==0:\n",
    "            here_accordion.set_title(0,'ERROR!!!!!! THERE ARE NO FILES!!!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Register The App\n",
    "This creates the actual App record that Jobs can run.\n",
    "\n",
    "This is when we send the json content to Tapis, where it it \"memorizes\" it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_makeApp:\n",
    "    # Create (or create a new version) of the app\n",
    "    with open(f'{appPath_Local}/app.json') as f:\n",
    "        app_def = json.load(f)\n",
    "    t.apps.createAppVersion(**app_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_makeApp_OpsPy:\n",
    "    # Create (or create a new version) of the app\n",
    "    with open(f'{appPath_Local_OpsPy}/app.json') as f:\n",
    "        app_def = json.load(f)\n",
    "    t.apps.createAppVersion(**app_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List All Tapis Apps to Verify Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efe2c5d59f343ab9e3c105492024111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Output(),), titles=('List all apps',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "here_out = widgets.Output()\n",
    "here_accordion = widgets.Accordion(children=[here_out])\n",
    "# here_accordion.selected_index = 0\n",
    "here_accordion.set_title(0, f'List all apps')\n",
    "display(here_accordion)\n",
    "\n",
    "with here_out:\n",
    "    listType = 'ALL' # Include all items requester is authorized to view. Includes check for READ or MODIFY permission.\n",
    "    select = 'id,created,description,version,owner' # Attributes to return in each result.\n",
    "    orderBy = 'created(asc)'\n",
    "    results = t.apps.getApps( orderBy=orderBy,\n",
    "                             select=select)  \n",
    "    for thisRes in results:\n",
    "        print('--')\n",
    "        print(thisRes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access App Schema on Tapis to Validate Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36e1538435a458884d60b8897f88d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OpsUtils.show_text_file_in_accordion(PathOpsUtils, ['getAppLatestVersion.py','display_tapis_app_schema.py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c539ca1fe90249fcaa348d4cde76c96e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Output(),), titles=('List the new app',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "appMetaData = t.apps.getAppLatestVersion(appId=app_id)\n",
    "\n",
    "here_out = widgets.Output()\n",
    "here_accordion = widgets.Accordion(children=[here_out])\n",
    "# here_accordion.selected_index = 0\n",
    "here_accordion.set_title(0, f'List the new app')\n",
    "display(here_accordion)\n",
    "\n",
    "with here_out:\n",
    "    OpsUtils.display_tapis_app_schema(appMetaData)\n",
    "thisAppVersion = appMetaData.version\n",
    "isPublic = appMetaData.isPublic\n",
    "here_accordion.set_title(0, f'app schema: {app_id}  -- version = {thisAppVersion}    --  isPublic = {isPublic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75d3292ad9e43a0b3b1b77704ee1d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Output(),), titles=('List the new app',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "appMetaData_OpsPy = t.apps.getAppLatestVersion(appId=app_id_OpsPy)\n",
    "\n",
    "here_out = widgets.Output()\n",
    "here_accordion = widgets.Accordion(children=[here_out])\n",
    "# here_accordion.selected_index = 0\n",
    "here_accordion.set_title(0, f'List the new app')\n",
    "display(here_accordion)\n",
    "\n",
    "with here_out:\n",
    "    OpsUtils.display_tapis_app_schema(appMetaData_OpsPy)\n",
    "thisAppVersion_OpsPy = appMetaData_OpsPy.version\n",
    "isPublic_OpsPy = appMetaData_OpsPy.isPublic\n",
    "here_accordion.set_title(0, f'app schema: {app_id_OpsPy}  -- version = {thisAppVersion_OpsPy}    --  isPublic = {isPublic_OpsPy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Manage Public App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage App *isPublic* Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make The App Public (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "makePublic\n"
     ]
    }
   ],
   "source": [
    "if makePublic:\n",
    "    print('makePublic')\n",
    "    t.apps.shareAppPublic(appId=app_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "makePublic_OpsPy\n"
     ]
    }
   ],
   "source": [
    "if makePublic_OpsPy:\n",
    "    print('makePublic_OpsPy')\n",
    "    t.apps.shareAppPublic(appId=app_id_OpsPy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### or Remove The App From Public Access (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "if makeUnPublic:\n",
    "    print('makeUnPublic')\n",
    "    t.apps.unShareAppPublic(appId=app_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "if makeUnPublic_OpsPy:\n",
    "    print('makeUnPublic_OpsPy')\n",
    "    t.apps.unShareAppPublic(appId=app_id_OpsPy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify isPublic Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c9a72037a149b5a8549803d673873d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Output(),), titles=('List the new app',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "appMetaData = t.apps.getAppLatestVersion(appId=app_id)\n",
    "\n",
    "here_out = widgets.Output()\n",
    "here_accordion = widgets.Accordion(children=[here_out])\n",
    "# here_accordion.selected_index = 0\n",
    "here_accordion.set_title(0, f'List the new app')\n",
    "display(here_accordion)\n",
    "\n",
    "with here_out:\n",
    "    OpsUtils.display_tapis_app_schema(appMetaData)\n",
    "thisAppVersion = appMetaData.version\n",
    "isPublic = appMetaData.isPublic\n",
    "here_accordion.set_title(0, f'app schema: {app_id}  -- version = {thisAppVersion}    --  isPublic = {isPublic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f023beb8aceb42fea41919c06b563a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Output(),), titles=('List the new app',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "appMetaData_OpsPy = t.apps.getAppLatestVersion(appId=app_id_OpsPy)\n",
    "\n",
    "here_out = widgets.Output()\n",
    "here_accordion = widgets.Accordion(children=[here_out])\n",
    "# here_accordion.selected_index = 0\n",
    "here_accordion.set_title(0, f'List the new app')\n",
    "display(here_accordion)\n",
    "\n",
    "with here_out:\n",
    "    OpsUtils.display_tapis_app_schema(appMetaData_OpsPy)\n",
    "thisAppVersion_OpsPy = appMetaData_OpsPy.version\n",
    "isPublic_OpsPy = appMetaData_OpsPy.isPublic\n",
    "here_accordion.set_title(0, f'app schema: {app_id_OpsPy}  -- version = {thisAppVersion_OpsPy}    --  isPublic = {isPublic_OpsPy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Set Permissions for Public App \n",
    "If you want to make your app public, **You must make files readable and the folders executable** so that the app can copy the app-definition file (.zip) to the user's execution directory.\n",
    "\n",
    "To allow anyone to copy a file from your folder, you must ensure:\n",
    "1. The file is readable (**+r**) by your group (**g**) and others (**o**):\n",
    "\n",
    "    * bash:\n",
    "        ```bash\n",
    "        chmod go+r yourfile.zip\n",
    "        ```\n",
    "        \n",
    "    * python:\n",
    "        ```python\n",
    "        file_perms = stat.S_IRGRP | stat.S_IROTH\n",
    "        ```\n",
    "  \n",
    "2. Every directory in the path is executable (traversable) (**+x**) by your group (**g**) and others (**o**):\n",
    "\n",
    "    * bash:\n",
    "        ```bash\n",
    "        chmod go+x /workId/groupID/username\n",
    "        chmod go+x /workId/groupID/username/system\n",
    "        chmod go+x /workId/groupID/username/system/apps\n",
    "        chmod go+x /workId/groupID/username/system/apps/app_name\n",
    "        chmod go+x /workId/groupID/username/system/apps/app_name/app_version\n",
    "        ```\n",
    "    \n",
    "    * python:\n",
    "        ```python\n",
    "        dir_perms = stat.S_IXGRP |  stat.S_IXOTH\n",
    "        ```\n",
    "\n",
    "\n",
    "**NOTE: On Stampede3 /work2 is group-write by default, but NOT others-readable.**\n",
    "    \n",
    "In Python, Permissions are changed with st.st_mode | perms, so:\n",
    "- Your existing user perms are preserved.\n",
    "- Any existing group/other bits are preserved; we’re only adding what's missing.\n",
    "- You will assign permissions once the process of creating folders and copying app files is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_perms(path: Path, perms: int):\n",
    "    \"\"\"OR in the given permission bits without removing existing ones.\"\"\"\n",
    "    st = os.stat(path)\n",
    "    old_mode = st.st_mode & 0o777\n",
    "    new_mode = old_mode | perms\n",
    "    print(f\"try: {path} : {oct(old_mode)} -> {oct(new_mode)}\")\n",
    "    os.chmod(path, new_mode)\n",
    "    print(f\"{path} : {oct(old_mode)} -> {oct(new_mode)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Permissions\n",
    "*For the files*: **group&others** get **read** (can copy)\n",
    "\n",
    "We want to make all the files accesible to the group+others: Tapis will want the .zip file. Users will want the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_perms = stat.S_IRGRP | stat.S_IROTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try: /home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11/ReadMe.MD : 0o660 -> 0o664\n",
      "/home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11/ReadMe.MD : 0o660 -> 0o664\n",
      "try: /home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11/designsafe-agnostic-app.zip : 0o660 -> 0o664\n",
      "/home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11/designsafe-agnostic-app.zip : 0o660 -> 0o664\n",
      "try: /home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11/tapisjob_app.sh : 0o660 -> 0o664\n",
      "/home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11/tapisjob_app.sh : 0o660 -> 0o664\n",
      "try: /home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11/app.json : 0o660 -> 0o664\n",
      "/home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11/app.json : 0o660 -> 0o664\n",
      "try: /home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15/ReadMe.MD : 0o660 -> 0o664\n",
      "/home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15/ReadMe.MD : 0o660 -> 0o664\n",
      "try: /home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15/tapisjob_app.sh : 0o660 -> 0o664\n",
      "/home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15/tapisjob_app.sh : 0o660 -> 0o664\n",
      "try: /home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15/app.json : 0o660 -> 0o664\n",
      "/home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15/app.json : 0o660 -> 0o664\n",
      "try: /home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15/designsafe-openseespy-s3.zip : 0o660 -> 0o664\n",
      "/home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15/designsafe-openseespy-s3.zip : 0o660 -> 0o664\n"
     ]
    }
   ],
   "source": [
    "if makePublic:\n",
    "    if do_makeApp:\n",
    "        appfiles = os.listdir(appPath_Tapis_local)\n",
    "        for fname in appfiles:\n",
    "            file_path = os.path.join(appPath_Tapis_local, fname)\n",
    "            add_perms(file_path, file_perms)\n",
    "        if len(appfiles)==0:\n",
    "            print('ERROR!!!!! THERE ARE NO FILES!!!')\n",
    "    if do_makeApp_OpsPy:\n",
    "        appfiles_OpsPy = os.listdir(appPath_Tapis_local_OpsPy)\n",
    "        for fname in appfiles_OpsPy:\n",
    "            file_path_OpsPy = os.path.join(appPath_Tapis_local_OpsPy, fname)\n",
    "            add_perms(file_path_OpsPy, file_perms)\n",
    "        if len(appfiles_OpsPy)==0:\n",
    "            print('ERROR!!!!! THERE ARE NO FILES!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path/Directory Permissions\n",
    "*For directories*: **group&others** get **execute** (can traverse but not list contents)\n",
    "\n",
    "We need to set these permission for every level of the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_perms = stat.S_IXGRP |  stat.S_IXOTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a python function that builds directories.\n",
    "def dirs_between(anchor: Path, descendant: Path):\n",
    "    \"\"\"\n",
    "    Yield directories from anchor down to descendant (inclusive),\n",
    "    assuming descendant is inside anchor.\n",
    "    \"\"\"\n",
    "    anchor = anchor.resolve()\n",
    "    descendant = descendant.resolve()\n",
    "\n",
    "    # safety check: make sure descendant is under anchor\n",
    "    try:\n",
    "        descendant.relative_to(anchor)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"{descendant} is not inside {anchor}\")\n",
    "\n",
    "    dirs = []\n",
    "    current = descendant\n",
    "    while True:\n",
    "        dirs.append(current)\n",
    "        if current == anchor:\n",
    "            break\n",
    "        current = current.parent\n",
    "\n",
    "    return list(reversed(dirs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_dir /home/jupyter/Work/stampede3\n",
      "end_dir /home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11\n",
      "try: /home/jupyter/Work/stampede3 : 0o711 -> 0o711\n",
      "/home/jupyter/Work/stampede3 : 0o711 -> 0o711\n",
      "try: /home/jupyter/Work/stampede3/apps : 0o711 -> 0o711\n",
      "/home/jupyter/Work/stampede3/apps : 0o711 -> 0o711\n",
      "try: /home/jupyter/Work/stampede3/apps/designsafe-agnostic-app : 0o711 -> 0o711\n",
      "/home/jupyter/Work/stampede3/apps/designsafe-agnostic-app : 0o711 -> 0o711\n",
      "try: /home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11 : 0o755 -> 0o755\n",
      "/home/jupyter/Work/stampede3/apps/designsafe-agnostic-app/1.3.11 : 0o755 -> 0o755\n"
     ]
    }
   ],
   "source": [
    "if makePublic:\n",
    "    if do_makeApp:\n",
    "        start_dir = Path(appPath_Tapis_local_anchor)  # don't go above this\n",
    "        end_dir = Path(os.path.abspath(os.path.expanduser(appPath_Tapis_local)))\n",
    "        print('start_dir',start_dir)\n",
    "        print('end_dir',end_dir)\n",
    "        permission_dirs = dirs_between(start_dir,end_dir)\n",
    "        # permission_dirs = dirs_below(end_dir)\n",
    "        \n",
    "        # set permissions\n",
    "        for thisDir in permission_dirs:\n",
    "            add_perms(thisDir, dir_perms)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_dir_OpsPy /home/jupyter/Work/stampede3\n",
      "end_dir_OpsPy /home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15\n",
      "try: /home/jupyter/Work/stampede3 : 0o711 -> 0o711\n",
      "/home/jupyter/Work/stampede3 : 0o711 -> 0o711\n",
      "try: /home/jupyter/Work/stampede3/apps : 0o711 -> 0o711\n",
      "/home/jupyter/Work/stampede3/apps : 0o711 -> 0o711\n",
      "try: /home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3 : 0o711 -> 0o711\n",
      "/home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3 : 0o711 -> 0o711\n",
      "try: /home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15 : 0o755 -> 0o755\n",
      "/home/jupyter/Work/stampede3/apps/designsafe-openseespy-s3/1.2.15 : 0o755 -> 0o755\n"
     ]
    }
   ],
   "source": [
    "if makePublic_OpsPy:\n",
    "    if do_makeApp_OpsPy:\n",
    "        start_dir_OpsPy = Path(os.path.abspath(os.path.expanduser(user_WorkPath_base_local)))  # don't go above this\n",
    "        end_dir_OpsPy = Path(os.path.abspath(os.path.expanduser(appPath_Tapis_local_OpsPy)))\n",
    "        print('start_dir_OpsPy',start_dir_OpsPy)\n",
    "        print('end_dir_OpsPy',end_dir_OpsPy)\n",
    "        permission_dirs_OpsPy = dirs_between(start_dir_OpsPy,end_dir_OpsPy)\n",
    "        \n",
    "        # set permissions\n",
    "        for thisDir_OpsPy in permission_dirs_OpsPy:\n",
    "            add_perms(thisDir_OpsPy, dir_perms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "print('Done!!!')"
   ]
  }
 ],
 "metadata": {
  "IMAGE_NAME": "taccsciapps/ds-nb-img:base-0.2.3",
  "UUID": "73e0880d-9b87-11ec-9c1c-13579dd95994",
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
