{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"reference external\" href=\"https://jupyter.designsafe-ci.org/hub/user-redirect/lab/tree/CommunityData/Training/Computational-Workflows-on-DesignSafe/Jupyter_Notebooks/Jupyter_Notebooks_TapisApps/tapis_discoverApp_Designsafe_Agnostic_App.ipynb\" target=\"_blank\">\n",
    "<img alt=\"Try on DesignSafe\" src=\"https://raw.githubusercontent.com/DesignSafe-Training/pinn/main/DesignSafe-Badge.svg\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# designsafe-agnostic-app\n",
    "***Dig Deep into an App Schema to Create the Input***\n",
    "\n",
    "by Silvia Mazzoni, DesignSafe, 2025\n",
    "\n",
    "We are going to walk through the app schema to develop our job input, and then we will submit the job.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Import Utilities Library\n",
    "import os,sys\n",
    "PathOpsUtils = os.path.expanduser('~/CommunityData/Training/Computational-Workflows-on-DesignSafe/OpsUtils')\n",
    "if not PathOpsUtils in sys.path: sys.path.append(PathOpsUtils)\n",
    "from OpsUtils import OpsUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tapipy.tapis import TapisResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitJob = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Tapis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Checking Tapis token --\n",
      " Token loaded from file. Token is still valid!\n",
      " Token expires at: 2026-02-05T18:54:18+00:00\n",
      " Token expires in: 1:51:46.626350\n",
      "-- AUTHENTICATED VIA SAVED TOKEN --\n"
     ]
    }
   ],
   "source": [
    "t=OpsUtils.connect_tapis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DesignSafe Agnostic App\n",
    "# submit via web form: https://www.designsafe-ci.org/workspace/designsafe-agnostic-app\n",
    "\n",
    "appId = 'designsafe-agnostic-app'\n",
    "appVersion = 'latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Get app.json schema -- input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisAppData_MP = OpsUtils.get_tapis_app_schema(t,appId,version=appVersion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "########### TAPIS-APP SCHEMA ###########\n",
      "########################################\n",
      "######## appID: designsafe-agnostic-app\n",
      "######## version: 1.2.0\n",
      "########################################\n",
      "{\n",
      "  sharedAppCtx: \"silvia\"\n",
      "  isPublic: True\n",
      "  tenant: \"designsafe\"\n",
      "  id: \"designsafe-agnostic-app\"\n",
      "  version: \"1.2.0\"\n",
      "  description: \"Agnostic Tapis App for General Python Execution as well as OpenSees, OpenSeesMP, OpenSeesSP, OpenSeesPy\"\n",
      "  owner: \"silvia\"\n",
      "  enabled: True\n",
      "  versionEnabled: True\n",
      "  locked: False\n",
      "  runtime: \"ZIP\"\n",
      "  runtimeVersion: None\n",
      "  runtimeOptions: None\n",
      "  containerImage: \"//work2/05072/silvia/stampede3/apps/designsafe-agnostic-app/1.2.0/designsafe-agnostic-app.zip\"\n",
      "  jobType: \"BATCH\"\n",
      "  maxJobs: 2147483647\n",
      "  maxJobsPerUser: 2147483647\n",
      "  strictFileInputs: False\n",
      "  uuid: \"e3854c4d-470b-46d3-b9b6-eec487f8f23e\"\n",
      "  deleted: False\n",
      "  created: \"2026-02-05T16:13:21.989088Z\"\n",
      "  updated: \"2026-02-05T16:13:21.989088Z\"\n",
      "  sharedWithUsers: []\n",
      "  tags: [\"portalName: DesignSafe\", \"portalName: CEP\"]\n",
      "  jobAttributes: {\n",
      "    description: None\n",
      "    dynamicExecSystem: False\n",
      "    execSystemConstraints: None\n",
      "    execSystemId: \"stampede3\"\n",
      "    execSystemExecDir: \"${JobWorkingDir}\"\n",
      "    execSystemInputDir: \"${JobWorkingDir}\"\n",
      "    execSystemOutputDir: \"${JobWorkingDir}\"\n",
      "    dtnSystemInputDir: \"!tapis_not_set\"\n",
      "    dtnSystemOutputDir: \"!tapis_not_set\"\n",
      "    execSystemLogicalQueue: \"skx-dev\"\n",
      "    archiveSystemId: \"designsafe.storage.default\"\n",
      "    archiveSystemDir: \"silvia/tapis-jobs-archive/${JobCreateDate}/${JobName}-${JobUUID}\"\n",
      "    archiveOnAppError: True\n",
      "    archiveMode: None\n",
      "    isMpi: False\n",
      "    mpiCmd: None\n",
      "    cmdPrefix: None\n",
      "    nodeCount: 1\n",
      "    coresPerNode: 48\n",
      "    memoryMB: 192000\n",
      "    maxMinutes: 120\n",
      "    fileInputs: [\n",
      "      {\n",
      "        name: \"Input Directory\"\n",
      "        description: \"Directory containing the main script and any supporting files (models, data, etc.). (Example: tapis://designsafe.storage.community/app_examples/opensees/OpenSeesPy)\"\n",
      "        inputMode: \"REQUIRED\"\n",
      "        autoMountLocal: True\n",
      "        envKey: \"inputDirectory\"\n",
      "        sourceUrl: None\n",
      "        targetPath: \"inputDirectory\"\n",
      "        notes: {\n",
      "          isHidden: False\n",
      "          selectionMode: \"directory\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "    fileInputArrays: []\n",
      "    subscriptions: []\n",
      "    tags: []\n",
      "    parameterSet: {\n",
      "      appArgs: [\n",
      "        {\n",
      "          arg: \"python3\"\n",
      "          name: \"Main Program\"\n",
      "          description: \"Binary executable to run. (e.g., OpenSees, OpenSeesMP, OpenSeesSP, python3 -- OpenSeesPy: use python3).    The executable must be available in the job's execution system. Some executables require you to load specific modules.\"\n",
      "          inputMode: \"REQUIRED\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "            enum_values: [\n",
      "              {\n",
      "                OpenSees: \"OpenSees\"\n",
      "              }\n",
      "              {\n",
      "                OpenSeesMP: \"OpenSeesMP\"\n",
      "              }\n",
      "              {\n",
      "                OpenSeesSP: \"OpenSeesSP\"\n",
      "              }\n",
      "              {\n",
      "                python3: \"Python\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "        {\n",
      "          arg: None\n",
      "          name: \"Main Script\"\n",
      "          description: \"Filename (no path) of the input script passed to the executable (Example: Ex1a.Canti2D.Push.mpi4py.tacc.py). This file must reside in the Input Directory.  Note: This App uses TACC-Compiled OpenSeesPy: use 'import opensees' or 'import opensees as ops' in your script.\"\n",
      "          inputMode: \"REQUIRED\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "            inputType: \"fileInput\"\n",
      "          }\n",
      "        }\n",
      "        {\n",
      "          arg: \"True\"\n",
      "          name: \"UseMPI\"\n",
      "          description: \"Flag indicating whether the application should launch the main program with an MPI parallel-execution command (ibrun). **True**: enable distributed-memory parallelism, allowing multi-core or multi-node execution. (Suitable for OpenSeesMP / OpenSeesSP / Python with mpi4py (OpenSeesPy)). **False**: execution stays on one node. (Suitable for OpenSees, Python, or Python with concurrent.futures for one-node parallelism.)\"\n",
      "          inputMode: \"REQUIRED\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "            enum_values: [\n",
      "              {\n",
      "                True: \"True — Enable MPI mode -- Use multi-node or multi-core parallelism.\"\n",
      "              }\n",
      "              {\n",
      "                False: \"False — No MPI -- Use single-node process.\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "        {\n",
      "          arg: None\n",
      "          name: \"CommandLine Arguments\"\n",
      "          description: \"Optional command-line arguments appended after Main Script (e.g., '--npts 2000 --dir X' or any format consistent with how your input script parses them).\"\n",
      "          inputMode: \"INCLUDE_ON_DEMAND\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "      containerArgs: []\n",
      "      schedulerOptions: [\n",
      "        {\n",
      "          arg: \"--tapis-profile tacc-no-modules\"\n",
      "          name: \"TACC Scheduler Profile\"\n",
      "          description: \"Scheduler profile (e.g., tacc-no-modules) -- the app loads the modules you specify.\"\n",
      "          inputMode: \"INCLUDE_BY_DEFAULT\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "          }\n",
      "        }\n",
      "        {\n",
      "          arg: None\n",
      "          name: \"TACC Reservation\"\n",
      "          description: \"If you have a TACC reservation, enter the reservation string here.\"\n",
      "          inputMode: \"INCLUDE_ON_DEMAND\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "      envVariables: [\n",
      "        {\n",
      "          key: \"GET_TACC_OPENSEESPY\"\n",
      "          value: \"True\"\n",
      "          description: \"If 'True', use the TACC-compiled OpenSeesPy (not the PyPI wheel). In your script, import OpenSeesPy using 'import opensees' or 'import opensees as ops'.\"\n",
      "          inputMode: \"INCLUDE_BY_DEFAULT\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "            enum_values: [\n",
      "              {\n",
      "                True: \"True: Copy TACC-Compiled OpenSeesPy\"\n",
      "              }\n",
      "              {\n",
      "                False: \"False: no TACC-Compiled OpenSeesPy\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "        {\n",
      "          key: \"PIP_INSTALLS_LIST\"\n",
      "          value: \"mpi4py,pandas,numpy,matplotlib,futures\"\n",
      "          description: \"Comma-separated list of Python packages to pip install before the run. Example: 'numpy,scipy,mpi4py' Defaults:'mpi4py,pandas,numpy,scipy'.\"\n",
      "          inputMode: \"INCLUDE_BY_DEFAULT\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "          }\n",
      "        }\n",
      "        {\n",
      "          key: \"MODULE_LOADS_LIST\"\n",
      "          value: \"python/3.12.11,opensees,hdf5/1.14.4,pylauncher\"\n",
      "          description: \"Comma-separated list of TACC modules to load before the run. Defaults: 'opensees,hdf5/1.14.4' 'python/3.12.11' and 'pylauncher' are included if  GET_TACC_OPENSEESPY=True.\"\n",
      "          inputMode: \"INCLUDE_BY_DEFAULT\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "          }\n",
      "        }\n",
      "        {\n",
      "          key: \"UNZIP_FILES_LIST\"\n",
      "          value: \"\"\n",
      "          description: \"Comma-separated list of ZIP files in the Input Directory to unzip before the run. Example: 'inputs.zip,gm_files.zip'.\"\n",
      "          inputMode: \"INCLUDE_ON_DEMAND\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "          }\n",
      "        }\n",
      "        {\n",
      "          key: \"PATH_COPY_IN_LIST\"\n",
      "          value: \"\"\n",
      "          description: \"Absolute Path (within the Execution System) of folder that will be copied into the job working directory **before** execution.  (Example: '$HOME/FileSet1,$WORK/FileSet2,$SCRATCH/FileSet3/thisFile.at2')\"\n",
      "          inputMode: \"INCLUDE_ON_DEMAND\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "          }\n",
      "        }\n",
      "        {\n",
      "          key: \"DELETE_COPIED_IN_ON_EXIT\"\n",
      "          value: \"0\"\n",
      "          description: \"If set to a true-like value, removes files or directories that were copied into the job working directory via PATH_COPY_IN_LIST after the job completes, preventing temporary inputs from being included in the final archive.\"\n",
      "          inputMode: \"INCLUDE_ON_DEMAND\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "          }\n",
      "        }\n",
      "        {\n",
      "          key: \"MODULE_LOADS_FILE\"\n",
      "          value: \"\"\n",
      "          description: \"Name of a file in the Input Directory containing a list of modules to load (newline- or comma-separated). Example: 'modules.txt'.\"\n",
      "          inputMode: \"INCLUDE_ON_DEMAND\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "          }\n",
      "        }\n",
      "        {\n",
      "          key: \"PIP_INSTALLS_FILE\"\n",
      "          value: \"\"\n",
      "          description: \"Name of a file in the Input Directory containing a list of Python packages to pip install (newline- or comma-separated). Example: 'requirements.txt'.\"\n",
      "          inputMode: \"INCLUDE_ON_DEMAND\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "          }\n",
      "        }\n",
      "        {\n",
      "          key: \"ZIP_OUTPUT_SWITCH\"\n",
      "          value: \"False\"\n",
      "          description: \"If 'True', zip the job output directory into a single archive before Tapis archiving. NOTE: the value must be defined as a string.\"\n",
      "          inputMode: \"INCLUDE_BY_DEFAULT\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "            enum_values: [\n",
      "              {\n",
      "                True: \"True: Zip All Output into a file\"\n",
      "              }\n",
      "              {\n",
      "                False: \"False: No Zipping\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "        {\n",
      "          key: \"PATH_MOVE_OUTPUT\"\n",
      "          value: \"\"\n",
      "          description: \"Destination path (Absolute and within the Execution System) where outputs will be moved **after** execution. (E.g., '$HOME/OutSet1', '$WORK/OutSet2', '$SCRATCH/OutSet3')\"\n",
      "          inputMode: \"INCLUDE_BY_DEFAULT\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "          }\n",
      "        }\n",
      "        {\n",
      "          key: \"PRE_JOB_SCRIPT\"\n",
      "          value: \"\"\n",
      "          description: \"Filename of user-defined PRE-JOB script (or absolute path). This file must reside in the Input Directory. It is run after the system has been configured, but before the main binary. (e.g. prehook.sh,$WORK/.../pre-hook.sh)\"\n",
      "          inputMode: \"INCLUDE_BY_DEFAULT\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "          }\n",
      "        }\n",
      "        {\n",
      "          key: \"POST_JOB_SCRIPT\"\n",
      "          value: \"\"\n",
      "          description: \"Filename of user-defined POST-JOB script (or absolute path). This file must reside in the Input Directory. It is run after the the main binary. (e.g. prehook.sh,$WORK/.../pre-hook.sh)\"\n",
      "          inputMode: \"INCLUDE_BY_DEFAULT\"\n",
      "          notes: {\n",
      "            isHidden: False\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "      archiveFilter: {\n",
      "        includeLaunchFiles: True\n",
      "        includes: []\n",
      "        excludes: [\"designsafe-agnostic-app.zip\"]\n",
      "      }\n",
      "      logConfig: {\n",
      "        stdoutFilename: \"\"\n",
      "        stderrFilename: \"\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  notes: {\n",
      "    icon: \"OpenSees\"\n",
      "    label: \"designsafe-agnostic-app\"\n",
      "    helpUrl: \"\"\n",
      "    category: \"Simulation\"\n",
      "    isInteractive: False\n",
      "    hideNodeCountAndCoresPerNode: False\n",
      "  }\n",
      "}\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "OpsUtils.display_tapis_app_schema(thisAppData_MP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break app schema into detailed parts and review them for possible input arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TapisResults Objects to dictionaries\n",
    "app_MetaData = thisAppData_MP.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** MAIN INPUT***\n",
      "sharedAppCtx = silvia\n",
      "isPublic = True\n",
      "tenant = designsafe\n",
      "id = designsafe-agnostic-app\n",
      "version = 1.2.0\n",
      "description = Agnostic Tapis App for General Python Execution as well as OpenSees, OpenSeesMP, OpenSeesSP, OpenSeesPy\n",
      "owner = silvia\n",
      "enabled = True\n",
      "versionEnabled = True\n",
      "locked = False\n",
      "runtime = ZIP\n",
      "runtimeVersion = None\n",
      "runtimeOptions = None\n",
      "containerImage = //work2/05072/silvia/stampede3/apps/designsafe-agnostic-app/1.2.0/designsafe-agnostic-app.zip\n",
      "jobType = BATCH\n",
      "maxJobs = 2147483647\n",
      "maxJobsPerUser = 2147483647\n",
      "strictFileInputs = False\n",
      "uuid = e3854c4d-470b-46d3-b9b6-eec487f8f23e\n",
      "deleted = False\n",
      "created = 2026-02-05T16:13:21.989088Z\n",
      "updated = 2026-02-05T16:13:21.989088Z\n",
      "*\n",
      "--- Nested Objects---\n",
      "dict-type input keys []\n",
      "list-type input keys ['sharedWithUsers', 'tags']\n",
      "TapisResult-type input keys ['jobAttributes', 'notes']\n"
     ]
    }
   ],
   "source": [
    "# Review the keys to see if there is any input we are interested in. \n",
    "# You can view the full schema above to see the values\n",
    "# print('app_MetaData.keys',app_MetaData.keys())\n",
    "dictKeys = []\n",
    "TapisResultKeys = []\n",
    "listKeys = []\n",
    "print('*** MAIN INPUT***')\n",
    "for thisKey,thisValue in app_MetaData.items():\n",
    "    if isinstance(thisValue, dict):\n",
    "        dictKeys.append(thisKey)\n",
    "    if isinstance(thisValue, TapisResult):\n",
    "        TapisResultKeys.append(thisKey)\n",
    "    elif isinstance(thisValue, list):\n",
    "        listKeys.append(thisKey)\n",
    "    else:\n",
    "        print(f'{thisKey} = {thisValue}')\n",
    "        \n",
    "print('*\\n--- Nested Objects---')\n",
    "print('dict-type input keys',dictKeys)\n",
    "print('list-type input keys',listKeys)\n",
    "print('TapisResult-type input keys',TapisResultKeys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Check App Basics\n",
    "A few things to check here:\n",
    "1. app name and version are what you want\n",
    "2. isPublic = True (you can use the app)\n",
    "3. if isPublic = False, make sure owner = usename\n",
    "4. enabled = True (app is usable)\n",
    "5. deleted = False (it exists)\n",
    "6. read the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: designsafe-agnostic-app\n",
      "version: 1.2.0\n",
      "description: Agnostic Tapis App for General Python Execution as well as OpenSees, OpenSeesMP, OpenSeesSP, OpenSeesPy\n",
      "isPublic: True\n",
      "enabled: True\n"
     ]
    }
   ],
   "source": [
    "for thisKey in ['id','version','description','isPublic','enabled']:\n",
    "    print(f'{thisKey}: {app_MetaData[thisKey]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the different types of arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **List**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** list-type INPUT ****\n",
      "sharedWithUsers : []\n",
      "tags : ['portalName: DesignSafe', 'portalName: CEP']\n"
     ]
    }
   ],
   "source": [
    "print(f'***** list-type INPUT ****')\n",
    "if len(listKeys)>0:\n",
    "    for thisKey in listKeys:\n",
    "        thisList = app_MetaData[thisKey]\n",
    "        print(f'{thisKey} : {thisList}')\n",
    "else: \n",
    "    print('-none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing related to input in the lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dictionaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** dict-type INPUT ****\n",
      "there are no dictionaries within jobAttributes, as expected, since Tapis works with TapisResults objects instead\n"
     ]
    }
   ],
   "source": [
    "print(f'***** dict-type INPUT ****')\n",
    "if len(dictKeys)>0:\n",
    "    for thisKey in dictKeys:\n",
    "        thisDict = app_MetaData[thisKey]\n",
    "        print(f'{thisKey} : {thisDict}')\n",
    "else: \n",
    "    print('there are no dictionaries within jobAttributes, as expected, since Tapis works with TapisResults objects instead')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TapisResult**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** TapisResult-type INPUT ****\n",
      "\n",
      "*** jobAttributes ***\n",
      "\n",
      "  --- Configuration Arguments ---\n",
      "  description = None\n",
      "  dynamicExecSystem = False\n",
      "  execSystemConstraints = None\n",
      "  execSystemId = stampede3\n",
      "  execSystemExecDir = ${JobWorkingDir}\n",
      "  execSystemInputDir = ${JobWorkingDir}\n",
      "  execSystemOutputDir = ${JobWorkingDir}\n",
      "  dtnSystemInputDir = !tapis_not_set\n",
      "  dtnSystemOutputDir = !tapis_not_set\n",
      "  execSystemLogicalQueue = skx-dev\n",
      "  archiveSystemId = designsafe.storage.default\n",
      "  archiveSystemDir = silvia/tapis-jobs-archive/${JobCreateDate}/${JobName}-${JobUUID}\n",
      "  archiveOnAppError = True\n",
      "  archiveMode = None\n",
      "  isMpi = False\n",
      "  mpiCmd = None\n",
      "  cmdPrefix = None\n",
      "  nodeCount = 1\n",
      "  coresPerNode = 48\n",
      "  memoryMB = 192000\n",
      "  maxMinutes = 120\n",
      "\n",
      "  --- jobAttributes -- Nested Objects---\n",
      "   dict-type input keys []\n",
      "   list-type input keys ['fileInputs', 'fileInputArrays', 'subscriptions', 'tags']\n",
      "   TapisResult-type input keys ['parameterSet']\n",
      "\n",
      "\n",
      "*** notes ***\n",
      "\n",
      "  --- Configuration Arguments ---\n",
      "  icon = OpenSees\n",
      "  label = designsafe-agnostic-app\n",
      "  helpUrl = \n",
      "  category = Simulation\n",
      "  isInteractive = False\n",
      "  hideNodeCountAndCoresPerNode = False\n",
      "\n",
      "  --- notes -- Nested Objects---\n",
      "   dict-type input keys []\n",
      "   list-type input keys []\n",
      "   TapisResult-type input keys []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'***** TapisResult-type INPUT ****')\n",
    "TR_dictKeys = {}\n",
    "TR_TapisResultKeys = {}\n",
    "TR_listKeys = {}\n",
    "for hereKey in TapisResultKeys:\n",
    "    print(f'\\n*** {hereKey} ***')\n",
    "    thisTapisResult = app_MetaData[hereKey]\n",
    "    thisTapisResult_dict = thisTapisResult.__dict__\n",
    "    TR_dictKeys[hereKey] = []\n",
    "    TR_TapisResultKeys[hereKey] = []\n",
    "    TR_listKeys[hereKey] = []\n",
    "    print(f'\\n  --- Configuration Arguments ---')\n",
    "    for thisKey,thisValue in thisTapisResult_dict.items():\n",
    "        if isinstance(thisValue, dict):\n",
    "            TR_dictKeys[hereKey].append(thisKey)\n",
    "        if isinstance(thisValue, TapisResult):\n",
    "            TR_TapisResultKeys[hereKey].append(thisKey)\n",
    "        elif isinstance(thisValue, list):\n",
    "            TR_listKeys[hereKey].append(thisKey)\n",
    "        else:\n",
    "            print(f'  {thisKey} = {thisValue}')\n",
    "    print(f'\\n  --- {hereKey} -- Nested Objects---')\n",
    "    print(f'   dict-type input keys',TR_dictKeys[hereKey])\n",
    "    print(f'   list-type input keys',TR_listKeys[hereKey])\n",
    "    print(f'   TapisResult-type input keys',TR_TapisResultKeys[hereKey])\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have **jobAttribues** and **notes**\n",
    "* **notes** this is informational content for the web portal\n",
    "* **jobAttributes** is the App-Specific Job input. Within this json object we have the following categories of job input:\n",
    "  * **configuration** -- these are the direct input, such as execSystemId -- where the job will be run, such as stampede3\n",
    "  * **fileInputs** -- this is a list object\n",
    "  * **fileInputArrays** -- this is a list object\n",
    "  * **subscriptions** -- this is a list object\n",
    "  * **parameterSet** -- this is a json object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notes {}\n",
    "notes is just informational."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## App User Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize\n",
    "TapisInput = {}\n",
    "TapisInput[\"name\"] = f'TestJob-${appId}' # not the job name, used just for bookkeeping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jobAttributes\n",
    "This is the content we will be submitting to the app.\n",
    "\n",
    "**jobAttributes** has valuable input arguments as well as nested ones.\n",
    "\n",
    "1. We need to initialize this json object in our TapisInput.\n",
    "2. Let's look at the high-level input\n",
    "3. Let's look at the nested content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialize TapisInput['jobAttributes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TapisInput['jobAttributes'] = {}\n",
    "# start this input with app id and version to jobAttributes since that is what we send to tapis\n",
    "TapisInput['jobAttributes'][\"name\"] = f'My first Tapis Job on {appId}'\n",
    "TapisInput['jobAttributes'][\"appId\"] = appId\n",
    "TapisInput['jobAttributes'][\"appVersion\"] = appVersion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Look at high-level variables to see if there is anything of value\n",
    "* This is where you find information about where the job is run (execSystemId)\n",
    "* In HPC applications this is where you define the SLURM input on queues and nodes, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TapisInput['jobAttributes']['execSystemId'] = \"stampede3\"; # we don't really need to specify this because stampede3 is already the default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slurmm-job input\n",
    "TapisInput['jobAttributes']['execSystemLogicalQueue'] = 'skx-dev'\n",
    "TapisInput['jobAttributes']['nodeCount'] = 1\n",
    "TapisInput['jobAttributes']['coresPerNode'] = 16\n",
    "TapisInput['jobAttributes']['maxMinutes'] = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Let's dig into the first level -- **app.jobAttributes** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's extract and study jobAttributes\n",
    "myKey = 'jobAttributes'\n",
    "app_jobAttributes = app_MetaData[myKey].__dict__\n",
    "# we have already extracted the contents of this dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****  jobAttributes dict-type Input ****\n",
      "there are no dictionaries within jobAttributes, as expected, since Tapis works with TapisResults objects instead\n"
     ]
    }
   ],
   "source": [
    "print(f'*****  {myKey} dict-type Input ****')\n",
    "if len(TR_dictKeys[myKey])>0:\n",
    "    for thisKey in TR_dictKeys[myKey]:\n",
    "        thisDict = app_jobAttributes[thisKey]\n",
    "        print(f'{myKey}.{thisKey} : {thisDict}')\n",
    "else:\n",
    "    print('there are no dictionaries within jobAttributes, as expected, since Tapis works with TapisResults objects instead')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****  jobAttributes list-type input****\n",
      "  fileInputs = \n",
      "    [\n",
      "      {'name': 'Input Directory', 'description': 'Directory containing the main script and any supporting files (models, data, etc.). (Example: tapis://designsafe.storage.community/app_examples/opensees/OpenSeesPy)', 'inputMode': 'REQUIRED', 'autoMountLocal': True, 'envKey': 'inputDirectory', 'notes': \n",
      "isHidden: False\n",
      "selectionMode: directory, 'sourceUrl': None, 'targetPath': 'inputDirectory'}\n",
      "    ]\n",
      "  fileInputArrays: []\n",
      "  subscriptions: []\n",
      "  tags: []\n"
     ]
    }
   ],
   "source": [
    "print(f'*****  {myKey} list-type input****')\n",
    "if len(TR_listKeys[myKey])>0:\n",
    "    for thisKey in TR_listKeys[myKey]:\n",
    "        thisList = app_jobAttributes[thisKey]\n",
    "        if len(thisList)>0:\n",
    "            print(f'  {thisKey} = ')\n",
    "            print('    [')\n",
    "            for thisValue in thisList:\n",
    "                if isinstance(thisValue, TapisResult):\n",
    "                    thisValue = thisValue.__dict__\n",
    "                print(f'      {thisValue}')\n",
    "            print('    ]')\n",
    "        else:\n",
    "            print(f'  {thisKey}: {thisList}')\n",
    "else:\n",
    "    print('none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **fileInputs**\n",
    "Here we find that jobAttributes.fileInputs is a REQUIRED input.\n",
    "\n",
    "In this case we need to get the tapisURI for our input directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage SystemTapis & Tapis Base Path in URI format\n",
    "this is the very first part of your path, just above your home folder.\n",
    "\n",
    "Options: \n",
    "* **CommunityData**\n",
    "* **Published**\n",
    "\n",
    "The following options are user or project-dependent, and require unique path input.\n",
    "\n",
    "\n",
    "The following option requires additional **user-dependent** input:\n",
    "* **MyData**\n",
    "\n",
    "The following option requires additional **user- and system- dependent** input:\n",
    "* **Work**\n",
    "\n",
    "The following option requires additional **project-dependent** input:\n",
    "* **MyProjects**\n",
    "\n",
    "You can obtain a dependent tapis-URI path by performing the first step of submitting an OpenSeesMP job at the app portal: https://www.designsafe-ci.org/workspace/opensees-mp-s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found paths file: /home/jupyter/MyData/.tapis_user_paths.json\n",
      "storage_system_baseURL: tapis://designsafe.storage.default/silvia\n"
     ]
    }
   ],
   "source": [
    "storage_system = 'MyData' # options: Community,MyData,Published,MyProjects,Work/stampede3,Work/frontera,Work/ls6\n",
    "storage_system_baseURL = OpsUtils.get_user_path_tapis_uri(t,storage_system)\n",
    "\n",
    "print('storage_system_baseURL:',storage_system_baseURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sourceUrl tapis://designsafe.storage.default/silvia/_ToCommunityData/OpenSees/TrainingMaterial/training-OpenSees-on-DesignSafe/Examples_OpenSees/BasicExamples\n"
     ]
    }
   ],
   "source": [
    "input_folder = '_ToCommunityData/OpenSees/TrainingMaterial/training-OpenSees-on-DesignSafe/Examples_OpenSees/BasicExamples'\n",
    "sourceUrl = f'{storage_system_baseURL}/{input_folder}'\n",
    "print('sourceUrl',sourceUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TapisInput['jobAttributes']['fileInputs'] = [{'name': 'Input Directory','sourceUrl':sourceUrl}]; # notice that it is a list!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** jobAttributes TapisResult-type input ****\n",
      "\n",
      "*** parameterSet ***\n",
      "\n",
      "  --- parameterSet -- Nested Objects---\n",
      "   jobAttributes.parameterSet dict-type input keys []\n",
      "   jobAttributes.parameterSet list-type input keys ['appArgs', 'containerArgs', 'schedulerOptions', 'envVariables']\n",
      "   jobAttributes.parameterSet TapisResult-type input keys ['archiveFilter', 'logConfig']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'***** {myKey} TapisResult-type input ****')\n",
    "if len(TR_TapisResultKeys[myKey])>0:\n",
    "    for hereKey in TR_TapisResultKeys[myKey]:\n",
    "        print(f'\\n*** {hereKey} ***')\n",
    "        thisTapisResult = app_jobAttributes[hereKey]\n",
    "        thisTapisResult_dict = thisTapisResult.__dict__\n",
    "        TR_dictKeys[hereKey] = []\n",
    "        TR_TapisResultKeys[hereKey] = []\n",
    "        TR_listKeys[hereKey] = []\n",
    "        for thisKey,thisValue in thisTapisResult_dict.items():\n",
    "            if isinstance(thisValue, dict):\n",
    "                TR_dictKeys[hereKey].append(thisKey)\n",
    "            if isinstance(thisValue, TapisResult):\n",
    "                TR_TapisResultKeys[hereKey].append(thisKey)\n",
    "            elif isinstance(thisValue, list):\n",
    "                TR_listKeys[hereKey].append(thisKey)\n",
    "            else:\n",
    "                print(f'  {myKey}.{thisKey} = {thisValue}')\n",
    "        print(f'\\n  --- {hereKey} -- Nested Objects---')\n",
    "        print(f'   {myKey}.{hereKey} dict-type input keys',TR_dictKeys[hereKey])\n",
    "        print(f'   {myKey}.{hereKey} list-type input keys',TR_listKeys[hereKey])\n",
    "        print(f'   {myKey}.{hereKey} TapisResult-type input keys',TR_TapisResultKeys[hereKey])\n",
    "        print('')\n",
    "else:\n",
    "    print('-none')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### app.jobAttributes.**parameterSet** is the interesting one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's extract and study jobAttributes\n",
    "myKey = 'parameterSet'\n",
    "app_parameterSet = app_jobAttributes[myKey].__dict__\n",
    "# we have already extracted the contents of this dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameterSet is a dictionary (TapisResult):\n",
    "TapisInput['jobAttributes'][myKey] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****  parameterSet dict-type Input ****\n",
      "there are no dictionaries within app_parameterSet, as expected, since Tapis works with TapisResults objects instead\n"
     ]
    }
   ],
   "source": [
    "print(f'*****  {myKey} dict-type Input ****')\n",
    "if len(TR_dictKeys[myKey])>0:\n",
    "    for thisKey in TR_dictKeys[myKey]:\n",
    "        thisDict = app_parameterSet[thisKey]\n",
    "        print(f'{myKey}.{thisKey} : {thisDict}')\n",
    "else:\n",
    "    print('there are no dictionaries within app_parameterSet, as expected, since Tapis works with TapisResults objects instead')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****  parameterSet list-type input****\n",
      "  appArgs = \n",
      "    [\n",
      "      {'arg': 'python3', 'name': 'Main Program', 'description': \"Binary executable to run. (e.g., OpenSees, OpenSeesMP, OpenSeesSP, python3 -- OpenSeesPy: use python3).    The executable must be available in the job's execution system. Some executables require you to load specific modules.\", 'inputMode': 'REQUIRED', 'notes': \n",
      "enum_values: [\n",
      "OpenSees: OpenSees, \n",
      "OpenSeesMP: OpenSeesMP, \n",
      "OpenSeesSP: OpenSeesSP, \n",
      "python3: Python]\n",
      "isHidden: False}\n",
      "      {'arg': None, 'name': 'Main Script', 'description': \"Filename (no path) of the input script passed to the executable (Example: Ex1a.Canti2D.Push.mpi4py.tacc.py). This file must reside in the Input Directory.  Note: This App uses TACC-Compiled OpenSeesPy: use 'import opensees' or 'import opensees as ops' in your script.\", 'inputMode': 'REQUIRED', 'notes': \n",
      "inputType: fileInput\n",
      "isHidden: False}\n",
      "      {'arg': 'True', 'name': 'UseMPI', 'description': 'Flag indicating whether the application should launch the main program with an MPI parallel-execution command (ibrun). **True**: enable distributed-memory parallelism, allowing multi-core or multi-node execution. (Suitable for OpenSeesMP / OpenSeesSP / Python with mpi4py (OpenSeesPy)). **False**: execution stays on one node. (Suitable for OpenSees, Python, or Python with concurrent.futures for one-node parallelism.)', 'inputMode': 'REQUIRED', 'notes': \n",
      "enum_values: [\n",
      "True: True — Enable MPI mode -- Use multi-node or multi-core parallelism., \n",
      "False: False — No MPI -- Use single-node process.]\n",
      "isHidden: False}\n",
      "      {'arg': None, 'name': 'CommandLine Arguments', 'description': \"Optional command-line arguments appended after Main Script (e.g., '--npts 2000 --dir X' or any format consistent with how your input script parses them).\", 'inputMode': 'INCLUDE_ON_DEMAND', 'notes': \n",
      "isHidden: False}\n",
      "    ]\n",
      "  containerArgs: []\n",
      "  schedulerOptions = \n",
      "    [\n",
      "      {'arg': '--tapis-profile tacc-no-modules', 'name': 'TACC Scheduler Profile', 'description': 'Scheduler profile (e.g., tacc-no-modules) -- the app loads the modules you specify.', 'inputMode': 'INCLUDE_BY_DEFAULT', 'notes': \n",
      "isHidden: False}\n",
      "      {'arg': None, 'name': 'TACC Reservation', 'description': 'If you have a TACC reservation, enter the reservation string here.', 'inputMode': 'INCLUDE_ON_DEMAND', 'notes': \n",
      "isHidden: False}\n",
      "    ]\n",
      "  envVariables = \n",
      "    [\n",
      "      {'key': 'GET_TACC_OPENSEESPY', 'value': 'True', 'description': \"If 'True', use the TACC-compiled OpenSeesPy (not the PyPI wheel). In your script, import OpenSeesPy using 'import opensees' or 'import opensees as ops'.\", 'inputMode': 'INCLUDE_BY_DEFAULT', 'notes': \n",
      "enum_values: [\n",
      "True: True: Copy TACC-Compiled OpenSeesPy, \n",
      "False: False: no TACC-Compiled OpenSeesPy]\n",
      "isHidden: False}\n",
      "      {'key': 'PIP_INSTALLS_LIST', 'value': 'mpi4py,pandas,numpy,matplotlib,futures', 'description': \"Comma-separated list of Python packages to pip install before the run. Example: 'numpy,scipy,mpi4py' Defaults:'mpi4py,pandas,numpy,scipy'.\", 'inputMode': 'INCLUDE_BY_DEFAULT', 'notes': \n",
      "isHidden: False}\n",
      "      {'key': 'MODULE_LOADS_LIST', 'value': 'python/3.12.11,opensees,hdf5/1.14.4,pylauncher', 'description': \"Comma-separated list of TACC modules to load before the run. Defaults: 'opensees,hdf5/1.14.4' 'python/3.12.11' and 'pylauncher' are included if  GET_TACC_OPENSEESPY=True.\", 'inputMode': 'INCLUDE_BY_DEFAULT', 'notes': \n",
      "isHidden: False}\n",
      "      {'key': 'UNZIP_FILES_LIST', 'value': '', 'description': \"Comma-separated list of ZIP files in the Input Directory to unzip before the run. Example: 'inputs.zip,gm_files.zip'.\", 'inputMode': 'INCLUDE_ON_DEMAND', 'notes': \n",
      "isHidden: False}\n",
      "      {'key': 'PATH_COPY_IN_LIST', 'value': '', 'description': \"Absolute Path (within the Execution System) of folder that will be copied into the job working directory **before** execution.  (Example: '$HOME/FileSet1,$WORK/FileSet2,$SCRATCH/FileSet3/thisFile.at2')\", 'inputMode': 'INCLUDE_ON_DEMAND', 'notes': \n",
      "isHidden: False}\n",
      "      {'key': 'DELETE_COPIED_IN_ON_EXIT', 'value': '0', 'description': 'If set to a true-like value, removes files or directories that were copied into the job working directory via PATH_COPY_IN_LIST after the job completes, preventing temporary inputs from being included in the final archive.', 'inputMode': 'INCLUDE_ON_DEMAND', 'notes': \n",
      "isHidden: False}\n",
      "      {'key': 'MODULE_LOADS_FILE', 'value': '', 'description': \"Name of a file in the Input Directory containing a list of modules to load (newline- or comma-separated). Example: 'modules.txt'.\", 'inputMode': 'INCLUDE_ON_DEMAND', 'notes': \n",
      "isHidden: False}\n",
      "      {'key': 'PIP_INSTALLS_FILE', 'value': '', 'description': \"Name of a file in the Input Directory containing a list of Python packages to pip install (newline- or comma-separated). Example: 'requirements.txt'.\", 'inputMode': 'INCLUDE_ON_DEMAND', 'notes': \n",
      "isHidden: False}\n",
      "      {'key': 'ZIP_OUTPUT_SWITCH', 'value': 'False', 'description': \"If 'True', zip the job output directory into a single archive before Tapis archiving. NOTE: the value must be defined as a string.\", 'inputMode': 'INCLUDE_BY_DEFAULT', 'notes': \n",
      "enum_values: [\n",
      "True: True: Zip All Output into a file, \n",
      "False: False: No Zipping]\n",
      "isHidden: False}\n",
      "      {'key': 'PATH_MOVE_OUTPUT', 'value': '', 'description': \"Destination path (Absolute and within the Execution System) where outputs will be moved **after** execution. (E.g., '$HOME/OutSet1', '$WORK/OutSet2', '$SCRATCH/OutSet3')\", 'inputMode': 'INCLUDE_BY_DEFAULT', 'notes': \n",
      "isHidden: False}\n",
      "      {'key': 'PRE_JOB_SCRIPT', 'value': '', 'description': 'Filename of user-defined PRE-JOB script (or absolute path). This file must reside in the Input Directory. It is run after the system has been configured, but before the main binary. (e.g. prehook.sh,$WORK/.../pre-hook.sh)', 'inputMode': 'INCLUDE_BY_DEFAULT', 'notes': \n",
      "isHidden: False}\n",
      "      {'key': 'POST_JOB_SCRIPT', 'value': '', 'description': 'Filename of user-defined POST-JOB script (or absolute path). This file must reside in the Input Directory. It is run after the the main binary. (e.g. prehook.sh,$WORK/.../pre-hook.sh)', 'inputMode': 'INCLUDE_BY_DEFAULT', 'notes': \n",
      "isHidden: False}\n",
      "    ]\n"
     ]
    }
   ],
   "source": [
    "print(f'*****  {myKey} list-type input****')\n",
    "if len(TR_listKeys[myKey])>0:\n",
    "    for thisKey in TR_listKeys[myKey]:\n",
    "        thisList = app_parameterSet[thisKey]\n",
    "        if len(thisList)>0:\n",
    "            print(f'  {thisKey} = ')\n",
    "            print('    [')\n",
    "            for thisValue in thisList:\n",
    "                if isinstance(thisValue, TapisResult):\n",
    "                    thisValue = thisValue.__dict__\n",
    "                print(f'      {str(thisValue)}')\n",
    "            print('    ]')\n",
    "        else:\n",
    "            print(f'  {thisKey}: {thisList}')\n",
    "else:\n",
    "    print('none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the opensees-mp-s3 and opensees-sp-s3 apps use appArgs, this app uses envVariables for the input.\n",
    "\n",
    "It looks like enum_values in notes is a list for a pull-down menu, and, interestingly, it is missing OpenSeesMP -- from the app definition in github, they Removed because OpenSeesMP is unable to use multiple cores, essentially making it SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review each of these items: ['appArgs', 'containerArgs', 'schedulerOptions', 'envVariables']\n"
     ]
    }
   ],
   "source": [
    "print('review each of these items:', TR_listKeys[myKey])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### app.jobAttributes.parameterSet.**appArgs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** app.jobAttributes.parameterSet.appArgs **\n",
      "\n",
      "arg: python3\n",
      "description: Binary executable to run. (e.g., OpenSees, OpenSeesMP, OpenSeesSP, python3 -- OpenSeesPy: use python3).    The executable must be available in the job's execution system. Some executables require you to load specific modules.\n",
      "inputMode: REQUIRED\n",
      "name: Main Program\n",
      "notes: \n",
      "enum_values: [\n",
      "OpenSees: OpenSees, \n",
      "OpenSeesMP: OpenSeesMP, \n",
      "OpenSeesSP: OpenSeesSP, \n",
      "python3: Python]\n",
      "isHidden: False\n",
      "\n",
      "arg: None\n",
      "description: Filename (no path) of the input script passed to the executable (Example: Ex1a.Canti2D.Push.mpi4py.tacc.py). This file must reside in the Input Directory.  Note: This App uses TACC-Compiled OpenSeesPy: use 'import opensees' or 'import opensees as ops' in your script.\n",
      "inputMode: REQUIRED\n",
      "name: Main Script\n",
      "notes: \n",
      "inputType: fileInput\n",
      "isHidden: False\n",
      "\n",
      "arg: True\n",
      "description: Flag indicating whether the application should launch the main program with an MPI parallel-execution command (ibrun). **True**: enable distributed-memory parallelism, allowing multi-core or multi-node execution. (Suitable for OpenSeesMP / OpenSeesSP / Python with mpi4py (OpenSeesPy)). **False**: execution stays on one node. (Suitable for OpenSees, Python, or Python with concurrent.futures for one-node parallelism.)\n",
      "inputMode: REQUIRED\n",
      "name: UseMPI\n",
      "notes: \n",
      "enum_values: [\n",
      "True: True — Enable MPI mode -- Use multi-node or multi-core parallelism., \n",
      "False: False — No MPI -- Use single-node process.]\n",
      "isHidden: False\n",
      "\n",
      "arg: None\n",
      "description: Optional command-line arguments appended after Main Script (e.g., '--npts 2000 --dir X' or any format consistent with how your input script parses them).\n",
      "inputMode: INCLUDE_ON_DEMAND\n",
      "name: CommandLine Arguments\n",
      "notes: \n",
      "isHidden: False\n"
     ]
    }
   ],
   "source": [
    "thisKey = 'appArgs'\n",
    "TapisInput['jobAttributes']['parameterSet'][thisKey] = [] # it's a list, initialize as a list!\n",
    "print(f'** app.jobAttributes.parameterSet.{thisKey} **')\n",
    "if len(app_parameterSet[thisKey])>0:\n",
    "    for thisItem in app_parameterSet[thisKey]:\n",
    "        print(thisItem)\n",
    "else:\n",
    "    print('.none.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing to input here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### app.jobAttributes.parameterSet.**containerArgs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** app.jobAttributes.parameterSet.containerArgs **\n",
      ".none.\n"
     ]
    }
   ],
   "source": [
    "thisKey = 'containerArgs'\n",
    "TapisInput['jobAttributes']['parameterSet'][thisKey] = [] # it's a list, initialize as a list!\n",
    "print(f'** app.jobAttributes.parameterSet.{thisKey} **')\n",
    "if len(app_parameterSet[thisKey])>0:\n",
    "    for thisItem in app_parameterSet[thisKey]:\n",
    "        print(thisItem)\n",
    "else:\n",
    "    print('.none.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do nothing for this app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### app.jobAttributes.parameterSet.**schedulerOptions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** app.jobAttributes.parameterSet.schedulerOptions **\n",
      "\n",
      "arg: --tapis-profile tacc-no-modules\n",
      "description: Scheduler profile (e.g., tacc-no-modules) -- the app loads the modules you specify.\n",
      "inputMode: INCLUDE_BY_DEFAULT\n",
      "name: TACC Scheduler Profile\n",
      "notes: \n",
      "isHidden: False\n",
      "\n",
      "arg: None\n",
      "description: If you have a TACC reservation, enter the reservation string here.\n",
      "inputMode: INCLUDE_ON_DEMAND\n",
      "name: TACC Reservation\n",
      "notes: \n",
      "isHidden: False\n"
     ]
    }
   ],
   "source": [
    "thisKey = 'schedulerOptions'\n",
    "TapisInput['jobAttributes']['parameterSet'][thisKey] = [] # it's a list, initialize as a list!\n",
    "print(f'** app.jobAttributes.parameterSet.{thisKey} **')\n",
    "if len(app_parameterSet[thisKey])>0:\n",
    "    for thisItem in app_parameterSet[thisKey]:\n",
    "        print(thisItem)\n",
    "else:\n",
    "    print('.none.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no scheduler nor allocation used in OpenSees-Express."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NO NEED to add allocation to the scheduler option -- not shown in the app schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_allocation = '-A DS-HPC1'; # you get this code from your allocation dashboard\n",
    "# TapisInput['jobAttributes']['parameterSet']['schedulerOptions'].append({'name': 'TACC Allocation', 'arg': user_allocation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### app.jobAttributes.parameterSet.**envVariables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** app.jobAttributes.parameterSet.envVariables **\n",
      "\n",
      "description: If 'True', use the TACC-compiled OpenSeesPy (not the PyPI wheel). In your script, import OpenSeesPy using 'import opensees' or 'import opensees as ops'.\n",
      "inputMode: INCLUDE_BY_DEFAULT\n",
      "key: GET_TACC_OPENSEESPY\n",
      "notes: \n",
      "enum_values: [\n",
      "True: True: Copy TACC-Compiled OpenSeesPy, \n",
      "False: False: no TACC-Compiled OpenSeesPy]\n",
      "isHidden: False\n",
      "value: True\n",
      "\n",
      "description: Comma-separated list of Python packages to pip install before the run. Example: 'numpy,scipy,mpi4py' Defaults:'mpi4py,pandas,numpy,scipy'.\n",
      "inputMode: INCLUDE_BY_DEFAULT\n",
      "key: PIP_INSTALLS_LIST\n",
      "notes: \n",
      "isHidden: False\n",
      "value: mpi4py,pandas,numpy,matplotlib,futures\n",
      "\n",
      "description: Comma-separated list of TACC modules to load before the run. Defaults: 'opensees,hdf5/1.14.4' 'python/3.12.11' and 'pylauncher' are included if  GET_TACC_OPENSEESPY=True.\n",
      "inputMode: INCLUDE_BY_DEFAULT\n",
      "key: MODULE_LOADS_LIST\n",
      "notes: \n",
      "isHidden: False\n",
      "value: python/3.12.11,opensees,hdf5/1.14.4,pylauncher\n",
      "\n",
      "description: Comma-separated list of ZIP files in the Input Directory to unzip before the run. Example: 'inputs.zip,gm_files.zip'.\n",
      "inputMode: INCLUDE_ON_DEMAND\n",
      "key: UNZIP_FILES_LIST\n",
      "notes: \n",
      "isHidden: False\n",
      "value: \n",
      "\n",
      "description: Absolute Path (within the Execution System) of folder that will be copied into the job working directory **before** execution.  (Example: '$HOME/FileSet1,$WORK/FileSet2,$SCRATCH/FileSet3/thisFile.at2')\n",
      "inputMode: INCLUDE_ON_DEMAND\n",
      "key: PATH_COPY_IN_LIST\n",
      "notes: \n",
      "isHidden: False\n",
      "value: \n",
      "\n",
      "description: If set to a true-like value, removes files or directories that were copied into the job working directory via PATH_COPY_IN_LIST after the job completes, preventing temporary inputs from being included in the final archive.\n",
      "inputMode: INCLUDE_ON_DEMAND\n",
      "key: DELETE_COPIED_IN_ON_EXIT\n",
      "notes: \n",
      "isHidden: False\n",
      "value: 0\n",
      "\n",
      "description: Name of a file in the Input Directory containing a list of modules to load (newline- or comma-separated). Example: 'modules.txt'.\n",
      "inputMode: INCLUDE_ON_DEMAND\n",
      "key: MODULE_LOADS_FILE\n",
      "notes: \n",
      "isHidden: False\n",
      "value: \n",
      "\n",
      "description: Name of a file in the Input Directory containing a list of Python packages to pip install (newline- or comma-separated). Example: 'requirements.txt'.\n",
      "inputMode: INCLUDE_ON_DEMAND\n",
      "key: PIP_INSTALLS_FILE\n",
      "notes: \n",
      "isHidden: False\n",
      "value: \n",
      "\n",
      "description: If 'True', zip the job output directory into a single archive before Tapis archiving. NOTE: the value must be defined as a string.\n",
      "inputMode: INCLUDE_BY_DEFAULT\n",
      "key: ZIP_OUTPUT_SWITCH\n",
      "notes: \n",
      "enum_values: [\n",
      "True: True: Zip All Output into a file, \n",
      "False: False: No Zipping]\n",
      "isHidden: False\n",
      "value: False\n",
      "\n",
      "description: Destination path (Absolute and within the Execution System) where outputs will be moved **after** execution. (E.g., '$HOME/OutSet1', '$WORK/OutSet2', '$SCRATCH/OutSet3')\n",
      "inputMode: INCLUDE_BY_DEFAULT\n",
      "key: PATH_MOVE_OUTPUT\n",
      "notes: \n",
      "isHidden: False\n",
      "value: \n",
      "\n",
      "description: Filename of user-defined PRE-JOB script (or absolute path). This file must reside in the Input Directory. It is run after the system has been configured, but before the main binary. (e.g. prehook.sh,$WORK/.../pre-hook.sh)\n",
      "inputMode: INCLUDE_BY_DEFAULT\n",
      "key: PRE_JOB_SCRIPT\n",
      "notes: \n",
      "isHidden: False\n",
      "value: \n",
      "\n",
      "description: Filename of user-defined POST-JOB script (or absolute path). This file must reside in the Input Directory. It is run after the the main binary. (e.g. prehook.sh,$WORK/.../pre-hook.sh)\n",
      "inputMode: INCLUDE_BY_DEFAULT\n",
      "key: POST_JOB_SCRIPT\n",
      "notes: \n",
      "isHidden: False\n",
      "value: \n"
     ]
    }
   ],
   "source": [
    "thisKey = 'envVariables'\n",
    "TapisInput['jobAttributes']['parameterSet'][thisKey] = [] # it's a list, initialize as a list!\n",
    "print(f'** app.jobAttributes.parameterSet.{thisKey} **')\n",
    "if len(app_parameterSet[thisKey])>0:\n",
    "    for thisItem in app_parameterSet[thisKey]:\n",
    "        print(thisItem)\n",
    "else:\n",
    "    print('.none.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YES this app does have input here, we need to specify the execution program and the tcl script\n",
    "\n",
    "Note that the names of the labels for the keys here are key and value , not name and arg, and the keys are different from opensees-mp-s3\n",
    "\n",
    "Make sure your tcl script is for a sequential analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TapisInput['jobAttributes']['parameterSet']['envVariables'].append({\"key\": \"mainProgram\", \"value\": 'OpenSees'})\n",
    "TapisInput['jobAttributes']['parameterSet']['envVariables'].append({\"key\": \"tclScript\", \"value\": 'Ex1a.Canti2D.Push.tcl'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** parameterSet TapisResult-type input ****\n",
      "\n",
      "*** archiveFilter ***\n",
      "  parameterSet.includeLaunchFiles = True\n",
      "\n",
      "  --- archiveFilter -- Nested Objects---\n",
      "   parameterSet.archiveFilter dict-type input keys []\n",
      "   parameterSet.archiveFilter list-type input keys ['includes', 'excludes']\n",
      "   parameterSet.archiveFilter TapisResult-type input keys []\n",
      "\n",
      "\n",
      "*** logConfig ***\n",
      "  parameterSet.stdoutFilename = \n",
      "  parameterSet.stderrFilename = \n",
      "\n",
      "  --- logConfig -- Nested Objects---\n",
      "   parameterSet.logConfig dict-type input keys []\n",
      "   parameterSet.logConfig list-type input keys []\n",
      "   parameterSet.logConfig TapisResult-type input keys []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'***** {myKey} TapisResult-type input ****')\n",
    "if len(TR_TapisResultKeys[myKey])>0:\n",
    "    for hereKey in TR_TapisResultKeys[myKey]:\n",
    "        print(f'\\n*** {hereKey} ***')\n",
    "        thisTapisResult = app_parameterSet[hereKey]\n",
    "        thisTapisResult_dict = thisTapisResult.__dict__\n",
    "        TR_dictKeys[hereKey] = []\n",
    "        TR_TapisResultKeys[hereKey] = []\n",
    "        TR_listKeys[hereKey] = []\n",
    "        for thisKey,thisValue in thisTapisResult_dict.items():\n",
    "            if isinstance(thisValue, dict):\n",
    "                TR_dictKeys[hereKey].append(thisKey)\n",
    "            if isinstance(thisValue, TapisResult):\n",
    "                TR_TapisResultKeys[hereKey].append(thisKey)\n",
    "            elif isinstance(thisValue, list):\n",
    "                TR_listKeys[hereKey].append(thisKey)\n",
    "            else:\n",
    "                print(f'  {myKey}.{thisKey} = {thisValue}')\n",
    "        print(f'\\n  --- {hereKey} -- Nested Objects---')\n",
    "        print(f'   {myKey}.{hereKey} dict-type input keys',TR_dictKeys[hereKey])\n",
    "        print(f'   {myKey}.{hereKey} list-type input keys',TR_listKeys[hereKey])\n",
    "        print(f'   {myKey}.{hereKey} TapisResult-type input keys',TR_TapisResultKeys[hereKey])\n",
    "        print('')\n",
    "else:\n",
    "    print('-none')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nothing of interest to us here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### We are done with our tapis-job input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TapisInput\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'TestJob-$designsafe-agnostic-app',\n",
       " 'jobAttributes': {'name': 'My first Tapis Job on designsafe-agnostic-app',\n",
       "  'appId': 'designsafe-agnostic-app',\n",
       "  'appVersion': 'latest',\n",
       "  'execSystemId': 'stampede3',\n",
       "  'execSystemLogicalQueue': 'skx-dev',\n",
       "  'nodeCount': 1,\n",
       "  'coresPerNode': 16,\n",
       "  'maxMinutes': 7,\n",
       "  'fileInputs': [{'name': 'Input Directory',\n",
       "    'sourceUrl': 'tapis://designsafe.storage.default/silvia/_ToCommunityData/OpenSees/TrainingMaterial/training-OpenSees-on-DesignSafe/Examples_OpenSees/BasicExamples'}],\n",
       "  'parameterSet': {'appArgs': [],\n",
       "   'containerArgs': [],\n",
       "   'schedulerOptions': [],\n",
       "   'envVariables': [{'key': 'mainProgram', 'value': 'OpenSees'},\n",
       "    {'key': 'tclScript', 'value': 'Ex1a.Canti2D.Push.tcl'}]}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('TapisInput')\n",
    "display(TapisInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TapisInput.jobAttributes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'My first Tapis Job on designsafe-agnostic-app',\n",
       " 'appId': 'designsafe-agnostic-app',\n",
       " 'appVersion': 'latest',\n",
       " 'execSystemId': 'stampede3',\n",
       " 'execSystemLogicalQueue': 'skx-dev',\n",
       " 'nodeCount': 1,\n",
       " 'coresPerNode': 16,\n",
       " 'maxMinutes': 7,\n",
       " 'fileInputs': [{'name': 'Input Directory',\n",
       "   'sourceUrl': 'tapis://designsafe.storage.default/silvia/_ToCommunityData/OpenSees/TrainingMaterial/training-OpenSees-on-DesignSafe/Examples_OpenSees/BasicExamples'}],\n",
       " 'parameterSet': {'appArgs': [],\n",
       "  'containerArgs': [],\n",
       "  'schedulerOptions': [],\n",
       "  'envVariables': [{'key': 'mainProgram', 'value': 'OpenSees'},\n",
       "   {'key': 'tclScript', 'value': 'Ex1a.Canti2D.Push.tcl'}]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('TapisInput.jobAttributes')\n",
    "display(TapisInput['jobAttributes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if submitJob:\n",
    "    submitted_job = t.jobs.submitJob(**TapisInput['jobAttributes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if submitJob:\n",
    "    print(submitted_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once you have no errors you are done submitting the job.\n",
    "### go to the job-status page on the web portal to monitor the your job. \n",
    "\n",
    "https://www.designsafe-ci.org/workspace/history\n",
    "\n",
    "You will, likely, have to debug your OpenSees script....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** ONCE THE JOB HAS COMPLETED, go to view Output and pay attention to the location (path) of the output, it may not be in MyData, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "IMAGE_NAME": "taccsciapps/ds-nb-img:base-0.2.3",
  "UUID": "73e0880d-9b87-11ec-9c1c-13579dd95994",
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
